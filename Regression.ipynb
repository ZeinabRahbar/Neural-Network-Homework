{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9121aa43",
   "metadata": {},
   "source": [
    "# 2 Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc38042",
   "metadata": {},
   "source": [
    "# 2_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f22b4615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Loss: [196.31308511+3.00892106j]\n",
      "--------------------------\n",
      "Epoch: 1\n",
      "Loss: [7719552.73122607+304916.51762372j]\n",
      "--------------------------\n",
      "Epoch: 2\n",
      "Loss: [8.91154214e+20+1.06110924e+20j]\n",
      "--------------------------\n",
      "Epoch: 3\n",
      "Loss: [1.32492929e+63+4.91972104e+62j]\n",
      "--------------------------\n",
      "Epoch: 4\n",
      "Loss: [2.66659641e+189+4.83308916e+189j]\n",
      "--------------------------\n",
      "Epoch: 5\n",
      "Loss: [nan+nanj]\n",
      "--------------------------\n",
      "Epoch: 6\n",
      "Loss: [nan+nanj]\n",
      "--------------------------\n",
      "Epoch: 7\n",
      "Loss: [nan+nanj]\n",
      "--------------------------\n",
      "Epoch: 8\n",
      "Loss: [nan+nanj]\n",
      "--------------------------\n",
      "Epoch: 9\n",
      "Loss: [nan+nanj]\n",
      "--------------------------\n",
      "Epoch: 10\n",
      "Loss: [nan+nanj]\n",
      "--------------------------\n",
      "Epoch: 11\n",
      "Loss: [nan+nanj]\n",
      "--------------------------\n",
      "Epoch: 12\n",
      "Loss: [nan+nanj]\n",
      "--------------------------\n",
      "Epoch: 13\n",
      "Loss: [nan+nanj]\n",
      "--------------------------\n",
      "Epoch: 14\n",
      "Loss: [nan+nanj]\n",
      "--------------------------\n",
      "Epoch: 15\n",
      "Loss: [nan+nanj]\n",
      "--------------------------\n",
      "Epoch: 16\n",
      "Loss: [nan+nanj]\n",
      "--------------------------\n",
      "Epoch: 17\n",
      "Loss: [nan+nanj]\n",
      "--------------------------\n",
      "Epoch: 18\n",
      "Loss: [nan+nanj]\n",
      "--------------------------\n",
      "Epoch: 19\n",
      "Loss: [nan+nanj]\n",
      "--------------------------\n",
      "Loss for testing dataset: [nan+nanj]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ansar9811291\\AppData\\Local\\Temp\\ipykernel_16088\\2436512996.py:82: RuntimeWarning: overflow encountered in square\n",
      "  return np.mean((y_true-y_predict)**2,axis = 0)\n",
      "C:\\Users\\Ansar9811291\\AppData\\Local\\Temp\\ipykernel_16088\\2436512996.py:82: RuntimeWarning: invalid value encountered in square\n",
      "  return np.mean((y_true-y_predict)**2,axis = 0)\n",
      "C:\\Users\\Ansar9811291\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\_methods.py:162: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = um.true_divide(\n",
      "C:\\Users\\Ansar9811291\\AppData\\Local\\Temp\\ipykernel_16088\\2436512996.py:53: RuntimeWarning: invalid value encountered in less_equal\n",
      "  self.b_output[self.input<=0] = 0\n",
      "C:\\Users\\Ansar9811291\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\_asarray.py:136: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "class Dense:\n",
    "    def __init__(self,n_inputs,n_neurons):\n",
    "       \n",
    "        self.w=np.random.randint(-2, 2, (n_inputs, n_neurons))\n",
    "        self.b = np.random.randint(-2, 2, (1, n_neurons))    #b\n",
    "        self.weight_history = 0\n",
    "        self.bias_history = 0\n",
    "    \n",
    "    def forward(self,inputs):\n",
    "        self.input = inputs  #p\n",
    "        self.output = np.dot(inputs,self.w)+self.b\n",
    "        #print(self.output)\n",
    "        \n",
    "    def backward(self,b_input):\n",
    "        #print(type(b_input))\n",
    "        #print(b_input)\n",
    "        #print(type(self.w))\n",
    "        #print(self.w)\n",
    "        self.b_output = np.dot(b_input,self.w.T)\n",
    "        self.g_w = np.dot(self.input.T,b_input)\n",
    "        self.g_b = np.sum(b_input,axis=0,keepdims=True)\n",
    "\n",
    "class Linear:\n",
    "    def forward(self,inputs):\n",
    "        self.input = inputs\n",
    "        self.output = inputs\n",
    "    def backward(self,b_input):\n",
    "        self.b_output = b_input  \n",
    "\n",
    "class Sigmoid:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def forward(self,inputs):\n",
    "        self.input = inputs\n",
    "        self.output = 1/(1+np.exp(-inputs))\n",
    "    def backward(self,b_input):\n",
    "        self.b_output = b_input*self.output*(1-self.output)\n",
    "\n",
    "class ReLU:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def forward(self,inputs):\n",
    "        self.output = np.maximum(0,inputs)\n",
    "        self.input = inputs\n",
    "    \n",
    "    def backward(self,b_input):\n",
    "        self.b_output = b_input\n",
    "        self.b_output[self.input<=0] = 0\n",
    "\n",
    "class SGD:\n",
    "    def __init__(self,learning_rate = 0.001,momentum=0):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.momentum = momentum\n",
    "    def update(self,layer):\n",
    "        if self.momentum:\n",
    "            weight_update = self.momentum*layer.weight_history\\\n",
    "            + (1-self.momentum)*(-self.learning_rate*layer.g_w)\n",
    "            layer.weight_update = weight_update\n",
    "            bias_update = self.momentum*layer.weight_history\\\n",
    "            + (1-self.momentum)*(-self.learning_rate*layer.g_b)\n",
    "            layer.bias_update = bias_update\n",
    "        else:\n",
    "            weight_update = - self.learning_rate*layer.g_w\n",
    "            bias_update = - self.learning_rate*layer.g_b\n",
    "        \n",
    "        layer.w = layer.w + weight_update\n",
    "        layer.b = layer.b + bias_update\n",
    "    \n",
    "    def discard(self,layer):\n",
    "        layer.w = layer.w \n",
    "        layer.b = layer.b \n",
    "\n",
    "class Mean_Square_Error_loss:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def forward(self,y_predict,y_true):\n",
    "        return np.mean((y_true-y_predict)**2,axis = 0)\n",
    "    \n",
    "    def backward(self,y_predict,y_true):\n",
    "        self.b_output = -2*(y_true-y_predict)\n",
    "\n",
    "#2_1\n",
    "\n",
    "p=[]\n",
    "t=[]\n",
    "\n",
    "p_test=[]\n",
    "t_test=[]\n",
    "\n",
    "for i in range(400):\n",
    "    dataP = np.random.randint(-4,4)\n",
    "    p.append(dataP)\n",
    "    \n",
    "    epsilon=np.random.normal(0, 1)\n",
    "    \n",
    "    dataT=(16+epsilon-(dataP**2))**(1/2)\n",
    "    t.append(dataT)\n",
    "\n",
    "p = pd.DataFrame(p,columns =['x_train'])\n",
    "t = pd.DataFrame(t,columns =['y_train'])\n",
    "\n",
    "\n",
    "for i in range(100):\n",
    "    dataP = np.random.randint(-3,3)\n",
    "    p_test.append(dataP)\n",
    "    \n",
    "    epsilon=np.random.normal(0, 1)\n",
    "    \n",
    "    dataT=(16+epsilon-(dataP**2))**(1/2)\n",
    "    t_test.append(dataT)\n",
    "        \n",
    "p_test=pd.DataFrame(p_test,columns =['x_test'])\n",
    "t_test=pd.DataFrame(t_test,columns =['y_test'])\n",
    "\n",
    "x_train=[]\n",
    "y_train=[]\n",
    "x_test=[]\n",
    "y_test=[]\n",
    "\n",
    "#Creating train data\n",
    "for i in range(400):\n",
    "    temp=[]\n",
    "    temp.append(p['x_train'][i])\n",
    "    x_train.append(temp)\n",
    "    \n",
    "for i in range(400):\n",
    "    temp=[]\n",
    "    temp.append(t['y_train'][i])\n",
    "    y_train.append(temp)\n",
    "\n",
    "#Creating test data\n",
    "for i in range(100):\n",
    "    temp=[]\n",
    "    temp.append(p_test['x_test'][i])\n",
    "    x_test.append(temp)\n",
    "\n",
    "\n",
    "for i in range(100):\n",
    "    temp=[]\n",
    "    temp.append(t_test['y_test'][i])\n",
    "    y_test.append(temp)\n",
    "    \n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# 2_1_a neural network model\n",
    "Layer1 = Dense(1,5)\n",
    "Act1 = ReLU()\n",
    "Layer2 = Dense(5,1)\n",
    "Act2 = Linear()\n",
    "Loss = Mean_Square_Error_loss()\n",
    "Optimizer = SGD(0.001)\n",
    "\n",
    "\n",
    "\n",
    "y_predict = 0\n",
    "for epoch in range(20):\n",
    "    #forward\n",
    "    \n",
    "    Layer1.forward(x_train)\n",
    "    Act1.forward(Layer1.output)\n",
    "    Layer2.forward(Act1.output)\n",
    "    Act2.forward(Layer2.output)\n",
    "    loss = Loss.forward(Act2.output,y_train)\n",
    "    \n",
    "    # Report\n",
    "    y_predict = np.argmax(Act2.output,axis = 1)\n",
    "    accuracy = np.mean(y_train == y_predict)\n",
    "    print(\"Epoch:\",epoch,)\n",
    "    print(\"Loss:\",loss)\n",
    "    print('--------------------------')\n",
    "    \n",
    "    #backward\n",
    "    Loss.backward(Act2.output,y_train)\n",
    "    Act2.backward(Loss.b_output)\n",
    "    Layer2.backward(Act2.b_output)\n",
    "    Act1.backward(Layer2.b_output)\n",
    "    Layer1.backward(Act1.b_output)\n",
    "    \n",
    "    #update params\n",
    "    Optimizer.update(Layer1)\n",
    "    Optimizer.update(Layer2)\n",
    "\n",
    "#Testing Step:\n",
    "p = x_test\n",
    "Layer1.forward(p)\n",
    "Act1.forward(Layer1.output)\n",
    "Layer2.forward(Act1.output)\n",
    "Act2.forward(Layer2.output)\n",
    "\n",
    "a = Act2.output\n",
    "\n",
    "plt.scatter(p,a)\n",
    "\n",
    "loss = Loss.forward(Act2.output,y_test)\n",
    "print(\"Loss for testing dataset:\", loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "976ce55d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Loss: [31.34323492+0.31847592j]\n",
      "--------------------------\n",
      "Epoch: 1\n",
      "Loss: [10.72634509-0.33820632j]\n",
      "--------------------------\n",
      "Epoch: 2\n",
      "Loss: [2.8518876-0.29418617j]\n",
      "--------------------------\n",
      "Epoch: 3\n",
      "Loss: [1.09767022-0.24181814j]\n",
      "--------------------------\n",
      "Epoch: 4\n",
      "Loss: [0.81738774-0.20812905j]\n",
      "--------------------------\n",
      "Epoch: 5\n",
      "Loss: [0.75450226-0.20012793j]\n",
      "--------------------------\n",
      "Epoch: 6\n",
      "Loss: [0.70899043-0.19522471j]\n",
      "--------------------------\n",
      "Epoch: 7\n",
      "Loss: [0.669102-0.19050739j]\n",
      "--------------------------\n",
      "Epoch: 8\n",
      "Loss: [0.63293062-0.18562328j]\n",
      "--------------------------\n",
      "Epoch: 9\n",
      "Loss: [0.59974469-0.18061096j]\n",
      "--------------------------\n",
      "Epoch: 10\n",
      "Loss: [0.56908566-0.17555496j]\n",
      "--------------------------\n",
      "Epoch: 11\n",
      "Loss: [0.54061684-0.17052664j]\n",
      "--------------------------\n",
      "Epoch: 12\n",
      "Loss: [0.51407835-0.16558038j]\n",
      "--------------------------\n",
      "Epoch: 13\n",
      "Loss: [0.48926359-0.16075578j]\n",
      "--------------------------\n",
      "Epoch: 14\n",
      "Loss: [0.46600496-0.15608113j]\n",
      "--------------------------\n",
      "Epoch: 15\n",
      "Loss: [0.44416397-0.15157622j]\n",
      "--------------------------\n",
      "Epoch: 16\n",
      "Loss: [0.42362423-0.14725464j]\n",
      "--------------------------\n",
      "Epoch: 17\n",
      "Loss: [0.40428647-0.14312545j]\n",
      "--------------------------\n",
      "Epoch: 18\n",
      "Loss: [0.38606488-0.13919455j]\n",
      "--------------------------\n",
      "Epoch: 19\n",
      "Loss: [0.36888445-0.13546563j]\n",
      "--------------------------\n",
      "Loss for testing dataset: [0.17988262-0.04211259j]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2_1_b neural network model\n",
    "Layer1 = Dense(1,5)\n",
    "Act1 = Sigmoid()\n",
    "Layer2 = Dense(5,1)\n",
    "Act2 = Linear()\n",
    "Loss = Mean_Square_Error_loss()\n",
    "Optimizer = SGD(0.001)\n",
    "\n",
    "for epoch in range(20):\n",
    "    #forward\n",
    "    \n",
    "    Layer1.forward(x_train)\n",
    "    Act1.forward(Layer1.output)\n",
    "    Layer2.forward(Act1.output)\n",
    "    Act2.forward(Layer2.output)\n",
    "    loss = Loss.forward(Act2.output,y_train)\n",
    "    \n",
    "    y_predict = np.argmax(Act2.output,axis = 1)\n",
    "    accuracy = np.mean(y_train == y_predict)\n",
    "    print(\"Epoch:\",epoch)\n",
    "    print(\"Loss:\",loss)\n",
    "    print('--------------------------')\n",
    "    \n",
    "    #backward\n",
    "    Loss.backward(Act2.output,y_train)\n",
    "    Act2.backward(Loss.b_output)\n",
    "    Layer2.backward(Act2.b_output)\n",
    "    Act1.backward(Layer2.b_output)\n",
    "    Layer1.backward(Act1.b_output)\n",
    "    \n",
    "    #update params\n",
    "    Optimizer.update(Layer1)\n",
    "    Optimizer.update(Layer2)\n",
    "\n",
    "\n",
    "#Testing Step:\n",
    "p = x_test\n",
    "Layer1.forward(p)\n",
    "Act1.forward(Layer1.output)\n",
    "Layer2.forward(Act1.output)\n",
    "Act2.forward(Layer2.output)\n",
    "a = Act2.output\n",
    "\n",
    "plt.scatter(p,a)\n",
    "\n",
    "loss = Loss.forward(Act2.output,y_test)\n",
    "print(\"Loss for testing dataset:\", loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81428395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 :\n",
      "Loss [8.73754454+0.36107053j]\n",
      "--------------------------\n",
      "Epoch 1 :\n",
      "Loss [1.30405219-0.37480548j]\n",
      "--------------------------\n",
      "Epoch 2 :\n",
      "Loss [1.22531419-0.36818161j]\n",
      "--------------------------\n",
      "Epoch 3 :\n",
      "Loss [1.22216467-0.36791666j]\n",
      "--------------------------\n",
      "Epoch 4 :\n",
      "Loss [1.22203868-0.36790606j]\n",
      "--------------------------\n",
      "Epoch 5 :\n",
      "Loss [1.22203365-0.36790564j]\n",
      "--------------------------\n",
      "Epoch 6 :\n",
      "Loss [1.22203344-0.36790562j]\n",
      "--------------------------\n",
      "Epoch 7 :\n",
      "Loss [1.22203344-0.36790562j]\n",
      "--------------------------\n",
      "Epoch 8 :\n",
      "Loss [1.22203344-0.36790562j]\n",
      "--------------------------\n",
      "Epoch 9 :\n",
      "Loss [1.22203344-0.36790562j]\n",
      "--------------------------\n",
      "Epoch 10 :\n",
      "Loss [1.22203344-0.36790562j]\n",
      "--------------------------\n",
      "Epoch 11 :\n",
      "Loss [1.22203344-0.36790562j]\n",
      "--------------------------\n",
      "Epoch 12 :\n",
      "Loss [1.22203344-0.36790562j]\n",
      "--------------------------\n",
      "Epoch 13 :\n",
      "Loss [1.22203344-0.36790562j]\n",
      "--------------------------\n",
      "Epoch 14 :\n",
      "Loss [1.22203344-0.36790562j]\n",
      "--------------------------\n",
      "Epoch 15 :\n",
      "Loss [1.22203344-0.36790562j]\n",
      "--------------------------\n",
      "Epoch 16 :\n",
      "Loss [1.22203344-0.36790562j]\n",
      "--------------------------\n",
      "Epoch 17 :\n",
      "Loss [1.22203344-0.36790562j]\n",
      "--------------------------\n",
      "Epoch 18 :\n",
      "Loss [1.22203344-0.36790562j]\n",
      "--------------------------\n",
      "Epoch 19 :\n",
      "Loss [1.22203344-0.36790562j]\n",
      "--------------------------\n",
      "Loss for testing dataset: [0.44800875-0.0574979j]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2_1_c neural network model\n",
    "\n",
    "Layer1 = Dense(1,10)\n",
    "Act1 = ReLU()\n",
    "\n",
    "Layer2 = Dense(10,5)\n",
    "Act2 = ReLU()\n",
    "\n",
    "Layer3 = Dense(5,1)\n",
    "Act3 = Linear()\n",
    "\n",
    "Loss = Mean_Square_Error_loss()\n",
    "\n",
    "Optimizer = SGD(0.001)\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(20):\n",
    "    #forward\n",
    "    Layer1.forward(x_train)\n",
    "    Act1.forward(Layer1.output)\n",
    "    Layer2.forward(Act1.output)\n",
    "    Act2.forward(Layer2.output)\n",
    "    Layer3.forward(Act2.output)\n",
    "    Act3.forward(Layer3.output)\n",
    "    loss = Loss.forward(Act3.output,y_train)\n",
    "    \n",
    "    print(\"Epoch\", epoch,\":\")\n",
    "    print(\"Loss\", loss)    \n",
    "    print('--------------------------')\n",
    "    \n",
    "    #backward\n",
    "    Loss.backward(Act3.output,y_train)\n",
    "    Act3.backward(Loss.b_output)\n",
    "    Layer3.backward(Act3.b_output)\n",
    "    Act2.backward(Layer3.b_output)\n",
    "    \n",
    "    Layer2.backward(Act2.b_output)\n",
    "    Act1.backward(Layer2.b_output)\n",
    "    Layer1.backward(Act1.b_output)\n",
    "    \n",
    "    #update params\n",
    "    Optimizer.update(Layer1)\n",
    "    Optimizer.update(Layer2)\n",
    "    Optimizer.update(Layer3)\n",
    "    \n",
    "#Testing Step:\n",
    "p = x_test\n",
    "Layer1.forward(p)\n",
    "Act1.forward(Layer1.output)\n",
    "Layer2.forward(Act1.output)\n",
    "Act2.forward(Layer2.output)\n",
    "Layer3.forward(Act2.output)\n",
    "Act3.forward(Layer3.output)\n",
    "a = Act3.output\n",
    "\n",
    "plt.scatter(p,a)\n",
    "\n",
    "loss = Loss.forward(Act3.output,y_test)\n",
    "print(\"Loss for testing dataset:\", loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "debc2fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 :\n",
      "Loss [10.94915079-0.08987325j]\n",
      "--------------------------\n",
      "Epoch 1 :\n",
      "Loss [1.31191251-0.38401437j]\n",
      "--------------------------\n",
      "Epoch 2 :\n",
      "Loss [1.2703908-0.37829933j]\n",
      "--------------------------\n",
      "Epoch 3 :\n",
      "Loss [1.26145066-0.37579408j]\n",
      "--------------------------\n",
      "Epoch 4 :\n",
      "Loss [1.25485388-0.37390879j]\n",
      "--------------------------\n",
      "Epoch 5 :\n",
      "Loss [1.24946178-0.37241191j]\n",
      "--------------------------\n",
      "Epoch 6 :\n",
      "Loss [1.24496222-0.37118432j]\n",
      "--------------------------\n",
      "Epoch 7 :\n",
      "Loss [1.24114541-0.37014687j]\n",
      "--------------------------\n",
      "Epoch 8 :\n",
      "Loss [1.2378584-0.36924457j]\n",
      "--------------------------\n",
      "Epoch 9 :\n",
      "Loss [1.23498719-0.36843793j]\n",
      "--------------------------\n",
      "Epoch 10 :\n",
      "Loss [1.23244525-0.36769759j]\n",
      "--------------------------\n",
      "Epoch 11 :\n",
      "Loss [1.23016584-0.36700087j]\n",
      "--------------------------\n",
      "Epoch 12 :\n",
      "Loss [1.22809663-0.36632947j]\n",
      "--------------------------\n",
      "Epoch 13 :\n",
      "Loss [1.22619598-0.3656679j]\n",
      "--------------------------\n",
      "Epoch 14 :\n",
      "Loss [1.22443028-0.36500229j]\n",
      "--------------------------\n",
      "Epoch 15 :\n",
      "Loss [1.22277202-0.36431953j]\n",
      "--------------------------\n",
      "Epoch 16 :\n",
      "Loss [1.22119848-0.36360655j]\n",
      "--------------------------\n",
      "Epoch 17 :\n",
      "Loss [1.21969073-0.36284966j]\n",
      "--------------------------\n",
      "Epoch 18 :\n",
      "Loss [1.218233-0.36203395j]\n",
      "--------------------------\n",
      "Epoch 19 :\n",
      "Loss [1.21681227-0.3611426j]\n",
      "--------------------------\n",
      "Loss for testing dataset: [0.43496851-0.0560992j]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# 2_1_d neural network model\n",
    "\n",
    "Layer1 = Dense(1,10)\n",
    "Act1 = Sigmoid()\n",
    "\n",
    "Layer2 = Dense(10,5)\n",
    "Act2 = Sigmoid()\n",
    "\n",
    "Layer3 = Dense(5,1)\n",
    "Act3 = Linear()\n",
    "\n",
    "Loss = Mean_Square_Error_loss()\n",
    "\n",
    "Optimizer = SGD(0.001)\n",
    "\n",
    "for epoch in range(20):\n",
    "    #forward\n",
    "    Layer1.forward(x_train)\n",
    "    Act1.forward(Layer1.output)\n",
    "    Layer2.forward(Act1.output)\n",
    "    Act2.forward(Layer2.output)\n",
    "    Layer3.forward(Act2.output)\n",
    "    Act3.forward(Layer3.output)\n",
    "    loss = Loss.forward(Act3.output,y_train)\n",
    "    \n",
    "    print(\"Epoch\", epoch,\":\")\n",
    "    print(\"Loss\", loss)    \n",
    "    print('--------------------------')\n",
    "    \n",
    "    #backward\n",
    "    Loss.backward(Act3.output,y_train)\n",
    "    Act3.backward(Loss.b_output)\n",
    "    Layer3.backward(Act3.b_output)\n",
    "    Act2.backward(Layer3.b_output)\n",
    "    \n",
    "    Layer2.backward(Act2.b_output)\n",
    "    Act1.backward(Layer2.b_output)\n",
    "    Layer1.backward(Act1.b_output)\n",
    "    \n",
    "    #update params\n",
    "    Optimizer.update(Layer1)\n",
    "    Optimizer.update(Layer2)\n",
    "    Optimizer.update(Layer3)\n",
    "    \n",
    "#Testing Step:\n",
    "p = x_test\n",
    "Layer1.forward(p)\n",
    "Act1.forward(Layer1.output)\n",
    "Layer2.forward(Act1.output)\n",
    "Act2.forward(Layer2.output)\n",
    "Layer3.forward(Act2.output)\n",
    "Act3.forward(Layer3.output)\n",
    "a = Act3.output\n",
    "\n",
    "plt.scatter(p,a)\n",
    "\n",
    "loss = Loss.forward(Act3.output,y_test)\n",
    "print(\"Loss for testing dataset:\", loss)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8759ad86",
   "metadata": {},
   "source": [
    "# 2-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "274f821f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Dense:\n",
    "    def __init__(self,n_inputs,n_neurons):\n",
    "        self.w = np.random.randn(n_inputs,n_neurons)   #w\n",
    "        self.b = np.ones([1,n_neurons])    #b\n",
    "        self.weight_history = 0\n",
    "        self.bias_history = 0\n",
    "    \n",
    "    def forward(self,inputs):\n",
    "        self.input = inputs  #p\n",
    "        self.output = np.dot(inputs,self.w)+self.b\n",
    "    \n",
    "    def backward(self,b_input):\n",
    "        self.b_output = np.dot(b_input,self.w.T)\n",
    "        self.g_w = np.dot(self.input.T,b_input)\n",
    "        self.g_b = np.sum(b_input,axis=0,keepdims=True)\n",
    "\n",
    "Data = np.loadtxt('housing_train.txt')\n",
    "Test_Data = np.loadtxt('housing_test.txt')\n",
    "\n",
    "x_train = Data[0:16].T[0:13].T\n",
    "y_train = Data[0:16].T[13].reshape(-1,1)\n",
    "x_test = Data[17:].T[0:13].T\n",
    "y_test = Data[17:].T[13].reshape(-1,1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d7b9da",
   "metadata": {},
   "source": [
    "# 2_2_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2073e09c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 :\n",
      "Loss [1385091.74586252]\n",
      "--------------------------\n",
      "Epoch 1 :\n",
      "Loss [1.79217065e+14]\n",
      "--------------------------\n",
      "Epoch 2 :\n",
      "Loss [2.31956238e+22]\n",
      "--------------------------\n",
      "Epoch 3 :\n",
      "Loss [3.00215313e+30]\n",
      "--------------------------\n",
      "Epoch 4 :\n",
      "Loss [3.88561372e+38]\n",
      "--------------------------\n",
      "Epoch 5 :\n",
      "Loss [5.02905527e+46]\n",
      "--------------------------\n",
      "Epoch 6 :\n",
      "Loss [6.50898383e+54]\n",
      "--------------------------\n",
      "Epoch 7 :\n",
      "Loss [8.42441934e+62]\n",
      "--------------------------\n",
      "Epoch 8 :\n",
      "Loss [1.09035209e+71]\n",
      "--------------------------\n",
      "Epoch 9 :\n",
      "Loss [1.41121617e+79]\n",
      "--------------------------\n",
      "Epoch 10 :\n",
      "Loss [1.82650274e+87]\n",
      "--------------------------\n",
      "Epoch 11 :\n",
      "Loss [2.36399804e+95]\n",
      "--------------------------\n",
      "Epoch 12 :\n",
      "Loss [3.05966512e+103]\n",
      "--------------------------\n",
      "Epoch 13 :\n",
      "Loss [3.9600501e+111]\n",
      "--------------------------\n",
      "Epoch 14 :\n",
      "Loss [5.12539646e+119]\n",
      "--------------------------\n",
      "Epoch 15 :\n",
      "Loss [6.63367588e+127]\n",
      "--------------------------\n",
      "Epoch 16 :\n",
      "Loss [8.58580523e+135]\n",
      "--------------------------\n",
      "Epoch 17 :\n",
      "Loss [1.11123987e+144]\n",
      "--------------------------\n",
      "Epoch 18 :\n",
      "Loss [1.43825072e+152]\n",
      "--------------------------\n",
      "Epoch 19 :\n",
      "Loss [1.8614929e+160]\n",
      "--------------------------\n",
      "Epoch 20 :\n",
      "Loss [2.40928495e+168]\n",
      "--------------------------\n",
      "Epoch 21 :\n",
      "Loss [3.11827887e+176]\n",
      "--------------------------\n",
      "Epoch 22 :\n",
      "Loss [4.03591244e+184]\n",
      "--------------------------\n",
      "Epoch 23 :\n",
      "Loss [5.22358324e+192]\n",
      "--------------------------\n",
      "Epoch 24 :\n",
      "Loss [6.76075665e+200]\n",
      "--------------------------\n",
      "Epoch 25 :\n",
      "Loss [8.75028278e+208]\n",
      "--------------------------\n",
      "Epoch 26 :\n",
      "Loss [1.1325278e+217]\n",
      "--------------------------\n",
      "Epoch 27 :\n",
      "Loss [1.46580317e+225]\n",
      "--------------------------\n",
      "Epoch 28 :\n",
      "Loss [1.89715336e+233]\n",
      "--------------------------\n",
      "Epoch 29 :\n",
      "Loss [2.45543942e+241]\n",
      "--------------------------\n",
      "Epoch 30 :\n",
      "Loss [3.17801548e+249]\n",
      "--------------------------\n",
      "Epoch 31 :\n",
      "Loss [4.11322808e+257]\n",
      "--------------------------\n",
      "Epoch 32 :\n",
      "Loss [5.32365099e+265]\n",
      "--------------------------\n",
      "Epoch 33 :\n",
      "Loss [6.89027189e+273]\n",
      "--------------------------\n",
      "Epoch 34 :\n",
      "Loss [8.9179112e+281]\n",
      "--------------------------\n",
      "Epoch 35 :\n",
      "Loss [1.15422354e+290]\n",
      "--------------------------\n",
      "Epoch 36 :\n",
      "Loss [1.49388344e+298]\n",
      "--------------------------\n",
      "Epoch 37 :\n",
      "Loss [1.93349697e+306]\n",
      "--------------------------\n",
      "Epoch 38 :\n",
      "Loss [inf]\n",
      "--------------------------\n",
      "Epoch 39 :\n",
      "Loss [inf]\n",
      "--------------------------\n",
      "Epoch 40 :\n",
      "Loss [inf]\n",
      "--------------------------\n",
      "Epoch 41 :\n",
      "Loss [inf]\n",
      "--------------------------\n",
      "Epoch 42 :\n",
      "Loss [inf]\n",
      "--------------------------\n",
      "Epoch 43 :\n",
      "Loss [inf]\n",
      "--------------------------\n",
      "Epoch 44 :\n",
      "Loss [inf]\n",
      "--------------------------\n",
      "Epoch 45 :\n",
      "Loss [inf]\n",
      "--------------------------\n",
      "Epoch 46 :\n",
      "Loss [inf]\n",
      "--------------------------\n",
      "Epoch 47 :\n",
      "Loss [inf]\n",
      "--------------------------\n",
      "Epoch 48 :\n",
      "Loss [inf]\n",
      "--------------------------\n",
      "Epoch 49 :\n",
      "Loss [inf]\n",
      "--------------------------\n",
      "Loss for testing data: [inf]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ansar9811291\\AppData\\Local\\Temp\\ipykernel_16088\\2436512996.py:82: RuntimeWarning: overflow encountered in square\n",
      "  return np.mean((y_true-y_predict)**2,axis = 0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1e447522370>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Layer1 = Dense(13,1)\n",
    "Act1 = Linear()\n",
    "Loss = Mean_Square_Error_loss()\n",
    "Optimizer = SGD(0.001)\n",
    "\n",
    "e = []\n",
    "l = []\n",
    "for epoch in range(50):\n",
    "    for i in range(int(len(Data)/16)):\n",
    "        low = 16*i\n",
    "    high = low + 16\n",
    "    x_train = Data[low:high].T[0:13].T\n",
    "    #forward\n",
    "    Layer1.forward(x_train)\n",
    "    Act1.forward(Layer1.output)    \n",
    "    loss = Loss.forward(Act1.output,y_train)\n",
    "    print(\"Epoch\", epoch,\":\")\n",
    "    print(\"Loss\", loss)\n",
    "    print('--------------------------')\n",
    "    \n",
    "    #backward\n",
    "    Loss.backward(Act1.output,y_train)\n",
    "    \n",
    "    Act1.backward(Loss.b_output)\n",
    "    Layer1.backward(Act1.b_output)\n",
    "    \n",
    "    #update params\n",
    "    Optimizer.update(Layer1)\n",
    "            \n",
    "    e.append(epoch)\n",
    "    l.append(loss)\n",
    "    \n",
    "Layer1.forward(x_train)\n",
    "Act1.forward(Layer1.output)    \n",
    "loss = Loss.forward(Act1.output,y_train)\n",
    "print(\"Loss for testing data:\", loss)\n",
    "\n",
    "plt.scatter(e,l)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7e1338",
   "metadata": {},
   "source": [
    "# 2_2_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2834dd6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "loss [32792.61026107]\n",
      "--------------------------\n",
      "epoch 1\n",
      "loss [756.70490583]\n",
      "--------------------------\n",
      "epoch 2\n",
      "loss [711.5939213]\n",
      "--------------------------\n",
      "epoch 3\n",
      "loss [669.32384613]\n",
      "--------------------------\n",
      "epoch 4\n",
      "loss [629.71577122]\n",
      "--------------------------\n",
      "epoch 5\n",
      "loss [592.60205443]\n",
      "--------------------------\n",
      "epoch 6\n",
      "loss [557.82561107]\n",
      "--------------------------\n",
      "epoch 7\n",
      "loss [525.23924901]\n",
      "--------------------------\n",
      "epoch 8\n",
      "loss [494.70504568]\n",
      "--------------------------\n",
      "epoch 9\n",
      "loss [466.09376434]\n",
      "--------------------------\n",
      "epoch 10\n",
      "loss [439.28430706]\n",
      "--------------------------\n",
      "epoch 11\n",
      "loss [414.16320216]\n",
      "--------------------------\n",
      "epoch 12\n",
      "loss [390.62412396]\n",
      "--------------------------\n",
      "epoch 13\n",
      "loss [368.56744275]\n",
      "--------------------------\n",
      "epoch 14\n",
      "loss [347.8998031]\n",
      "--------------------------\n",
      "epoch 15\n",
      "loss [328.53372872]\n",
      "--------------------------\n",
      "epoch 16\n",
      "loss [310.38725224]\n",
      "--------------------------\n",
      "epoch 17\n",
      "loss [293.38356826]\n",
      "--------------------------\n",
      "epoch 18\n",
      "loss [277.45070828]\n",
      "--------------------------\n",
      "epoch 19\n",
      "loss [262.5212361]\n",
      "--------------------------\n",
      "epoch 20\n",
      "loss [248.53196235]\n",
      "--------------------------\n",
      "epoch 21\n",
      "loss [235.42367711]\n",
      "--------------------------\n",
      "epoch 22\n",
      "loss [223.14089924]\n",
      "--------------------------\n",
      "epoch 23\n",
      "loss [211.63164159]\n",
      "--------------------------\n",
      "epoch 24\n",
      "loss [200.84719095]\n",
      "--------------------------\n",
      "epoch 25\n",
      "loss [190.74190187]\n",
      "--------------------------\n",
      "epoch 26\n",
      "loss [181.27300348]\n",
      "--------------------------\n",
      "epoch 27\n",
      "loss [172.40041843]\n",
      "--------------------------\n",
      "epoch 28\n",
      "loss [164.0865933]\n",
      "--------------------------\n",
      "epoch 29\n",
      "loss [156.29633962]\n",
      "--------------------------\n",
      "epoch 30\n",
      "loss [148.99668496]\n",
      "--------------------------\n",
      "epoch 31\n",
      "loss [142.15673335]\n",
      "--------------------------\n",
      "epoch 32\n",
      "loss [135.74753453]\n",
      "--------------------------\n",
      "epoch 33\n",
      "loss [129.74196141]\n",
      "--------------------------\n",
      "epoch 34\n",
      "loss [124.11459527]\n",
      "--------------------------\n",
      "epoch 35\n",
      "loss [118.84161814]\n",
      "--------------------------\n",
      "epoch 36\n",
      "loss [113.90071202]\n",
      "--------------------------\n",
      "epoch 37\n",
      "loss [109.2709644]\n",
      "--------------------------\n",
      "epoch 38\n",
      "loss [104.93277976]\n",
      "--------------------------\n",
      "epoch 39\n",
      "loss [100.86779664]\n",
      "--------------------------\n",
      "epoch 40\n",
      "loss [97.0588099]\n",
      "--------------------------\n",
      "epoch 41\n",
      "loss [93.48969791]\n",
      "--------------------------\n",
      "epoch 42\n",
      "loss [90.14535431]\n",
      "--------------------------\n",
      "epoch 43\n",
      "loss [87.0116241]\n",
      "--------------------------\n",
      "epoch 44\n",
      "loss [84.07524368]\n",
      "--------------------------\n",
      "epoch 45\n",
      "loss [81.32378476]\n",
      "--------------------------\n",
      "epoch 46\n",
      "loss [78.74560171]\n",
      "--------------------------\n",
      "epoch 47\n",
      "loss [76.32978231]\n",
      "--------------------------\n",
      "epoch 48\n",
      "loss [74.06610156]\n",
      "--------------------------\n",
      "epoch 49\n",
      "loss [71.94497837]\n",
      "--------------------------\n",
      "Epoch:0\n",
      "Loss: [722.28200386]\n",
      "--------------------------\n",
      "Epoch:1\n",
      "Loss: [416.30012625]\n",
      "--------------------------\n",
      "Epoch:2\n",
      "Loss: [247.8307584]\n",
      "--------------------------\n",
      "Epoch:3\n",
      "Loss: [155.06069091]\n",
      "--------------------------\n",
      "Epoch:4\n",
      "Loss: [103.96291766]\n",
      "--------------------------\n",
      "Epoch:5\n",
      "Loss: [75.80579916]\n",
      "--------------------------\n",
      "Epoch:6\n",
      "Loss: [60.27768725]\n",
      "--------------------------\n",
      "Epoch:7\n",
      "Loss: [51.70208288]\n",
      "--------------------------\n",
      "Epoch:8\n",
      "Loss: [46.95410861]\n",
      "--------------------------\n",
      "Epoch:9\n",
      "Loss: [44.3135395]\n",
      "--------------------------\n",
      "Epoch:10\n",
      "Loss: [42.8334015]\n",
      "--------------------------\n",
      "Epoch:11\n",
      "Loss: [41.99238864]\n",
      "--------------------------\n",
      "Epoch:12\n",
      "Loss: [41.5035217]\n",
      "--------------------------\n",
      "Epoch:13\n",
      "Loss: [41.20881666]\n",
      "--------------------------\n",
      "Epoch:14\n",
      "Loss: [41.02130054]\n",
      "--------------------------\n",
      "Epoch:15\n",
      "Loss: [40.89309159]\n",
      "--------------------------\n",
      "Epoch:16\n",
      "Loss: [40.79782756]\n",
      "--------------------------\n",
      "Epoch:17\n",
      "Loss: [40.72099263]\n",
      "--------------------------\n",
      "Epoch:18\n",
      "Loss: [40.65459243]\n",
      "--------------------------\n",
      "Epoch:19\n",
      "Loss: [40.59422264]\n",
      "--------------------------\n",
      "Epoch:20\n",
      "Loss: [40.53745529]\n",
      "--------------------------\n",
      "Epoch:21\n",
      "Loss: [40.48295043]\n",
      "--------------------------\n",
      "Epoch:22\n",
      "Loss: [40.42996708]\n",
      "--------------------------\n",
      "Epoch:23\n",
      "Loss: [40.37809405]\n",
      "--------------------------\n",
      "Epoch:24\n",
      "Loss: [40.32710174]\n",
      "--------------------------\n",
      "Epoch:25\n",
      "Loss: [40.27686052]\n",
      "--------------------------\n",
      "Epoch:26\n",
      "Loss: [40.22729588]\n",
      "--------------------------\n",
      "Epoch:27\n",
      "Loss: [40.17836363]\n",
      "--------------------------\n",
      "Epoch:28\n",
      "Loss: [40.13003635]\n",
      "--------------------------\n",
      "Epoch:29\n",
      "Loss: [40.08229585]\n",
      "--------------------------\n",
      "Epoch:30\n",
      "Loss: [40.03512909]\n",
      "--------------------------\n",
      "Epoch:31\n",
      "Loss: [39.98852583]\n",
      "--------------------------\n",
      "Epoch:32\n",
      "Loss: [39.94247741]\n",
      "--------------------------\n",
      "Epoch:33\n",
      "Loss: [39.89697606]\n",
      "--------------------------\n",
      "Epoch:34\n",
      "Loss: [39.85201443]\n",
      "--------------------------\n",
      "Epoch:35\n",
      "Loss: [39.80758533]\n",
      "--------------------------\n",
      "Epoch:36\n",
      "Loss: [39.76368145]\n",
      "--------------------------\n",
      "Epoch:37\n",
      "Loss: [39.72029495]\n",
      "--------------------------\n",
      "Epoch:38\n",
      "Loss: [39.67741645]\n",
      "--------------------------\n",
      "Epoch:39\n",
      "Loss: [39.63503204]\n",
      "--------------------------\n",
      "Epoch:40\n",
      "Loss: [39.59311047]\n",
      "--------------------------\n",
      "Epoch:41\n",
      "Loss: [39.55151366]\n",
      "--------------------------\n",
      "Epoch:42\n",
      "Loss: [39.50779339]\n",
      "--------------------------\n",
      "Epoch:43\n",
      "Loss: [38.20857495]\n",
      "--------------------------\n",
      "Epoch:44\n",
      "Loss: [40.58551344]\n",
      "--------------------------\n",
      "Epoch:45\n",
      "Loss: [40.48647575]\n",
      "--------------------------\n",
      "Epoch:46\n",
      "Loss: [40.43626918]\n",
      "--------------------------\n",
      "Epoch:47\n",
      "Loss: [40.41081726]\n",
      "--------------------------\n",
      "Epoch:48\n",
      "Loss: [40.39791457]\n",
      "--------------------------\n",
      "Epoch:49\n",
      "Loss: [40.39137362]\n",
      "--------------------------\n",
      "epoch 0\n",
      "loss [456.72628292]\n",
      "--------------------------\n",
      "epoch 1\n",
      "loss [352.30839201]\n",
      "--------------------------\n",
      "epoch 2\n",
      "loss [274.09051382]\n",
      "--------------------------\n",
      "epoch 3\n",
      "loss [215.497831]\n",
      "--------------------------\n",
      "epoch 4\n",
      "loss [171.6059434]\n",
      "--------------------------\n",
      "epoch 5\n",
      "loss [138.72630142]\n",
      "--------------------------\n",
      "epoch 6\n",
      "loss [114.0957292]\n",
      "--------------------------\n",
      "epoch 7\n",
      "loss [95.64438666]\n",
      "--------------------------\n",
      "epoch 8\n",
      "loss [81.82179766]\n",
      "--------------------------\n",
      "epoch 9\n",
      "loss [71.46653128]\n",
      "--------------------------\n",
      "epoch 10\n",
      "loss [63.70858256]\n",
      "--------------------------\n",
      "epoch 11\n",
      "loss [57.89624795]\n",
      "--------------------------\n",
      "epoch 12\n",
      "loss [53.54134907]\n",
      "--------------------------\n",
      "epoch 13\n",
      "loss [50.27820105]\n",
      "--------------------------\n",
      "epoch 14\n",
      "loss [47.83287644]\n",
      "--------------------------\n",
      "epoch 15\n",
      "loss [46.00018141]\n",
      "--------------------------\n",
      "epoch 16\n",
      "loss [44.62640917]\n",
      "--------------------------\n",
      "epoch 17\n",
      "loss [43.59642082]\n",
      "--------------------------\n",
      "epoch 18\n",
      "loss [42.82396789]\n",
      "--------------------------\n",
      "epoch 19\n",
      "loss [42.24444318]\n",
      "--------------------------\n",
      "epoch 20\n",
      "loss [41.80945052]\n",
      "--------------------------\n",
      "epoch 21\n",
      "loss [41.48273709]\n",
      "--------------------------\n",
      "epoch 22\n",
      "loss [41.23714647]\n",
      "--------------------------\n",
      "epoch 23\n",
      "loss [41.05233609]\n",
      "--------------------------\n",
      "epoch 24\n",
      "loss [40.91306757]\n",
      "--------------------------\n",
      "epoch 25\n",
      "loss [40.80792597]\n",
      "--------------------------\n",
      "epoch 26\n",
      "loss [40.72836036]\n",
      "--------------------------\n",
      "epoch 27\n",
      "loss [40.66796526]\n",
      "--------------------------\n",
      "epoch 28\n",
      "loss [40.62194227]\n",
      "--------------------------\n",
      "epoch 29\n",
      "loss [40.58669681]\n",
      "--------------------------\n",
      "epoch 30\n",
      "loss [40.5595361]\n",
      "--------------------------\n",
      "epoch 31\n",
      "loss [40.53844284]\n",
      "--------------------------\n",
      "epoch 32\n",
      "loss [40.52190576]\n",
      "--------------------------\n",
      "epoch 33\n",
      "loss [40.50879261]\n",
      "--------------------------\n",
      "epoch 34\n",
      "loss [40.4982551]\n",
      "--------------------------\n",
      "epoch 35\n",
      "loss [40.48965761]\n",
      "--------------------------\n",
      "epoch 36\n",
      "loss [40.48252388]\n",
      "--------------------------\n",
      "epoch 37\n",
      "loss [40.47649697]\n",
      "--------------------------\n",
      "epoch 38\n",
      "loss [40.47130936]\n",
      "--------------------------\n",
      "epoch 39\n",
      "loss [40.4667605]\n",
      "--------------------------\n",
      "epoch 40\n",
      "loss [40.46270002]\n",
      "--------------------------\n",
      "epoch 41\n",
      "loss [40.45901512]\n",
      "--------------------------\n",
      "epoch 42\n",
      "loss [40.45562117]\n",
      "--------------------------\n",
      "epoch 43\n",
      "loss [40.45245462]\n",
      "--------------------------\n",
      "epoch 44\n",
      "loss [40.44946773]\n",
      "--------------------------\n",
      "epoch 45\n",
      "loss [40.44662461]\n",
      "--------------------------\n",
      "epoch 46\n",
      "loss [40.44389823]\n",
      "--------------------------\n",
      "epoch 47\n",
      "loss [40.4412682]\n",
      "--------------------------\n",
      "epoch 48\n",
      "loss [40.43871912]\n",
      "--------------------------\n",
      "epoch 49\n",
      "loss [40.43623933]\n",
      "--------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ansar9811291\\AppData\\Local\\Temp\\ipykernel_16088\\2436512996.py:39: RuntimeWarning: overflow encountered in exp\n",
      "  self.output = 1/(1+np.exp(-inputs))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1e4475b64f0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Layer1 = Dense(13,5)\n",
    "Act1 = ReLU()\n",
    "Layer2 = Dense(5,1)\n",
    "Act2 = Linear()\n",
    "Loss = Mean_Square_Error_loss()\n",
    "Optimizer = SGD(0.001)\n",
    "\n",
    "e = []\n",
    "l = []\n",
    "for epoch in range(50):\n",
    "    #forward\n",
    "    Layer1.forward(x_train)\n",
    "    Act1.forward(Layer1.output)\n",
    "    Layer2.forward(Act1.output)\n",
    "    Act2.forward(Layer2.output)\n",
    "    loss = Loss.forward(Act2.output,y_train)\n",
    "        \n",
    "    print(\"epoch\",epoch)\n",
    "    print(\"loss\",loss)\n",
    "    print('--------------------------')\n",
    "    \n",
    "    #backward\n",
    "    Loss.backward(Act2.output,y_train)\n",
    "    Act2.backward(Loss.b_output)\n",
    "    Layer2.backward(Act2.b_output)\n",
    "    Act1.backward(Layer2.b_output)\n",
    "    Layer1.backward(Act1.b_output)\n",
    "    \n",
    "    #update params\n",
    "    Optimizer.update(Layer1)\n",
    "    Optimizer.update(Layer2)\n",
    "    e.append(epoch)\n",
    "    l.append(loss)\n",
    "    \n",
    "plt.scatter(e,l)\n",
    "\n",
    "#2-2-c\n",
    "Layer1 = Dense(13,15)\n",
    "Act1 = Sigmoid()\n",
    "Layer2 = Dense(15,1)\n",
    "Act2 = Linear()\n",
    "Loss = Mean_Square_Error_loss()\n",
    "Optimizer = SGD(0.001)\n",
    "\n",
    "e = []\n",
    "l = []\n",
    "for epoch in range(50):\n",
    "    #forward\n",
    "    Layer1.forward(x_train)\n",
    "    Act1.forward(Layer1.output)\n",
    "    Layer2.forward(Act1.output)\n",
    "    Act2.forward(Layer2.output)\n",
    "    loss = Loss.forward(Act2.output,y_train)\n",
    "    \n",
    "    \n",
    "    # Report\n",
    "    #y_predict = np.argmax(Act2.output,axis = 1)\n",
    "    #accuracy = np.mean(y_train == y_predict)\n",
    "    print(f'Epoch:{epoch}')\n",
    "    print(f'Loss: {loss}')\n",
    "    #print(f'Accuracy: {accuracy}')\n",
    "    print('--------------------------')\n",
    "    \n",
    "    #backward\n",
    "    Loss.backward(Act2.output,y_train)\n",
    "    Act2.backward(Loss.b_output)\n",
    "    Layer2.backward(Act2.b_output)\n",
    "    Act1.backward(Layer2.b_output)\n",
    "    Layer1.backward(Act1.b_output)\n",
    "    \n",
    "    #update params\n",
    "    Optimizer.update(Layer1)\n",
    "    Optimizer.update(Layer2)\n",
    "    e.append(epoch)\n",
    "    l.append(loss)\n",
    "    \n",
    "plt.scatter(e,l)\n",
    "\n",
    "#2_2_d\n",
    "Layer1 = Dense(13,10)\n",
    "Act1 = ReLU()\n",
    "Layer2 = Dense(10,5)\n",
    "Act2 = Sigmoid()\n",
    "Layer3 = Dense(5,1)\n",
    "Act3 = Linear()\n",
    "Loss = Mean_Square_Error_loss()\n",
    "Optimizer = SGD(0.001)\n",
    "\n",
    "e = []\n",
    "l = []\n",
    "for epoch in range(50):\n",
    "    #forward\n",
    "    Layer1.forward(x_train)\n",
    "    Act1.forward(Layer1.output)\n",
    "    Layer2.forward(Act1.output)\n",
    "    Act2.forward(Layer2.output)\n",
    "    Layer3.forward(Act2.output)\n",
    "    Act3.forward(Layer3.output)\n",
    "    loss = Loss.forward(Act3.output,y_train)\n",
    "        \n",
    "    # Report\n",
    "    print(\"epoch\",epoch)\n",
    "    print(\"loss\", loss)\n",
    "    print('--------------------------')\n",
    "    \n",
    "    #backward\n",
    "    Loss.backward(Act3.output,y_train)\n",
    "    Act3.backward(Loss.b_output)\n",
    "    Layer3.backward(Act3.b_output)\n",
    "    Act2.backward(Layer3.b_output)\n",
    "    \n",
    "    Layer2.backward(Act2.b_output)\n",
    "    Act1.backward(Layer2.b_output)\n",
    "    Layer1.backward(Act1.b_output)\n",
    "    \n",
    "    #update params\n",
    "    Optimizer.update(Layer1)\n",
    "    Optimizer.update(Layer2)\n",
    "    Optimizer.update(Layer3)\n",
    "    e.append(epoch)\n",
    "    l.append(loss)\n",
    "    \n",
    "plt.scatter(e,l)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6dc4ae5",
   "metadata": {},
   "source": [
    "# 2-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fae4329",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSprop():\n",
    "    def __init__(self, gamma = 0.8,learning_rate = 0.01):\n",
    "        self.v_dw = 0\n",
    "        self.v_db = 0\n",
    "        self.gamma = gamma\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def update(self, layer):\n",
    "        ## dw, db are from current minibatch\n",
    "        ## momentum beta 1\n",
    "        # *** weights *** #\n",
    "        \n",
    "        self.v_dw = self.gamma * self.v_dw + (1 - self.gamma) * layer.g_w ** 2\n",
    "        self.v_db = self.gamma * self.v_db + (1 - self.gamma) * layer.g_b ** 2\n",
    "\n",
    "        layer.w -= (self.learning_rate / (np.sqrt( self.v_dw+ 1e-08))) * layer.g_w\n",
    "        layer.b -= (self.learning_rate / (np.sqrt(self.v_db + 1e-08))) * layer.g_b\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "432c3e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdamOptim():\n",
    "    def __init__(self, eta=0.01, beta1=0.9, beta2=0.999, epsilon=1e-8):\n",
    "        self.m_dw, self.v_dw = 0, 0\n",
    "        self.m_db, self.v_db = 0, 0\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.epsilon = epsilon\n",
    "        self.eta = eta\n",
    "\n",
    "    def update(self, t, layer):\n",
    "        ## dw, db are from current minibatch\n",
    "        ## momentum beta 1\n",
    "        # *** weights *** #\n",
    "        \n",
    "        self.m_dw = self.beta1*(self.m_dw) + (1-self.beta1)* layer.g_w\n",
    "        # *** biases *** #\n",
    "        self.m_db = self.beta1*(self.m_db) + (1-self.beta1)* layer.g_b\n",
    "\n",
    "        ## rms beta 2\n",
    "        # *** weights *** #\n",
    "        self.v_dw = self.beta2*(self.v_dw) + (1-self.beta2)*(layer.g_w**2)\n",
    "        # *** biases *** #\n",
    "        self.v_db = self.beta2*(self.v_db) + (1-self.beta2)*(layer.g_b)\n",
    "\n",
    "        ## bias correction\n",
    "        m_dw_corr = self.m_dw/(1-self.beta1**t)\n",
    "        m_db_corr = self.m_db/(1-self.beta1**t)\n",
    "        v_dw_corr = self.v_dw/(1-self.beta2**t)\n",
    "        v_db_corr = self.v_db/(1-self.beta2**t)\n",
    "        \n",
    "        print(m_dw_corr)\n",
    "        \n",
    "        print(v_dw_corr)\n",
    "        print((np.sqrt(v_dw_corr)+self.epsilon))\n",
    "\n",
    "        ## update weights and biases\n",
    "        layer.w = layer.w - self.eta*(m_dw_corr/(np.sqrt(v_dw_corr)+self.epsilon))\n",
    "        layer.b = layer.b - self.eta*(m_db_corr/(np.sqrt(v_db_corr)+self.epsilon))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9efdf60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 :\n",
      "Loss [5150.34972656]\n",
      "--------------------------\n",
      "[[inf]\n",
      " [nan]\n",
      " [inf]\n",
      " [nan]\n",
      " [inf]\n",
      " [inf]\n",
      " [inf]\n",
      " [inf]\n",
      " [inf]\n",
      " [inf]\n",
      " [inf]\n",
      " [inf]\n",
      " [inf]]\n",
      "[[inf]\n",
      " [nan]\n",
      " [inf]\n",
      " [nan]\n",
      " [inf]\n",
      " [inf]\n",
      " [inf]\n",
      " [inf]\n",
      " [inf]\n",
      " [inf]\n",
      " [inf]\n",
      " [inf]\n",
      " [inf]]\n",
      "[[inf]\n",
      " [nan]\n",
      " [inf]\n",
      " [nan]\n",
      " [inf]\n",
      " [inf]\n",
      " [inf]\n",
      " [inf]\n",
      " [inf]\n",
      " [inf]\n",
      " [inf]\n",
      " [inf]\n",
      " [inf]]\n",
      "Epoch 1 :\n",
      "Loss [nan]\n",
      "--------------------------\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Epoch 2 :\n",
      "Loss [nan]\n",
      "--------------------------\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Epoch 3 :\n",
      "Loss [nan]\n",
      "--------------------------\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Epoch 4 :\n",
      "Loss [nan]\n",
      "--------------------------\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Epoch 5 :\n",
      "Loss [nan]\n",
      "--------------------------\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Epoch 6 :\n",
      "Loss [nan]\n",
      "--------------------------\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Epoch 7 :\n",
      "Loss [nan]\n",
      "--------------------------\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Epoch 8 :\n",
      "Loss [nan]\n",
      "--------------------------\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Epoch 9 :\n",
      "Loss [nan]\n",
      "--------------------------\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Epoch 10 :\n",
      "Loss [nan]\n",
      "--------------------------\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Epoch 11 :\n",
      "Loss [nan]\n",
      "--------------------------\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Epoch 12 :\n",
      "Loss [nan]\n",
      "--------------------------\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Epoch 13 :\n",
      "Loss [nan]\n",
      "--------------------------\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Epoch 14 :\n",
      "Loss [nan]\n",
      "--------------------------\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Epoch 15 :\n",
      "Loss [nan]\n",
      "--------------------------\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Epoch 16 :\n",
      "Loss [nan]\n",
      "--------------------------\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Epoch 17 :\n",
      "Loss [nan]\n",
      "--------------------------\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Epoch 18 :\n",
      "Loss [nan]\n",
      "--------------------------\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Epoch 19 :\n",
      "Loss [nan]\n",
      "--------------------------\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Epoch 20 :\n",
      "Loss [nan]\n",
      "--------------------------\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Epoch 21 :\n",
      "Loss [nan]\n",
      "--------------------------\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Epoch 22 :\n",
      "Loss [nan]\n",
      "--------------------------\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Epoch 23 :\n",
      "Loss [nan]\n",
      "--------------------------\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Epoch 24 :\n",
      "Loss [nan]\n",
      "--------------------------\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Epoch 25 :\n",
      "Loss [nan]\n",
      "--------------------------\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Epoch 26 :\n",
      "Loss [nan]\n",
      "--------------------------\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Epoch 27 :\n",
      "Loss [nan]\n",
      "--------------------------\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Epoch 28 :\n",
      "Loss [nan]\n",
      "--------------------------\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Epoch 29 :\n",
      "Loss [nan]\n",
      "--------------------------\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Epoch 30 :\n",
      "Loss [nan]\n",
      "--------------------------\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Epoch 31 :\n",
      "Loss [nan]\n",
      "--------------------------\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Epoch 32 :\n",
      "Loss [nan]\n",
      "--------------------------\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Epoch 33 :\n",
      "Loss [nan]\n",
      "--------------------------\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Epoch 34 :\n",
      "Loss [nan]\n",
      "--------------------------\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Epoch 35 :\n",
      "Loss [nan]\n",
      "--------------------------\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Epoch 36 :\n",
      "Loss [nan]\n",
      "--------------------------\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Epoch 37 :\n",
      "Loss [nan]\n",
      "--------------------------\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Epoch 38 :\n",
      "Loss [nan]\n",
      "--------------------------\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Epoch 39 :\n",
      "Loss [nan]\n",
      "--------------------------\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Epoch 40 :\n",
      "Loss [nan]\n",
      "--------------------------\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Epoch 41 :\n",
      "Loss [nan]\n",
      "--------------------------\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Epoch 42 :\n",
      "Loss [nan]\n",
      "--------------------------\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Epoch 43 :\n",
      "Loss [nan]\n",
      "--------------------------\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Epoch 44 :\n",
      "Loss [nan]\n",
      "--------------------------\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Epoch 45 :\n",
      "Loss [nan]\n",
      "--------------------------\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Epoch 46 :\n",
      "Loss [nan]\n",
      "--------------------------\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Epoch 47 :\n",
      "Loss [nan]\n",
      "--------------------------\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Epoch 48 :\n",
      "Loss [nan]\n",
      "--------------------------\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Epoch 49 :\n",
      "Loss [nan]\n",
      "--------------------------\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Loss for testing data: [nan]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ansar9811291\\AppData\\Local\\Temp\\ipykernel_16088\\4012035994.py:26: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  m_dw_corr = self.m_dw/(1-self.beta1**t)\n",
      "C:\\Users\\Ansar9811291\\AppData\\Local\\Temp\\ipykernel_16088\\4012035994.py:26: RuntimeWarning: invalid value encountered in true_divide\n",
      "  m_dw_corr = self.m_dw/(1-self.beta1**t)\n",
      "C:\\Users\\Ansar9811291\\AppData\\Local\\Temp\\ipykernel_16088\\4012035994.py:27: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  m_db_corr = self.m_db/(1-self.beta1**t)\n",
      "C:\\Users\\Ansar9811291\\AppData\\Local\\Temp\\ipykernel_16088\\4012035994.py:28: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  v_dw_corr = self.v_dw/(1-self.beta2**t)\n",
      "C:\\Users\\Ansar9811291\\AppData\\Local\\Temp\\ipykernel_16088\\4012035994.py:28: RuntimeWarning: invalid value encountered in true_divide\n",
      "  v_dw_corr = self.v_dw/(1-self.beta2**t)\n",
      "C:\\Users\\Ansar9811291\\AppData\\Local\\Temp\\ipykernel_16088\\4012035994.py:29: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  v_db_corr = self.v_db/(1-self.beta2**t)\n",
      "C:\\Users\\Ansar9811291\\AppData\\Local\\Temp\\ipykernel_16088\\4012035994.py:37: RuntimeWarning: invalid value encountered in true_divide\n",
      "  layer.w = layer.w - self.eta*(m_dw_corr/(np.sqrt(v_dw_corr)+self.epsilon))\n",
      "C:\\Users\\Ansar9811291\\AppData\\Local\\Temp\\ipykernel_16088\\4012035994.py:38: RuntimeWarning: invalid value encountered in true_divide\n",
      "  layer.b = layer.b - self.eta*(m_db_corr/(np.sqrt(v_db_corr)+self.epsilon))\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjAAAAGdCAYAAAAMm0nCAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAnK0lEQVR4nO3df1TVdYL/8dcF5II/LqghF0Y0HRPF0SbtiMzJmo4saFSu6+ZKZO2s5dDYVkwaueMqOueMs/1Yc5sxt9MUs7vuFnZ23ElTI0nNQC1mUND0qGHowIWSuBdNUfH9/WO+fLabP5abIL7x+Tjnc+x+Pu/P574/n6Pd5/lw78VljDECAACwSFhXTwAAACBUBAwAALAOAQMAAKxDwAAAAOsQMAAAwDoEDAAAsA4BAwAArEPAAAAA60R09QQ6y/nz51VbW6s+ffrI5XJ19XQAAEA7GGPU3NysxMREhYVd+j5Ltw2Y2tpaJSUldfU0AADAt3D06FENHDjwktu7bcD06dNH0p8vgMfj6eLZAACA9ggEAkpKSnJexy+l2wZM24+NPB4PAQMAgGX+r7d/8CZeAABgHQIGAABYh4ABAADWIWAAAIB1CBgAAGAdAgYAAFiHgAEAANYhYAAAgHUIGAAAYB0CBgAAWIeAAQAA1iFgAACAdQgYAABgHQIGAABYJ6SAKSgokMvlClpGjBhxwThjjKZMmSKXy6W1a9cGbaupqVFWVpZ69uypAQMGaP78+Tp37lzQmC1btmjs2LFyu90aNmyYCgsLQz4xAADQfUWEusOoUaP03nvv/e8BIi48xIsvviiXy3XB+tbWVmVlZcnr9aq0tFR1dXV68MEH1aNHD/3iF7+QJFVXVysrK0u5ublavXq1Nm/erIcfflgJCQnKzMwMdboAAKAbCjlgIiIi5PV6L7m9oqJCL7zwgj7++GMlJCQEbXv33Xe1b98+vffee4qPj9f3v/99/fznP1d+fr4KCgoUGRmpVatWaciQIXrhhRckSSNHjtT27du1fPlyAgYAAEj6Fu+BOXjwoBITEzV06FDl5OSopqbG2fbVV1/p/vvv169//euLRk5ZWZlGjx6t+Ph4Z11mZqYCgYD27t3rjElPTw/aLzMzU2VlZaFOFQAAdFMh3YFJTU1VYWGhkpOTVVdXpyVLlmjixImqqqpSnz59lJeXpx/84AeaOnXqRff3+XxB8SLJeezz+S47JhAI6NSpU4qOjr7osVtaWtTS0uI8DgQCoZwaAACwSEgBM2XKFOe/x4wZo9TUVA0ePFhFRUWKi4tTSUmJ/vjHP3b4JNtj2bJlWrJkSZc8NwAAuLqu6GPUsbGxGj58uA4dOqSSkhIdPnxYsbGxioiIcN7cO336dP3whz+UJHm9XtXX1wcdo+1x24+cLjXG4/Fc8u6LJC1YsEB+v99Zjh49eiWnBgAArmFXFDAnTpzQ4cOHlZCQoGeeeUZ79uxRRUWFs0jS8uXL9frrr0uS0tLSVFlZqYaGBucYxcXF8ng8SklJccZs3rw56HmKi4uVlpZ22bm43W55PJ6gBQAAdE8h/Qhp3rx5uueeezR48GDV1tZq8eLFCg8PV3Z2tuLi4i76xt1BgwZpyJAhkqSMjAylpKRo1qxZevbZZ+Xz+bRw4ULNnTtXbrdbkpSbm6tf/epXevrpp/V3f/d3KikpUVFRkdavX98BpwsAALqDkALm2LFjys7O1vHjxxUXF6fbbrtNO3bsUFxcXLv2Dw8P17p16/Too48qLS1NvXr10kMPPaSlS5c6Y4YMGaL169crLy9PK1as0MCBA/Xqq6/yEWoAAOBwGWNMV0+iMwQCAcXExMjv9/PjJAAALNHe129+FxIAALAOAQMAAKxDwAAAAOsQMAAAwDoEDAAAsA4BAwAArEPAAAAA6xAwAADAOgQMAACwDgEDAACsQ8AAAADrEDAAAMA6BAwAALAOAQMAAKxDwAAAAOsQMAAAwDoEDAAAsA4BAwAArEPAAAAA6xAwAADAOgQMAACwDgEDAACsQ8AAAADrEDAAAMA6BAwAALAOAQMAAKxDwAAAAOsQMAAAwDoEDAAAsA4BAwAArEPAAAAA6xAwAADAOgQMAACwDgEDAACsQ8AAAADrEDAAAMA6BAwAALAOAQMAAKxDwAAAAOsQMAAAwDoEDAAAsA4BAwAArEPAAAAA6xAwAADAOgQMAACwDgEDAACsQ8AAAADrEDAAAMA6BAwAALAOAQMAAKxDwAAAAOsQMAAAwDoEDAAAsA4BAwAArEPAAAAA64QUMAUFBXK5XEHLiBEjnO0//vGP9d3vflfR0dGKi4vT1KlTtX///qBj1NTUKCsrSz179tSAAQM0f/58nTt3LmjMli1bNHbsWLndbg0bNkyFhYXf/gwBAEC3E/IdmFGjRqmurs5Ztm/f7mwbN26cXn/9dX3yySfatGmTjDHKyMhQa2urJKm1tVVZWVk6c+aMSktL9dvf/laFhYVatGiRc4zq6mplZWXpzjvvVEVFhZ588kk9/PDD2rRpUwecLgAA6A5cxhjT3sEFBQVau3atKioq2jV+z549uvnmm3Xo0CF997vf1YYNG3T33XertrZW8fHxkqRVq1YpPz9fn3/+uSIjI5Wfn6/169erqqrKOc7MmTPV1NSkjRs3tvvEAoGAYmJi5Pf75fF42r0fAADoOu19/Q75DszBgweVmJiooUOHKicnRzU1NRcdd/LkSb3++usaMmSIkpKSJEllZWUaPXq0Ey+SlJmZqUAgoL179zpj0tPTg46VmZmpsrKyy86rpaVFgUAgaAEAAN1TSAGTmpqqwsJCbdy4US+//LKqq6s1ceJENTc3O2NWrlyp3r17q3fv3tqwYYOKi4sVGRkpSfL5fEHxIsl57PP5LjsmEAjo1KlTl5zbsmXLFBMT4yxt0QQAALqfkAJmypQpuu+++zRmzBhlZmbqnXfeUVNTk4qKipwxOTk5+uMf/6itW7dq+PDhmjFjhk6fPt3hE/+mBQsWyO/3O8vRo0c7/TkBAEDXiLiSnWNjYzV8+HAdOnTIWdd2B+Smm27ShAkT1LdvX/3ud79Tdna2vF6vdu3aFXSM+vp6SZLX63X+bFv39TEej0fR0dGXnIvb7Zbb7b6S0wEAAJa4ou+BOXHihA4fPqyEhISLbjfGyBijlpYWSVJaWpoqKyvV0NDgjCkuLpbH41FKSoozZvPmzUHHKS4uVlpa2pVMFQAAdCMhBcy8efO0detWHTlyRKWlpZo2bZrCw8OVnZ2tTz/9VMuWLVN5eblqampUWlqq++67T9HR0brrrrskSRkZGUpJSdGsWbO0e/dubdq0SQsXLtTcuXOduye5ubn69NNP9fTTT2v//v1auXKlioqKlJeX1/FnDwAArBRSwBw7dkzZ2dlKTk7WjBkz1L9/f+3YsUNxcXGKiorSBx98oLvuukvDhg3T3/zN36hPnz4qLS3VgAEDJEnh4eFat26dwsPDlZaWpgceeEAPPvigli5d6jzHkCFDtH79ehUXF+vmm2/WCy+8oFdffVWZmZkde+YAAMBaIX0PjE34HhgAAOzTad8DAwAA0NUIGAAAYB0CBgAAWIeAAQAA1iFgAACAdQgYAABgHQIGAABYh4ABAADWIWAAAIB1CBgAAGAdAgYAAFiHgAEAANYhYAAAgHUIGAAAYB0CBgAAWIeAAQAA1iFgAACAdQgYAABgHQIGAABYh4ABAADWIWAAAIB1CBgAAGAdAgYAAFiHgAEAANYhYAAAgHUIGAAAYB0CBgAAWIeAAQAA1iFgAACAdQgYAABgHQIGAABYh4ABAADWIWAAAIB1CBgAAGAdAgYAAFiHgAEAANYhYAAAgHUIGAAAYB0CBgAAWIeAAQAA1iFgAACAdQgYAABgHQIGAABYh4ABAADWIWAAAIB1CBgAAGAdAgYAAFiHgAEAANYhYAAAgHUIGAAAYB0CBgAAWIeAAQAA1iFgAACAdQgYAABgnZACpqCgQC6XK2gZMWKEJKmxsVF///d/r+TkZEVHR2vQoEF6/PHH5ff7g45RU1OjrKws9ezZUwMGDND8+fN17ty5oDFbtmzR2LFj5Xa7NWzYMBUWFl7ZWQIAgG4lItQdRo0apffee+9/DxDx50PU1taqtrZWzz//vFJSUvTZZ58pNzdXtbW1euuttyRJra2tysrKktfrVWlpqerq6vTggw+qR48e+sUvfiFJqq6uVlZWlnJzc7V69Wpt3rxZDz/8sBISEpSZmdkR5wwAACznMsaY9g4uKCjQ2rVrVVFR0a7xa9as0QMPPKCTJ08qIiJCGzZs0N13363a2lrFx8dLklatWqX8/Hx9/vnnioyMVH5+vtavX6+qqirnODNnzlRTU5M2btzY7hMLBAKKiYmR3++Xx+Np934AAKDrtPf1O+T3wBw8eFCJiYkaOnSocnJyVFNTc8mxbU/edpemrKxMo0ePduJFkjIzMxUIBLR3715nTHp6etBxMjMzVVZWdtl5tbS0KBAIBC0AAKB7CilgUlNTVVhYqI0bN+rll19WdXW1Jk6cqObm5gvGfvHFF/r5z3+uOXPmOOt8Pl9QvEhyHvt8vsuOCQQCOnXq1CXntmzZMsXExDhLUlJSKKcGAAAsElLATJkyRffdd5/GjBmjzMxMvfPOO2pqalJRUVHQuEAgoKysLKWkpKigoKAj53tJCxYskN/vd5ajR49elecFAABXX8hv4v262NhYDR8+XIcOHXLWNTc3a/LkyerTp49+97vfqUePHs42r9erXbt2BR2jvr7e2db2Z9u6r4/xeDyKjo6+5FzcbrfcbveVnA4AALDEFX0PzIkTJ3T48GElJCRI+vOdl4yMDEVGRur3v/+9oqKigsanpaWpsrJSDQ0Nzrri4mJ5PB6lpKQ4YzZv3hy0X3FxsdLS0q5kqgAAoBsJKWDmzZunrVu36siRIyotLdW0adMUHh6u7OxsJ15Onjyp3/zmNwoEAvL5fPL5fGptbZUkZWRkKCUlRbNmzdLu3bu1adMmLVy4UHPnznXunuTm5urTTz/V008/rf3792vlypUqKipSXl5ex589AACwUkg/Qjp27Jiys7N1/PhxxcXF6bbbbtOOHTsUFxenLVu2aOfOnZKkYcOGBe1XXV2tG2+8UeHh4Vq3bp0effRRpaWlqVevXnrooYe0dOlSZ+yQIUO0fv165eXlacWKFRo4cKBeffVVvgMGAAA4QvoeGJvwPTAAANin074HBgAAoKsRMAAAwDoEDAAAsA4BAwAArEPAAAAA6xAwAADAOgQMAACwDgEDAACsQ8AAAADrEDAAAMA6BAwAALAOAQMAAKxDwAAAAOsQMAAAwDoEDAAAsA4BAwAArEPAAAAA6xAwAADAOgQMAACwDgEDAACsE9HVEwCAULSeN9pV3aiG5tMa0CdK44f0U3iYq6unBeAqI2AAWGNjVZ2WvL1Pdf7TzrqEmCgtvidFk7+X0IUzA3C18SMkAFbYWFWnR//jD0HxIkk+/2k9+h9/0Maqui6aGYCuQMAAuOa1njda8vY+mYtsa1u35O19aj1/sREAuiMCBsA1b1d14wV3Xr7OSKrzn9au6sarNykAXYqAAXDNa2i+dLx8m3EA7EfAALjmDegT1aHjANiPgAFwzRs/pJ8SYqJ0qQ9Lu/TnTyONH9Lvak4LQBciYABc88LDXFp8T4okXRAxbY8X35PC98EA1xECBoAVJn8vQS8/MFbemOAfE3ljovTyA2P5HhjgOsMX2QGwxuTvJegvUrx8Ey8AAgaAXcLDXEr7bv+ungaALsaPkAAAgHUIGAAAYB0CBgAAWIeAAQAA1iFgAACAdQgYAABgHQIGAABYh4ABAADWIWAAAIB1CBgAAGAdAgYAAFiHgAEAANYhYAAAgHUIGAAAYB0CBgAAWIeAAQAA1iFgAACAdQgYAABgHQIGAABYh4ABAADWIWAAAIB1CBgAAGCdkAKmoKBALpcraBkxYoSz/ZVXXtEPf/hDeTweuVwuNTU1XXCMxsZG5eTkyOPxKDY2VrNnz9aJEyeCxuzZs0cTJ05UVFSUkpKS9Oyzz367swMAAN1SyHdgRo0apbq6OmfZvn27s+2rr77S5MmT9Q//8A+X3D8nJ0d79+5VcXGx1q1bp23btmnOnDnO9kAgoIyMDA0ePFjl5eV67rnnVFBQoFdeeSXUqQIAgG4qIuQdIiLk9Xovuu3JJ5+UJG3ZsuWi2z/55BNt3LhRH330kW699VZJ0ksvvaS77rpLzz//vBITE7V69WqdOXNGr732miIjIzVq1ChVVFTon//5n4NCBwAAXL9CvgNz8OBBJSYmaujQocrJyVFNTU279y0rK1NsbKwTL5KUnp6usLAw7dy50xlz++23KzIy0hmTmZmpAwcO6Msvv7zksVtaWhQIBIIWAADQPYUUMKmpqSosLNTGjRv18ssvq7q6WhMnTlRzc3O79vf5fBowYEDQuoiICPXr108+n88ZEx8fHzSm7XHbmItZtmyZYmJinCUpKSmUUwMAABYJKWCmTJmi++67T2PGjFFmZqbeeecdNTU1qaioqLPm124LFiyQ3+93lqNHj3b1lAAAQCcJ+T0wXxcbG6vhw4fr0KFD7Rrv9XrV0NAQtO7cuXNqbGx03lfj9XpVX18fNKbt8aXeeyNJbrdbbrc7lOkDAABLXdH3wJw4cUKHDx9WQkJCu8anpaWpqalJ5eXlzrqSkhKdP39eqampzpht27bp7Nmzzpji4mIlJyerb9++VzJdAADQTYQUMPPmzdPWrVt15MgRlZaWatq0aQoPD1d2drakP79HpaKiwrkjU1lZqYqKCjU2NkqSRo4cqcmTJ+uRRx7Rrl279OGHH+qxxx7TzJkzlZiYKEm6//77FRkZqdmzZ2vv3r168803tWLFCv30pz/tyPMGAAAWCylgjh07puzsbCUnJ2vGjBnq37+/duzYobi4OEnSqlWrdMstt+iRRx6RJN1+++265ZZb9Pvf/945xurVqzVixAhNmjRJd911l2677bag73iJiYnRu+++q+rqao0bN05PPfWUFi1axEeoAQCAw2WMMV09ic4QCAQUExMjv98vj8fT1dMBAADt0N7Xb34XEgAAsA4BAwAArEPAAAAA6xAwAADAOgQMAACwDgEDAACsQ8AAAADrEDAAAMA6BAwAALAOAQMAAKxDwAAAAOsQMAAAwDoEDAAAsA4BAwAArEPAAAAA6xAwAADAOgQMAACwDgEDAACsQ8AAAADrEDAAAMA6BAwAALAOAQMAAKxDwAAAAOsQMAAAwDoEDAAAsA4BAwAArEPAAAAA6xAwAADAOgQMAACwDgEDAACsQ8AAAADrEDAAAMA6BAwAALAOAQMAAKxDwAAAAOsQMAAAwDoEDAAAsA4BAwAArEPAAAAA6xAwAADAOgQMAACwDgEDAACsQ8AAAADrEDAAAMA6BAwAALAOAQMAAKxDwAAAAOsQMAAAwDoEDAAAsA4BAwAArEPAAAAA6xAwAADAOgQMAACwDgEDAACsE1LAFBQUyOVyBS0jRoxwtp8+fVpz585V//791bt3b02fPl319fVBx6ipqVFWVpZ69uypAQMGaP78+Tp37lzQmC1btmjs2LFyu90aNmyYCgsLv/0ZAgCAbifkOzCjRo1SXV2ds2zfvt3ZlpeXp7fffltr1qzR1q1bVVtbq7/6q79ytre2tiorK0tnzpxRaWmpfvvb36qwsFCLFi1yxlRXVysrK0t33nmnKioq9OSTT+rhhx/Wpk2brvBUAQBAd+Eyxpj2Di4oKNDatWtVUVFxwTa/36+4uDj953/+p/76r/9akrR//36NHDlSZWVlmjBhgjZs2KC7775btbW1io+PlyStWrVK+fn5+vzzzxUZGan8/HytX79eVVVVzrFnzpyppqYmbdy4sd0nFggEFBMTI7/fL4/H0+79AABA12nv63fId2AOHjyoxMREDR06VDk5OaqpqZEklZeX6+zZs0pPT3fGjhgxQoMGDVJZWZkkqaysTKNHj3biRZIyMzMVCAS0d+9eZ8zXj9E2pu0YAAAAEaEMTk1NVWFhoZKTk1VXV6clS5Zo4sSJqqqqks/nU2RkpGJjY4P2iY+Pl8/nkyT5fL6geGnb3rbtcmMCgYBOnTql6Ojoi86tpaVFLS0tzuNAIBDKqQEAAIuEFDBTpkxx/nvMmDFKTU3V4MGDVVRUdMmwuFqWLVumJUuWdOkcAADA1XFFH6OOjY3V8OHDdejQIXm9Xp05c0ZNTU1BY+rr6+X1eiVJXq/3gk8ltT3+v8Z4PJ7LRtKCBQvk9/ud5ejRo1dyagAA4Bp2RQFz4sQJHT58WAkJCRo3bpx69OihzZs3O9sPHDigmpoapaWlSZLS0tJUWVmphoYGZ0xxcbE8Ho9SUlKcMV8/RtuYtmNcitvtlsfjCVoAAED3FFLAzJs3T1u3btWRI0dUWlqqadOmKTw8XNnZ2YqJidHs2bP105/+VO+//77Ky8v1ox/9SGlpaZowYYIkKSMjQykpKZo1a5Z2796tTZs2aeHChZo7d67cbrckKTc3V59++qmefvpp7d+/XytXrlRRUZHy8vI6/uwBAICVQnoPzLFjx5Sdna3jx48rLi5Ot912m3bs2KG4uDhJ0vLlyxUWFqbp06erpaVFmZmZWrlypbN/eHi41q1bp0cffVRpaWnq1auXHnroIS1dutQZM2TIEK1fv155eXlasWKFBg4cqFdffVWZmZkddMoAAMB2IX0PjE34HhgAAOzTad8DAwAA0NUIGAAAYB0CBgAAWIeAAQAA1iFgAACAdQgYAABgHQIGAABYh4ABAADWIWAAAIB1CBgAAGAdAgYAAFiHgAEAANYhYAAAgHUIGAAAYB0CBgAAWIeAAQAA1iFgAACAdQgYAABgHQIGAABYh4ABAADWIWAAAIB1CBgAAGAdAgYAAFiHgAEAANYhYAAAgHUIGAAAYB0CBgAAWIeAAQAA1iFgAACAdQgYAABgHQIGAABYh4ABAADWIWAAAIB1CBgAAGAdAgYAAFiHgAEAANYhYAAAgHUIGAAAYB0CBgAAWIeAAQAA1iFgAACAdQgYAABgHQIGAABYh4ABAADWIWAAAIB1CBgAAGAdAgYAAFiHgAEAANYhYAAAgHUIGAAAYB0CBgAAWIeAAQAA1iFgAACAdQgYAABgHQIGAABY54oC5pe//KVcLpeefPJJZ93hw4c1bdo0xcXFyePxaMaMGaqvrw/ar7GxUTk5OfJ4PIqNjdXs2bN14sSJoDF79uzRxIkTFRUVpaSkJD377LNXMlUAANCNfOuA+eijj/Sv//qvGjNmjLPu5MmTysjIkMvlUklJiT788EOdOXNG99xzj86fP++My8nJ0d69e1VcXKx169Zp27ZtmjNnjrM9EAgoIyNDgwcPVnl5uZ577jkVFBTolVde+bbTBQAA3Yn5Fpqbm81NN91kiouLzR133GGeeOIJY4wxmzZtMmFhYcbv9ztjm5qajMvlMsXFxcYYY/bt22ckmY8++sgZs2HDBuNyucyf/vQnY4wxK1euNH379jUtLS3OmPz8fJOcnNzuOfr9fiMpaC4AAODa1t7X7291B2bu3LnKyspSenp60PqWlha5XC653W5nXVRUlMLCwrR9+3ZJUllZmWJjY3Xrrbc6Y9LT0xUWFqadO3c6Y26//XZFRkY6YzIzM3XgwAF9+eWXF51TS0uLAoFA0AIAALqnkAPmjTfe0B/+8ActW7bsgm0TJkxQr169lJ+fr6+++konT57UvHnz1Nraqrq6OkmSz+fTgAEDgvaLiIhQv3795PP5nDHx8fFBY9oet435pmXLlikmJsZZkpKSQj01AABgiZAC5ujRo3riiSe0evVqRUVFXbA9Li5Oa9as0dtvv63evXsrJiZGTU1NGjt2rMLCOvcDTwsWLJDf73eWo0ePdurzAQCArhMRyuDy8nI1NDRo7NixzrrW1lZt27ZNv/rVr9TS0qKMjAwdPnxYX3zxhSIiIhQbGyuv16uhQ4dKkrxerxoaGoKOe+7cOTU2Nsrr9TpjvvnJpbbHbWO+ye12B/3oCgAAdF8h3RaZNGmSKisrVVFR4Sy33nqrcnJyVFFRofDwcGfsDTfcoNjYWJWUlKihoUH33nuvJCktLU1NTU0qLy93xpaUlOj8+fNKTU11xmzbtk1nz551xhQXFys5OVl9+/a9ohMGAAD2C+kOTJ8+ffS9730vaF2vXr3Uv39/Z/3rr7+ukSNHKi4uTmVlZXriiSeUl5en5ORkSdLIkSM1efJkPfLII1q1apXOnj2rxx57TDNnzlRiYqIk6f7779eSJUs0e/Zs5efnq6qqSitWrNDy5cs74pwBAIDlQgqY9jhw4IAWLFigxsZG3XjjjfrZz36mvLy8oDGrV6/WY489pkmTJiksLEzTp0/Xv/zLvzjbY2Ji9O6772ru3LkaN26cbrjhBi1atCjou2IAAMD1y2WMMV09ic4QCAQUExMjv98vj8fT1dMBAADt0N7Xb34XEgAAsA4BAwAArEPAAAAA6xAwAADAOgQMAACwDgEDAACsQ8AAAADrEDAAAMA6BAwAALAOAQMAAKxDwAAAAOsQMAAAwDoEDAAAsE5EV0+gs7T9ku1AINDFMwEAAO3V9rrd9jp+Kd02YJqbmyVJSUlJXTwTAAAQqubmZsXExFxyu8v8X4ljqfPnz6u2tlZ9+vSRy+Xq6ul0qUAgoKSkJB09elQej6erp9Otca2vDq7z1cF1vjq4zsGMMWpublZiYqLCwi79TpduewcmLCxMAwcO7OppXFM8Hg//OK4SrvXVwXW+OrjOVwfX+X9d7s5LG97ECwAArEPAAAAA6xAw1wG3263FixfL7XZ39VS6Pa711cF1vjq4zlcH1/nb6bZv4gUAAN0Xd2AAAIB1CBgAAGAdAgYAAFiHgAEAANYhYLqJxsZG5eTkyOPxKDY2VrNnz9aJEycuu8/p06c1d+5c9e/fX71799b06dNVX19/0bHHjx/XwIED5XK51NTU1AlnYIfOuM67d+9Wdna2kpKSFB0drZEjR2rFihWdfSrXlF//+te68cYbFRUVpdTUVO3ateuy49esWaMRI0YoKipKo0eP1jvvvBO03RijRYsWKSEhQdHR0UpPT9fBgwc78xSs0ZHX+uzZs8rPz9fo0aPVq1cvJSYm6sEHH1RtbW1nn8Y1r6P/Tn9dbm6uXC6XXnzxxQ6etWUMuoXJkyebm2++2ezYscN88MEHZtiwYSY7O/uy++Tm5pqkpCSzefNm8/HHH5sJEyaYH/zgBxcdO3XqVDNlyhQjyXz55ZedcAZ26Izr/Jvf/MY8/vjjZsuWLebw4cPm3//93010dLR56aWXOvt0rglvvPGGiYyMNK+99prZu3eveeSRR0xsbKypr6+/6PgPP/zQhIeHm2effdbs27fPLFy40PTo0cNUVlY6Y375y1+amJgYs3btWrN7925z7733miFDhphTp05drdO6JnX0tW5qajLp6enmzTffNPv37zdlZWVm/PjxZty4cVfztK45nfF3us1///d/m5tvvtkkJiaa5cuXd/KZXNsImG5g3759RpL56KOPnHUbNmwwLpfL/OlPf7roPk1NTaZHjx5mzZo1zrpPPvnESDJlZWVBY1euXGnuuOMOs3nz5us6YDr7On/dT37yE3PnnXd23OSvYePHjzdz5851Hre2tprExESzbNmyi46fMWOGycrKClqXmppqfvzjHxtjjDl//rzxer3mueeec7Y3NTUZt9tt/uu//qsTzsAeHX2tL2bXrl1Gkvnss886ZtIW6qzrfOzYMfOd73zHVFVVmcGDB1/3AcOPkLqBsrIyxcbG6tZbb3XWpaenKywsTDt37rzoPuXl5Tp79qzS09OddSNGjNCgQYNUVlbmrNu3b5+WLl2qf/u3f7vsL9W6HnTmdf4mv9+vfv36ddzkr1FnzpxReXl50PUJCwtTenr6Ja9PWVlZ0HhJyszMdMZXV1fL5/MFjYmJiVFqauplr3l31xnX+mL8fr9cLpdiY2M7ZN626azrfP78ec2aNUvz58/XqFGjOmfylrm+X5G6CZ/PpwEDBgSti4iIUL9+/eTz+S65T2Rk5AX/k4mPj3f2aWlpUXZ2tp577jkNGjSoU+Zuk866zt9UWlqqN998U3PmzOmQeV/LvvjiC7W2tio+Pj5o/eWuj8/nu+z4tj9DOeb1oDOu9TedPn1a+fn5ys7Ovm5/KWFnXed/+qd/UkREhB5//PGOn7SlCJhr2DPPPCOXy3XZZf/+/Z32/AsWLNDIkSP1wAMPdNpzXAu6+jp/XVVVlaZOnarFixcrIyPjqjwn0BHOnj2rGTNmyBijl19+uaun062Ul5drxYoVKiwslMvl6urpXDMiunoCuLSnnnpKf/u3f3vZMUOHDpXX61VDQ0PQ+nPnzqmxsVFer/ei+3m9Xp05c0ZNTU1Bdwfq6+udfUpKSlRZWam33npL0p8/2SFJN9xwg372s59pyZIl3/LMri1dfZ3b7Nu3T5MmTdKcOXO0cOHCb3UutrnhhhsUHh5+waffLnZ92ni93suOb/uzvr5eCQkJQWO+//3vd+Ds7dIZ17pNW7x89tlnKikpuW7vvkidc50/+OADNTQ0BN0Jb21t1VNPPaUXX3xRR44c6diTsEVXvwkHV67tzaUff/yxs27Tpk3tenPpW2+95azbv39/0JtLDx06ZCorK53ltddeM5JMaWnpJd9N35111nU2xpiqqiozYMAAM3/+/M47gWvU+PHjzWOPPeY8bm1tNd/5zncu+4bHu+++O2hdWlraBW/iff75553tfr+fN/Gajr/Wxhhz5swZ85d/+Zdm1KhRpqGhoXMmbpmOvs5ffPFF0P+LKysrTWJiosnPzzf79+/vvBO5xhEw3cTkyZPNLbfcYnbu3Gm2b99ubrrppqCP9x47dswkJyebnTt3Outyc3PNoEGDTElJifn4449NWlqaSUtLu+RzvP/++9f1p5CM6ZzrXFlZaeLi4swDDzxg6urqnOV6eTF44403jNvtNoWFhWbfvn1mzpw5JjY21vh8PmOMMbNmzTLPPPOMM/7DDz80ERER5vnnnzeffPKJWbx48UU/Rh0bG2v+53/+x+zZs8dMnTqVj1Gbjr/WZ86cMffee68ZOHCgqaioCPr729LS0iXneC3ojL/T38SnkAiYbuP48eMmOzvb9O7d23g8HvOjH/3INDc3O9urq6uNJPP+++87606dOmV+8pOfmL59+5qePXuaadOmmbq6uks+BwHTOdd58eLFRtIFy+DBg6/imXWtl156yQwaNMhERkaa8ePHmx07djjb7rjjDvPQQw8FjS8qKjLDhw83kZGRZtSoUWb9+vVB28+fP2/+8R//0cTHxxu3220mTZpkDhw4cDVO5ZrXkde67e/7xZav/xu4HnX03+lvImCMcRnz/9/YAAAAYAk+hQQAAKxDwAAAAOsQMAAAwDoEDAAAsA4BAwAArEPAAAAA6xAwAADAOgQMAACwDgEDAACsQ8AAAADrEDAAAMA6BAwAALDO/wMaGOxvRC6s3AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#2_3\n",
    "\n",
    "\n",
    "Layer1 = Dense(13,1)\n",
    "Act1 = Linear()\n",
    "Loss = Mean_Square_Error_loss()\n",
    "Optimizer = AdamOptim(0.001)\n",
    "\n",
    "\n",
    "e = []\n",
    "l = []\n",
    "for epoch in range(50):\n",
    "    #forward\n",
    "    Layer1.forward(x_train)\n",
    "    Act1.forward(Layer1.output)    \n",
    "    loss = Loss.forward(Act1.output,y_train)\n",
    "    print(\"Epoch\", epoch,\":\")\n",
    "    print(\"Loss\", loss)\n",
    "    print('--------------------------')\n",
    "    \n",
    "    #backward\n",
    "    Loss.backward(Act1.output,y_train)\n",
    "    \n",
    "    Act1.backward(Loss.b_output)\n",
    "    Layer1.backward(Act1.b_output)\n",
    "    \n",
    "    #update params\n",
    "    Optimizer.update(epoch,Layer1)\n",
    "            \n",
    "    e.append(epoch)\n",
    "    l.append(loss)\n",
    "    \n",
    "Layer1.forward(x_train)\n",
    "Act1.forward(Layer1.output)    \n",
    "loss = Loss.forward(Act1.output,y_train)\n",
    "print(\"Loss for testing data:\", loss)\n",
    "\n",
    "plt.scatter(e,l)\n",
    "\n",
    "Optimizer = RMSprop(0.001)\n",
    "Optimizer.update(Layer1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ea6f20",
   "metadata": {},
   "source": [
    "# 2-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0f47cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 :\n",
      "Loss [1616392.6981359]\n",
      "Learning_rate 0.001\n",
      "--------------------------\n",
      "Epoch 1 :\n",
      "Loss [1.02402832e+14]\n",
      "Learning_rate 0.0007\n",
      "--------------------------\n",
      "Epoch 2 :\n",
      "Loss [3.1816405e+21]\n",
      "Learning_rate 0.00049\n",
      "--------------------------\n",
      "Epoch 3 :\n",
      "Loss [4.84306029e+28]\n",
      "Learning_rate 0.000343\n",
      "--------------------------\n",
      "Epoch 4 :\n",
      "Loss [3.61151404e+35]\n",
      "Learning_rate 0.00024009999999999998\n",
      "--------------------------\n",
      "Epoch 5 :\n",
      "Loss [1.31922384e+42]\n",
      "Learning_rate 0.00016806999999999998\n",
      "--------------------------\n",
      "Epoch 6 :\n",
      "Loss [2.36020085e+48]\n",
      "Learning_rate 0.00011764899999999998\n",
      "--------------------------\n",
      "Epoch 7 :\n",
      "Loss [2.06774588e+54]\n",
      "Learning_rate 8.235429999999999e-05\n",
      "--------------------------\n",
      "Epoch 8 :\n",
      "Loss [8.86836681e+59]\n",
      "Learning_rate 5.764800999999999e-05\n",
      "--------------------------\n",
      "Epoch 9 :\n",
      "Loss [1.86130529e+65]\n",
      "Learning_rate 4.035360699999999e-05\n",
      "--------------------------\n",
      "Epoch 10 :\n",
      "Loss [1.91062178e+70]\n",
      "Learning_rate 2.8247524899999994e-05\n",
      "--------------------------\n",
      "Epoch 11 :\n",
      "Loss [9.58440739e+74]\n",
      "Learning_rate 1.9773267429999995e-05\n",
      "--------------------------\n",
      "Epoch 12 :\n",
      "Loss [2.34686577e+79]\n",
      "Learning_rate 1.3841287200999995e-05\n",
      "--------------------------\n",
      "Epoch 13 :\n",
      "Loss [2.80043279e+83]\n",
      "Learning_rate 9.688901040699997e-06\n",
      "--------------------------\n",
      "Epoch 14 :\n",
      "Loss [1.62458962e+87]\n",
      "Learning_rate 6.782230728489997e-06\n",
      "--------------------------\n",
      "Epoch 15 :\n",
      "Loss [4.56622249e+90]\n",
      "Learning_rate 4.747561509942998e-06\n",
      "--------------------------\n",
      "Epoch 16 :\n",
      "Loss [6.18751826e+93]\n",
      "Learning_rate 3.323293056960098e-06\n",
      "--------------------------\n",
      "Epoch 17 :\n",
      "Loss [4.01328671e+96]\n",
      "Learning_rate 2.3263051398720685e-06\n",
      "--------------------------\n",
      "Epoch 18 :\n",
      "Loss [1.23293166e+99]\n",
      "Learning_rate 1.6284135979104478e-06\n",
      "--------------------------\n",
      "Epoch 19 :\n",
      "Loss [1.76632947e+101]\n",
      "Learning_rate 1.1398895185373134e-06\n",
      "--------------------------\n",
      "Epoch 20 :\n",
      "Loss [1.15273447e+103]\n",
      "Learning_rate 7.979226629761193e-07\n",
      "--------------------------\n",
      "Epoch 21 :\n",
      "Loss [3.30549121e+104]\n",
      "Learning_rate 5.585458640832835e-07\n",
      "--------------------------\n",
      "Epoch 22 :\n",
      "Loss [3.93082021e+105]\n",
      "Learning_rate 3.9098210485829847e-07\n",
      "--------------------------\n",
      "Epoch 23 :\n",
      "Loss [1.75653751e+106]\n",
      "Learning_rate 2.736874734008089e-07\n",
      "--------------------------\n",
      "Epoch 24 :\n",
      "Loss [2.44472163e+106]\n",
      "Learning_rate 1.9158123138056623e-07\n",
      "--------------------------\n",
      "Epoch 25 :\n",
      "Loss [6.75926279e+105]\n",
      "Learning_rate 1.3410686196639635e-07\n",
      "--------------------------\n",
      "Epoch 26 :\n",
      "Loss [2.45046512e+105]\n",
      "Learning_rate 1.4081220506471618e-07\n",
      "--------------------------\n",
      "Epoch 27 :\n",
      "Loss [1.1404845e+105]\n",
      "Learning_rate 1.4785281531795199e-07\n",
      "--------------------------\n",
      "Epoch 28 :\n",
      "Loss [6.69752998e+104]\n",
      "Learning_rate 1.552454560838496e-07\n",
      "--------------------------\n",
      "Epoch 29 :\n",
      "Loss [4.89194652e+104]\n",
      "Learning_rate 1.6300772888804207e-07\n",
      "--------------------------\n",
      "Epoch 30 :\n",
      "Loss [4.39059483e+104]\n",
      "Learning_rate 1.7115811533244418e-07\n",
      "--------------------------\n",
      "Epoch 31 :\n",
      "Loss [4.79226527e+104]\n",
      "Learning_rate 1.797160210990664e-07\n",
      "--------------------------\n",
      "Epoch 32 :\n",
      "Loss [8.91533741e+103]\n",
      "Learning_rate 1.2580121476934646e-07\n",
      "--------------------------\n",
      "Epoch 33 :\n",
      "Loss [2.25462771e+103]\n",
      "Learning_rate 1.3209127550781378e-07\n",
      "--------------------------\n",
      "Epoch 34 :\n",
      "Loss [7.53310795e+102]\n",
      "Learning_rate 1.3869583928320447e-07\n",
      "--------------------------\n",
      "Epoch 35 :\n",
      "Loss [3.25097076e+102]\n",
      "Learning_rate 1.456306312473647e-07\n",
      "--------------------------\n",
      "Epoch 36 :\n",
      "Loss [1.779159e+102]\n",
      "Learning_rate 1.5291216280973294e-07\n",
      "--------------------------\n",
      "Epoch 37 :\n",
      "Loss [1.21612963e+102]\n",
      "Learning_rate 1.605577709502196e-07\n",
      "--------------------------\n",
      "Epoch 38 :\n",
      "Loss [1.02509427e+102]\n",
      "Learning_rate 1.685856594977306e-07\n",
      "--------------------------\n",
      "Epoch 39 :\n",
      "Loss [1.05401737e+102]\n",
      "Learning_rate 1.7701494247261712e-07\n",
      "--------------------------\n",
      "Epoch 40 :\n",
      "Loss [1.08375653e+102]\n",
      "Learning_rate 1.7701494247261712e-07\n",
      "--------------------------\n",
      "Epoch 41 :\n",
      "Loss [1.11433479e+102]\n",
      "Learning_rate 1.7701494247261712e-07\n",
      "--------------------------\n",
      "Epoch 42 :\n",
      "Loss [1.14577581e+102]\n",
      "Learning_rate 1.7701494247261712e-07\n",
      "--------------------------\n",
      "Epoch 43 :\n",
      "Loss [1.17810394e+102]\n",
      "Learning_rate 1.7701494247261712e-07\n",
      "--------------------------\n",
      "Epoch 44 :\n",
      "Loss [1.21134422e+102]\n",
      "Learning_rate 1.7701494247261712e-07\n",
      "--------------------------\n",
      "Epoch 45 :\n",
      "Loss [1.24552237e+102]\n",
      "Learning_rate 1.7701494247261712e-07\n",
      "--------------------------\n",
      "Epoch 46 :\n",
      "Loss [1.28066486e+102]\n",
      "Learning_rate 1.7701494247261712e-07\n",
      "--------------------------\n",
      "Epoch 47 :\n",
      "Loss [1.31679889e+102]\n",
      "Learning_rate 1.7701494247261712e-07\n",
      "--------------------------\n",
      "Epoch 48 :\n",
      "Loss [1.35395245e+102]\n",
      "Learning_rate 1.7701494247261712e-07\n",
      "--------------------------\n",
      "Epoch 49 :\n",
      "Loss [1.3921543e+102]\n",
      "Learning_rate 1.7701494247261712e-07\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "Layer1 = Dense(13,1)\n",
    "Act1 = Linear()\n",
    "Loss = Mean_Square_Error_loss()\n",
    "\n",
    "\n",
    "loss_old = 100\n",
    "Layer1_history = Layer1\n",
    "\n",
    "for epoch in range(50):\n",
    "    #forward\n",
    "    Layer1.forward(x_train)\n",
    "    Act1.forward(Layer1.output)    \n",
    "    loss = Loss.forward(Act1.output,y_train)\n",
    "    \n",
    "    #report\n",
    "    print(\"Epoch\", epoch,\":\")\n",
    "    print(\"Loss\", loss)\n",
    "    print(\"Learning_rate\", learning_rate)\n",
    "    print('--------------------------')\n",
    "    \n",
    "    #backward\n",
    "    Loss.backward(Act1.output,y_train)\n",
    "    Act1.backward(Loss.b_output)\n",
    "    Layer1.backward(Act1.b_output)\n",
    "    \n",
    "        \n",
    "    if (1.04 <loss/loss_old):\n",
    "        #discard weight update\n",
    "        Layer1 = Layer1_history\n",
    "        learning_rate = learning_rate * 0.7\n",
    "        \n",
    "    elif(loss/loss_old<1):\n",
    "        #accept weight update\n",
    "        learning_rate = learning_rate * 1.05\n",
    "        \n",
    "        \n",
    "    \n",
    "    #keeping old params    \n",
    "    Layer1_history = Layer1\n",
    "    loss_old = loss\n",
    "        \n",
    "    #update params\n",
    "    Optimizer = SGD(learning_rate)\n",
    "    Optimizer.update(Layer1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d108df2c",
   "metadata": {},
   "source": [
    "# 2-5, i=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02d195a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "i =1\n",
    "x_train = np.random.uniform(-3, 3, 200).reshape(-1,1)\n",
    "y_train = (np.sin((x_train*i*np.pi/2)) - 1).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74202ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the neural network\n",
    "Layer1=Dense(1,4)\n",
    "Act1 = Sigmoid()\n",
    "\n",
    "Layer2=Dense(4,4)\n",
    "Act2 = Sigmoid()\n",
    "\n",
    "Layer3 = Dense(4,1)\n",
    "Act3 = Sigmoid()\n",
    "\n",
    "Loss =  Mean_Square_Error_loss()\n",
    "Optimizer = SGD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63f92686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0\n",
      "Loss: [4.12974663]\n",
      "--------------------------\n",
      "Epoch:1\n",
      "Loss: [4.11641445]\n",
      "--------------------------\n",
      "Epoch:2\n",
      "Loss: [4.10225523]\n",
      "--------------------------\n",
      "Epoch:3\n",
      "Loss: [4.0872031]\n",
      "--------------------------\n",
      "Epoch:4\n",
      "Loss: [4.0711846]\n",
      "--------------------------\n",
      "Epoch:5\n",
      "Loss: [4.05411818]\n",
      "--------------------------\n",
      "Epoch:6\n",
      "Loss: [4.03591413]\n",
      "--------------------------\n",
      "Epoch:7\n",
      "Loss: [4.0164753]\n",
      "--------------------------\n",
      "Epoch:8\n",
      "Loss: [3.99569892]\n",
      "--------------------------\n",
      "Epoch:9\n",
      "Loss: [3.97348014]\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "            #forward\n",
    "            Layer1.forward(x_train)\n",
    "            Act1.forward(Layer1.output)\n",
    "            Layer2.forward(Act1.output)\n",
    "            Act2.forward(Layer2.output)\n",
    "            Layer3.forward(Act2.output)\n",
    "            Act3.forward(Layer3.output)\n",
    "            loss = Loss.forward(Act3.output,y_train)\n",
    "            \n",
    "            print(f'Epoch:{epoch}')\n",
    "            print(f'Loss: {loss}')\n",
    "            print('--------------------------')\n",
    "\n",
    "            #backward\n",
    "            Loss.backward(Act3.output,y_train)\n",
    "            Act3.backward(Loss.b_output)\n",
    "            Layer3.backward(Act3.b_output)\n",
    "            Act2.backward(Layer3.b_output)\n",
    "            Layer2.backward(Act2.b_output)\n",
    "            Act1.backward(Layer2.b_output)\n",
    "            Layer1.backward(Act1.b_output)\n",
    "\n",
    "            #update params\n",
    "            Optimizer.update(Layer1)\n",
    "            Optimizer.update(Layer2)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05ced719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Loss for new data: [3.94341651]\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "#i =[1,2,4,8]\n",
    "x_test = np.random.uniform(-4, 4, 200).reshape(-1,1)\n",
    "y_test = (np.sin((x_train*i*np.pi/2)) - 1).reshape(-1,1)\n",
    "\n",
    "Layer1.forward(x_test)\n",
    "Act1.forward(Layer1.output)\n",
    "Layer2.forward(Act1.output)\n",
    "Act2.forward(Layer2.output)\n",
    "Layer3.forward(Act2.output)\n",
    "Act3.forward(Layer3.output)\n",
    "loss = Loss.forward(Act3.output,y_test)\n",
    "            \n",
    "print(f'Final Loss for new data: {loss}')\n",
    "print('--------------------------')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a55fb0",
   "metadata": {},
   "source": [
    "# 2-5, i= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b5751d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "i =2\n",
    "x_train = np.random.uniform(-3, 3, 200).reshape(-1,1)\n",
    "y_train = (np.sin((x_train*i*np.pi/2)) - 1).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d432f45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the neural network\n",
    "Layer1=Dense(1,4)\n",
    "Act1 = Sigmoid()\n",
    "\n",
    "Layer2=Dense(4,4)\n",
    "Act2 = Sigmoid()\n",
    "\n",
    "Layer3 = Dense(4,1)\n",
    "Act3 = Sigmoid()\n",
    "\n",
    "Loss =  Mean_Square_Error_loss()\n",
    "Optimizer = SGD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3b470bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0\n",
      "Loss: [2.21579976]\n",
      "--------------------------\n",
      "Epoch:1\n",
      "Loss: [2.17976243]\n",
      "--------------------------\n",
      "Epoch:2\n",
      "Loss: [2.14892309]\n",
      "--------------------------\n",
      "Epoch:3\n",
      "Loss: [2.1221097]\n",
      "--------------------------\n",
      "Epoch:4\n",
      "Loss: [2.09845595]\n",
      "--------------------------\n",
      "Epoch:5\n",
      "Loss: [2.07732067]\n",
      "--------------------------\n",
      "Epoch:6\n",
      "Loss: [2.05822621]\n",
      "--------------------------\n",
      "Epoch:7\n",
      "Loss: [2.04081349]\n",
      "--------------------------\n",
      "Epoch:8\n",
      "Loss: [2.02480964]\n",
      "--------------------------\n",
      "Epoch:9\n",
      "Loss: [2.01000487]\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "            #forward\n",
    "            Layer1.forward(x_train)\n",
    "            Act1.forward(Layer1.output)\n",
    "            Layer2.forward(Act1.output)\n",
    "            Act2.forward(Layer2.output)\n",
    "            Layer3.forward(Act2.output)\n",
    "            Act3.forward(Layer3.output)\n",
    "            loss = Loss.forward(Act3.output,y_train)\n",
    "            \n",
    "            print(f'Epoch:{epoch}')\n",
    "            print(f'Loss: {loss}')\n",
    "            print('--------------------------')\n",
    "\n",
    "            #backward\n",
    "            Loss.backward(Act3.output,y_train)\n",
    "            Act3.backward(Loss.b_output)\n",
    "            Layer3.backward(Act3.b_output)\n",
    "            Act2.backward(Layer3.b_output)\n",
    "            Layer2.backward(Act2.b_output)\n",
    "            Act1.backward(Layer2.b_output)\n",
    "            Layer1.backward(Act1.b_output)\n",
    "\n",
    "            #update params\n",
    "            Optimizer.update(Layer1)\n",
    "            Optimizer.update(Layer2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88ccb60b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Loss for new data: [2.00960023]\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "#i =[1,2,4,8]\n",
    "x_test = np.random.uniform(-4, 4, 200).reshape(-1,1)\n",
    "y_test = (np.sin((x_train*i*np.pi/2)) - 1).reshape(-1,1)\n",
    "\n",
    "Layer1.forward(x_test)\n",
    "Act1.forward(Layer1.output)\n",
    "Layer2.forward(Act1.output)\n",
    "Act2.forward(Layer2.output)\n",
    "Layer3.forward(Act2.output)\n",
    "Act3.forward(Layer3.output)\n",
    "loss = Loss.forward(Act3.output,y_test)\n",
    "            \n",
    "print(f'Final Loss for new data: {loss}')\n",
    "print('--------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36baed3a",
   "metadata": {},
   "source": [
    "# 2-5, i=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b191b7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 4\n",
    "x_train = np.random.uniform(-3, 3, 200).reshape(-1,1)\n",
    "y_train = (np.sin((x_train*i*np.pi/2)) - 1).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "84ae3209",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the neural network\n",
    "Layer1=Dense(1,4)\n",
    "Act1 = Sigmoid()\n",
    "\n",
    "Layer2=Dense(4,4)\n",
    "Act2 = Sigmoid()\n",
    "\n",
    "Layer3 = Dense(4,1)\n",
    "Act3 = Sigmoid()\n",
    "\n",
    "Loss =  Mean_Square_Error_loss()\n",
    "Optimizer = SGD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8044012b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0\n",
      "Loss: [3.1129811]\n",
      "--------------------------\n",
      "Epoch:1\n",
      "Loss: [3.10929442]\n",
      "--------------------------\n",
      "Epoch:2\n",
      "Loss: [3.10564383]\n",
      "--------------------------\n",
      "Epoch:3\n",
      "Loss: [3.10202682]\n",
      "--------------------------\n",
      "Epoch:4\n",
      "Loss: [3.09844091]\n",
      "--------------------------\n",
      "Epoch:5\n",
      "Loss: [3.09488368]\n",
      "--------------------------\n",
      "Epoch:6\n",
      "Loss: [3.09135276]\n",
      "--------------------------\n",
      "Epoch:7\n",
      "Loss: [3.08784588]\n",
      "--------------------------\n",
      "Epoch:8\n",
      "Loss: [3.0843608]\n",
      "--------------------------\n",
      "Epoch:9\n",
      "Loss: [3.08089542]\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "            #forward\n",
    "            Layer1.forward(x_train)\n",
    "            Act1.forward(Layer1.output)\n",
    "            Layer2.forward(Act1.output)\n",
    "            Act2.forward(Layer2.output)\n",
    "            Layer3.forward(Act2.output)\n",
    "            Act3.forward(Layer3.output)\n",
    "            loss = Loss.forward(Act3.output,y_train)\n",
    "            \n",
    "            print(f'Epoch:{epoch}')\n",
    "            print(f'Loss: {loss}')\n",
    "            print('--------------------------')\n",
    "\n",
    "            #backward\n",
    "            Loss.backward(Act3.output,y_train)\n",
    "            Act3.backward(Loss.b_output)\n",
    "            Layer3.backward(Act3.b_output)\n",
    "            Act2.backward(Layer3.b_output)\n",
    "            Layer2.backward(Act2.b_output)\n",
    "            Act1.backward(Layer2.b_output)\n",
    "            Layer1.backward(Act1.b_output)\n",
    "\n",
    "            #update params\n",
    "            Optimizer.update(Layer1)\n",
    "            Optimizer.update(Layer2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c4819d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Loss for new data: [3.07450717]\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "#i =[1,2,4,8]\n",
    "x_test = np.random.uniform(-4, 4, 200).reshape(-1,1)\n",
    "y_test = (np.sin((x_train*i*np.pi/2)) - 1).reshape(-1,1)\n",
    "\n",
    "Layer1.forward(x_test)\n",
    "Act1.forward(Layer1.output)\n",
    "Layer2.forward(Act1.output)\n",
    "Act2.forward(Layer2.output)\n",
    "Layer3.forward(Act2.output)\n",
    "Act3.forward(Layer3.output)\n",
    "loss = Loss.forward(Act3.output,y_test)\n",
    "            \n",
    "print(f'Final Loss for new data: {loss}')\n",
    "print('--------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421f9047",
   "metadata": {},
   "source": [
    "# 2-5, i = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6a004bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 8\n",
    "x_train = np.random.uniform(-3, 3, 200).reshape(-1,1)\n",
    "y_train = (np.sin((x_train*i*np.pi/2)) - 1).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b6eb03f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the neural network\n",
    "Layer1=Dense(1,4)\n",
    "Act1 = Sigmoid()\n",
    "\n",
    "Layer2=Dense(4,4)\n",
    "Act2 = Sigmoid()\n",
    "\n",
    "Layer3 = Dense(4,1)\n",
    "Act3 = Sigmoid()\n",
    "\n",
    "Loss =  Mean_Square_Error_loss()\n",
    "Optimizer = SGD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "704d0083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0\n",
      "Loss: [2.31208374]\n",
      "--------------------------\n",
      "Epoch:1\n",
      "Loss: [2.24302665]\n",
      "--------------------------\n",
      "Epoch:2\n",
      "Loss: [2.1737263]\n",
      "--------------------------\n",
      "Epoch:3\n",
      "Loss: [2.10554007]\n",
      "--------------------------\n",
      "Epoch:4\n",
      "Loss: [2.04026961]\n",
      "--------------------------\n",
      "Epoch:5\n",
      "Loss: [1.9798501]\n",
      "--------------------------\n",
      "Epoch:6\n",
      "Loss: [1.92587496]\n",
      "--------------------------\n",
      "Epoch:7\n",
      "Loss: [1.87919866]\n",
      "--------------------------\n",
      "Epoch:8\n",
      "Loss: [1.8398377]\n",
      "--------------------------\n",
      "Epoch:9\n",
      "Loss: [1.8071688]\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "            #forward\n",
    "            Layer1.forward(x_train)\n",
    "            Act1.forward(Layer1.output)\n",
    "            Layer2.forward(Act1.output)\n",
    "            Act2.forward(Layer2.output)\n",
    "            Layer3.forward(Act2.output)\n",
    "            Act3.forward(Layer3.output)\n",
    "            loss = Loss.forward(Act3.output,y_train)\n",
    "            \n",
    "            print(f'Epoch:{epoch}')\n",
    "            print(f'Loss: {loss}')\n",
    "            print('--------------------------')\n",
    "\n",
    "            #backward\n",
    "            Loss.backward(Act3.output,y_train)\n",
    "            Act3.backward(Loss.b_output)\n",
    "            Layer3.backward(Act3.b_output)\n",
    "            Act2.backward(Layer3.b_output)\n",
    "            Layer2.backward(Act2.b_output)\n",
    "            Act1.backward(Layer2.b_output)\n",
    "            Layer1.backward(Act1.b_output)\n",
    "\n",
    "            #update params\n",
    "            Optimizer.update(Layer1)\n",
    "            Optimizer.update(Layer2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c222f42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Loss for new data: [1.78246638]\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "#i =[1,2,4,8]\n",
    "x_test = np.random.uniform(-4, 4, 200).reshape(-1,1)\n",
    "y_test = (np.sin((x_train*i*np.pi/2)) - 1).reshape(-1,1)\n",
    "\n",
    "Layer1.forward(x_test)\n",
    "Act1.forward(Layer1.output)\n",
    "Layer2.forward(Act1.output)\n",
    "Act2.forward(Layer2.output)\n",
    "Layer3.forward(Act2.output)\n",
    "Act3.forward(Layer3.output)\n",
    "loss = Loss.forward(Act3.output,y_test)\n",
    "            \n",
    "print(f'Final Loss for new data: {loss}')\n",
    "print('--------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c9d162",
   "metadata": {},
   "source": [
    "# 2-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7dc88231",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.random.uniform(-3, 3, 200).reshape(-1,1)\n",
    "y_train = (np.sin((6*x_train*np.pi/2)) - 1).reshape(-1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "641db6a1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "neuron number in hidden layer =  2\n",
      "Epoch:0\n",
      "Loss: [2.46428656]\n",
      "--------------------------\n",
      "Epoch:1\n",
      "Loss: [2.45143865]\n",
      "--------------------------\n",
      "Epoch:2\n",
      "Loss: [2.43971107]\n",
      "--------------------------\n",
      "Epoch:3\n",
      "Loss: [2.42899043]\n",
      "--------------------------\n",
      "Epoch:4\n",
      "Loss: [2.41917387]\n",
      "--------------------------\n",
      "Epoch:5\n",
      "Loss: [2.41016877]\n",
      "--------------------------\n",
      "Epoch:6\n",
      "Loss: [2.40189227]\n",
      "--------------------------\n",
      "Epoch:7\n",
      "Loss: [2.39427047]\n",
      "--------------------------\n",
      "Epoch:8\n",
      "Loss: [2.38723766]\n",
      "--------------------------\n",
      "Epoch:9\n",
      "Loss: [2.38073544]\n",
      "--------------------------\n",
      "\n",
      "neuron number in hidden layer =  3\n",
      "Epoch:0\n",
      "Loss: [4.34217209]\n",
      "--------------------------\n",
      "Epoch:1\n",
      "Loss: [4.34161351]\n",
      "--------------------------\n",
      "Epoch:2\n",
      "Loss: [4.34103958]\n",
      "--------------------------\n",
      "Epoch:3\n",
      "Loss: [4.3404497]\n",
      "--------------------------\n",
      "Epoch:4\n",
      "Loss: [4.33984324]\n",
      "--------------------------\n",
      "Epoch:5\n",
      "Loss: [4.33921955]\n",
      "--------------------------\n",
      "Epoch:6\n",
      "Loss: [4.33857794]\n",
      "--------------------------\n",
      "Epoch:7\n",
      "Loss: [4.3379177]\n",
      "--------------------------\n",
      "Epoch:8\n",
      "Loss: [4.33723807]\n",
      "--------------------------\n",
      "Epoch:9\n",
      "Loss: [4.33653826]\n",
      "--------------------------\n",
      "\n",
      "neuron number in hidden layer =  4\n",
      "Epoch:0\n",
      "Loss: [3.79693781]\n",
      "--------------------------\n",
      "Epoch:1\n",
      "Loss: [3.7610804]\n",
      "--------------------------\n",
      "Epoch:2\n",
      "Loss: [3.72486305]\n",
      "--------------------------\n",
      "Epoch:3\n",
      "Loss: [3.68879934]\n",
      "--------------------------\n",
      "Epoch:4\n",
      "Loss: [3.65332225]\n",
      "--------------------------\n",
      "Epoch:5\n",
      "Loss: [3.61875361]\n",
      "--------------------------\n",
      "Epoch:6\n",
      "Loss: [3.58529554]\n",
      "--------------------------\n",
      "Epoch:7\n",
      "Loss: [3.55303917]\n",
      "--------------------------\n",
      "Epoch:8\n",
      "Loss: [3.5219835]\n",
      "--------------------------\n",
      "Epoch:9\n",
      "Loss: [3.49205767]\n",
      "--------------------------\n",
      "\n",
      "neuron number in hidden layer =  5\n",
      "Epoch:0\n",
      "Loss: [3.28710918]\n",
      "--------------------------\n",
      "Epoch:1\n",
      "Loss: [3.2205629]\n",
      "--------------------------\n",
      "Epoch:2\n",
      "Loss: [3.15091929]\n",
      "--------------------------\n",
      "Epoch:3\n",
      "Loss: [3.07898074]\n",
      "--------------------------\n",
      "Epoch:4\n",
      "Loss: [3.00569946]\n",
      "--------------------------\n",
      "Epoch:5\n",
      "Loss: [2.93212463]\n",
      "--------------------------\n",
      "Epoch:6\n",
      "Loss: [2.85933521]\n",
      "--------------------------\n",
      "Epoch:7\n",
      "Loss: [2.78836531]\n",
      "--------------------------\n",
      "Epoch:8\n",
      "Loss: [2.7201326]\n",
      "--------------------------\n",
      "Epoch:9\n",
      "Loss: [2.65538168]\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "#Creating the neural network\n",
    "i = [2,3,4,5]\n",
    "for ind in i : \n",
    "    Layer1=Dense(1,ind)\n",
    "    Act1 = Sigmoid()\n",
    "\n",
    "    Layer2=Dense(ind,ind)\n",
    "    Act2 = Sigmoid()\n",
    "\n",
    "    Layer3 = Dense(ind,1)\n",
    "    Act3 = Sigmoid()\n",
    "\n",
    "    Loss =  Mean_Square_Error_loss()\n",
    "    Optimizer = SGD()\n",
    "    print(\"\\nneuron number in hidden layer = \",ind)\n",
    "    \n",
    "    for epoch in range(10):\n",
    "            #forward\n",
    "            Layer1.forward(x_train)\n",
    "            Act1.forward(Layer1.output)\n",
    "            Layer2.forward(Act1.output)\n",
    "            Act2.forward(Layer2.output)\n",
    "            Layer3.forward(Act2.output)\n",
    "            Act3.forward(Layer3.output)\n",
    "            loss = Loss.forward(Act3.output,y_train)\n",
    "            \n",
    "            print(f'Epoch:{epoch}')\n",
    "            print(f'Loss: {loss}')\n",
    "            print('--------------------------')\n",
    "\n",
    "            #backward\n",
    "            Loss.backward(Act3.output,y_train)\n",
    "            Act3.backward(Loss.b_output)\n",
    "            Layer3.backward(Act3.b_output)\n",
    "            Act2.backward(Layer3.b_output)\n",
    "            Layer2.backward(Act2.b_output)\n",
    "            Act1.backward(Layer2.b_output)\n",
    "            Layer1.backward(Act1.b_output)\n",
    "\n",
    "            #update params\n",
    "            Optimizer.update(Layer1)\n",
    "            Optimizer.update(Layer2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "29c58383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Loss for new data: [2.843862]\n",
      "--------------------------\n",
      "Final Loss for new data: [2.57800833]\n",
      "--------------------------\n",
      "Final Loss for new data: [2.56851098]\n",
      "--------------------------\n",
      "Final Loss for new data: [2.59791869]\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "i =[1,2,4,8]\n",
    "for ind in i:\n",
    "    x_train = np.random.uniform(-4, 4, 200).reshape(-1,1)\n",
    "    y_train = (np.sin((x_train*ind*np.pi/2)) - 1).reshape(-1,1)\n",
    "\n",
    "    Layer1.forward(x_train)\n",
    "    Act1.forward(Layer1.output)\n",
    "    Layer2.forward(Act1.output)\n",
    "    Act2.forward(Layer2.output)\n",
    "    Layer3.forward(Act2.output)\n",
    "    Act3.forward(Layer3.output)\n",
    "    loss = Loss.forward(Act3.output,y_train)\n",
    "\n",
    "    print(f'Final Loss for new data: {loss}')\n",
    "    print('--------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
