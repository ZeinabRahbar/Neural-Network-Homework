{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d10bc854",
   "metadata": {},
   "source": [
    "# 3-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e6b2163",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09006455",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for i in range(9):\n",
    "    for j in range(9):\n",
    "        x_train.append([i,j])\n",
    "        if [i,j] == [1,5] or  [i,j] ==[2,2] or  [i,j] ==[2,4] or  [i,j] ==[3,1] or  [i,j] ==[3,1] or [i,j] == [3,2] or  [i,j] ==[3,3] or  [i,j] ==[4,2] or  [i,j] ==[5,5] or  [i,j] ==[6,6] or  [i,j] ==[7,7]:\n",
    "            y_train.append([1])\n",
    "        else:\n",
    "            y_train.append([2])\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ca120de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Accuracy = 82.71604938271605\n",
      "epoch 1\n",
      "Accuracy = 82.71604938271605\n",
      "epoch 2\n",
      "Accuracy = 79.01234567901234\n",
      "epoch 3\n",
      "Accuracy = 81.48148148148148\n",
      "epoch 4\n",
      "Accuracy = 82.71604938271605\n",
      "epoch 5\n",
      "Accuracy = 79.01234567901234\n",
      "epoch 6\n",
      "Accuracy = 81.48148148148148\n",
      "epoch 7\n",
      "Accuracy = 82.71604938271605\n",
      "epoch 8\n",
      "Accuracy = 79.01234567901234\n",
      "epoch 9\n",
      "Accuracy = 81.48148148148148\n"
     ]
    }
   ],
   "source": [
    "class Dense:\n",
    "    def __init__(self,n_inputs,n_neurons):\n",
    "        self.w = np.random.uniform(0,1,size=(n_inputs,n_neurons))\n",
    "        self.b =  np.random.uniform(0,1,size= n_neurons)\n",
    "    \n",
    "    def forward(self,inputs):\n",
    "        self.output = np.dot(inputs,self.w)+self.b\n",
    "\n",
    "class UnitStep:\n",
    "     def __init__(self):\n",
    "        pass\n",
    "     def forward(self,inputs):\n",
    "        self.output=np.heaviside(inputs,0)\n",
    "            \n",
    "\n",
    "Layer1 = Dense(2,2)\n",
    "Act1 = UnitStep()\n",
    "\n",
    "Layer2 = Dense(2,1)\n",
    "Act2= UnitStep()\n",
    "\n",
    "epoch = 10\n",
    "c = 0\n",
    "alpha = 0.1\n",
    "\n",
    "for i in range(epoch):\n",
    "    L = []\n",
    "    for j in range(len(y_train)):\n",
    "        \n",
    "        Layer1.forward(x_train[j])\n",
    "        Act1.forward(Layer1.output)\n",
    "        Layer2.forward(Act1.output)\n",
    "        Act2.forward(Layer2.output)\n",
    "        \n",
    "        if Act2.output == 0:\n",
    "            Act2.output = 1\n",
    "        else:\n",
    "            Act2.output = 2\n",
    "            \n",
    "            \n",
    "       \n",
    "        e = y_train[j] - Act2.output\n",
    "        e = np.array(e*alpha)\n",
    "        \n",
    "        k = [(e*x_train[j][0]) ,  (e*x_train[j][1])] \n",
    "\n",
    "        Layer2.w = Layer2.w + k\n",
    "        Layer2.b = Layer2.b + e\n",
    "       \n",
    "        L.append(Act2.output)\n",
    "\n",
    "    c = 0\n",
    "    L = np.array(L)\n",
    "    for f in range(len(y_train)):\n",
    "        if L[f]==y_train[f]:\n",
    "            c = c+1\n",
    "    print(\"epoch\", i)\n",
    "    print(\"Accuracy =\",c/len(y_train)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37d31ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer1.w =\n",
      " [[0.62464032 0.64776587]\n",
      " [0.94896237 0.35917579]]\n",
      "Layer1.b =\n",
      " [0.64439249 0.93333491]\n",
      "Layer2.w =\n",
      " [[-2.57200853]\n",
      " [ 4.58367973]]\n",
      "Layer2.b =\n",
      " [-1.08136961]\n"
     ]
    }
   ],
   "source": [
    "print('Layer1.w =\\n',Layer1.w)\n",
    "print('Layer1.b =\\n',Layer1.b)\n",
    "\n",
    "\n",
    "print('Layer2.w =\\n',Layer2.w)\n",
    "print('Layer2.b =\\n',Layer2.b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03cada6a",
   "metadata": {},
   "source": [
    "# 3-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c88fe84",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense:\n",
    "    def __init__(self,n_inputs,n_neurons):\n",
    "       \n",
    "        self.w=np.random.randint(-2, 2, (n_inputs, n_neurons))\n",
    "        self.b = np.random.randint(-2, 2, (1, n_neurons))    #b\n",
    "        self.weight_history = 0\n",
    "        self.bias_history = 0\n",
    "    \n",
    "    def forward(self,inputs):\n",
    "        self.input = inputs  #p\n",
    "        self.output = np.dot(inputs,self.w)+self.b\n",
    "        #print(self.output)\n",
    "        \n",
    "    def backward(self,b_input):\n",
    "        #print(type(b_input))\n",
    "        #print(b_input)\n",
    "        #print(type(self.w))\n",
    "        #print(self.w)\n",
    "        self.b_output = np.dot(b_input,self.w.T)\n",
    "        self.g_w = np.dot(self.input.T,b_input)\n",
    "        self.g_b = np.sum(b_input,axis=0,keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9de977a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear:\n",
    "    def forward(self,inputs):\n",
    "        self.input = inputs\n",
    "        self.output = inputs\n",
    "    def backward(self,b_input):\n",
    "        self.b_output = b_input  \n",
    "\n",
    "class Sigmoid:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def forward(self,inputs):\n",
    "        self.input = inputs\n",
    "        self.output = 1/(1+np.exp(-inputs))\n",
    "    def backward(self,b_input):\n",
    "        self.b_output = b_input*self.output*(1-self.output)\n",
    "\n",
    "class ReLU:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def forward(self,inputs):\n",
    "        self.output = np.maximum(0,inputs)\n",
    "        self.input = inputs\n",
    "    \n",
    "    def backward(self,b_input):\n",
    "        self.b_output = b_input\n",
    "        self.b_output[self.input<=0] = 0\n",
    "\n",
    "class SGD:\n",
    "    def __init__(self,learning_rate = 0.001,momentum=0):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.momentum = momentum\n",
    "    def update(self,layer):\n",
    "        if self.momentum:\n",
    "            weight_update = self.momentum*layer.weight_history\\\n",
    "            + (1-self.momentum)*(-self.learning_rate*layer.g_w)\n",
    "            layer.weight_update = weight_update\n",
    "            bias_update = self.momentum*layer.weight_history\\\n",
    "            + (1-self.momentum)*(-self.learning_rate*layer.g_b)\n",
    "            layer.bias_update = bias_update\n",
    "        else:\n",
    "            weight_update = - self.learning_rate*layer.g_w\n",
    "            bias_update = - self.learning_rate*layer.g_b\n",
    "        layer.w = layer.w + weight_update\n",
    "        layer.b = layer.b + bias_update\n",
    "\n",
    "class Mean_Square_Error_loss:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def forward(self,y_predict,y_true):\n",
    "        return np.mean((y_true-y_predict)**2,axis = 0)\n",
    "    \n",
    "    def backward(self,y_predict,y_true):\n",
    "        self.b_output = -2*(y_true-y_predict)\n",
    "\n",
    "class Categorical_cross_entroy_loss:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def forward(self,softmax_output,class_label):\n",
    "        softmax_output = np.clip(softmax_output,0.000001,0.999999)\n",
    "        cc = np.sum(softmax_output*class_label,axis=1)\n",
    "        return np.sum(-np.log(cc)).reshape(-1)\n",
    "\n",
    "    \n",
    "    def backward(self,softmax_output,class_label):\n",
    "        softmax_output = np.clip(softmax_output,0.000001,0.999999)\n",
    "        self.b_output = -class_label/softmax_output\n",
    "\n",
    "class Softmax:\n",
    "\n",
    "    def forward(self,inputs):\n",
    "        neuron_output = np.exp(inputs-np.max(inputs,keepdims=True))\n",
    "        self.output = neuron_output/np.sum(neuron_output,keepdims=True)\n",
    "    \n",
    "    def backward(self,b_input):\n",
    "        self.b_output = b_input\n",
    "        for i , (item1 , item2) in enumerate(zip(self.output,b_input)):\n",
    "            item1 = item1.reshape(-1,1)\n",
    "            #sd means softmax derivative\n",
    "            sd = np.diagflat(item1)-np.dot(item1,item1.T)\n",
    "            #if j=k: S_j-(S_j)^2\n",
    "            #if j!=k: 0-(S_j)*(S_k)\n",
    "            self.b_output[i] = np.dot(sd,item2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "798a829e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datatrain = pd.read_csv(\"mnist_train.csv\",delimiter=\",\", dtype=str)\n",
    "datatest = pd.read_csv(\"mnist_test.csv\",delimiter=\",\", dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81915ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "datatrain = np.array(datatrain)\n",
    "datatest = np.array(datatest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "137b0e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = datatrain[0:55000].T[1:].T\n",
    "t = datatrain[0:55000].T[0].reshape(-1,1)\n",
    "\n",
    "pv = datatrain[0:5000].T[1:].T\n",
    "tv = datatrain[0:5000].T[0].reshape(-1,1)\n",
    "\n",
    "p_test = datatest[0:500].T[1:].T\n",
    "t_test = datatest[0:500].T[0].reshape(-1,1)\n",
    "\n",
    "x_train=p\n",
    "y_train=t\n",
    "\n",
    "x_valid=pv\n",
    "y_valid=tv\n",
    "\n",
    "x_test=p_test\n",
    "y_test=t_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50e09f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype(int)\n",
    "x_test = x_test.astype(int)\n",
    "y_test = y_test.astype(int)\n",
    "x_train = x_train.astype(int)\n",
    "x_valid =  x_valid.astype(int)\n",
    "y_valid = y_valid.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757c5228",
   "metadata": {},
   "source": [
    "# a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a79bf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Layer1 = Dense(784,10)\n",
    "Act1 = Softmax()\n",
    "Loss = Categorical_cross_entroy_loss()\n",
    "Optimizer = SGD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "31cd365c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ansar9811291\\AppData\\Local\\Temp\\ipykernel_5516\\784203532.py:62: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.sum(-np.log(cc)).reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988010132231405\n",
      "Epoch:1\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:2\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:3\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:4\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:5\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:6\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:7\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:8\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:9\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:10\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:11\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:12\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:13\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:14\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:15\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:16\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:17\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:18\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:19\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:20\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:21\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:22\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:23\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:24\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:25\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:26\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:27\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:28\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:29\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:30\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:31\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:32\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:33\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:34\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:35\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:36\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:37\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:38\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:39\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:40\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:41\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:42\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:43\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:44\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:45\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:46\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:47\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:48\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:49\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:50\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:51\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:52\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:53\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:54\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:55\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:56\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:57\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:58\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:59\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:60\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:61\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:62\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:63\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:64\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:65\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:66\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:67\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:68\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:69\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:70\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:71\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:72\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:73\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:74\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:75\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:76\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:77\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:78\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:79\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:80\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:81\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:82\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:83\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:84\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:85\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:86\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:87\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:88\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:89\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:90\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:91\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:92\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:93\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:94\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:95\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:96\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:97\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:98\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n",
      "Epoch:99\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988000105785124\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "c=0\n",
    "for epoch in range(100):\n",
    "    #forward\n",
    "    Layer1.forward(x_train)\n",
    "    Act1.forward(Layer1.output)\n",
    "    loss_train = Loss.forward(Act1.output,y_train)\n",
    "    \n",
    "    # Report\n",
    "    y_predict = np.argmax(Act1.output,axis = 1)\n",
    "    accuracy = np.mean(y_train == y_predict)\n",
    "    \n",
    "    #backward\n",
    "    Loss.backward(Act1.output,y_train)\n",
    "    Act1.backward(Loss.b_output)\n",
    "    Layer1.backward(Act1.b_output)\n",
    "    \n",
    "    print(f'Epoch:{epoch}')\n",
    "    print(f'Loss: {loss_train}')\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    \n",
    "\n",
    "    #update params\n",
    "    Optimizer.update(Layer1)\n",
    "    \n",
    "    plt.scatter(epoch,accuracy, c= 'blue')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "81593542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:99\n",
      "Accuracy for test data: 0.084416\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "Layer1.forward(x_test)\n",
    "Act1.forward(Layer1.output)\n",
    "    \n",
    "    \n",
    "# Report\n",
    "y_predict_test = np.argmax(Act1.output,axis = 1)\n",
    "accuracy_test = np.mean(y_test == y_predict_test)\n",
    "print(f'Epoch:{epoch}')\n",
    "print(f'Accuracy for test data: {accuracy_test}')\n",
    "print('--------------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b23f7d7",
   "metadata": {},
   "source": [
    "# b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2e310ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Layer1 = Dense(784,30)\n",
    "Act1=ReLU()\n",
    "\n",
    "Layer2 = Dense(30,10)\n",
    "Act2= Softmax()\n",
    "\n",
    "Loss = Categorical_cross_entroy_loss()\n",
    "Optimizer = SGD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "32f976a7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ansar9811291\\AppData\\Local\\Temp\\ipykernel_5516\\784203532.py:62: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.sum(-np.log(cc)).reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0987828852892562\n",
      "Epoch:1\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:2\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:3\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:4\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:5\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:6\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:7\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:8\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:9\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:10\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:11\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:12\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:13\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:14\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:15\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:16\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:17\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:18\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:19\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:20\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:21\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:22\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:23\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:24\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:25\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:26\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:27\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:28\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:29\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:30\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:31\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:32\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:33\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:34\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:35\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:36\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:37\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:38\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:39\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:40\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:41\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:42\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:43\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:44\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:45\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:46\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:47\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:48\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:49\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:50\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:51\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:52\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:53\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:54\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:55\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:56\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:57\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:58\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:59\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:60\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:61\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:62\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:63\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:64\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:65\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:66\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:67\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:68\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:69\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:70\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:71\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:72\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:73\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:74\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:75\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:76\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:77\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:78\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:79\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:80\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:81\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:82\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:83\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:84\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:85\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:86\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:87\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:88\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:89\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:90\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:91\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:92\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:93\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:94\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:95\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:96\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:97\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:98\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n",
      "Epoch:99\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09878294876033057\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "c=0\n",
    "for epoch in range(100):\n",
    "    #forward\n",
    "    Layer1.forward(x_train)\n",
    "    Act1.forward(Layer1.output)\n",
    "    Layer2.forward(Act1.output)\n",
    "    Act2.forward(Layer2.output)\n",
    "    loss_train = Loss.forward(Act2.output,y_train)\n",
    "    \n",
    "    y_predict = np.argmax(Act1.output,axis = 1)\n",
    "    accuracy = np.mean(y_train == y_predict)\n",
    "    \n",
    "    #backward\n",
    "    Loss.backward(Act2.output,y_train)\n",
    "    Act2.backward(Loss.b_output)\n",
    "    Layer2.backward(Act2.b_output)\n",
    "    Act1.backward(Layer2.b_output)\n",
    "    Layer1.backward(Act1.b_output)\n",
    "    \n",
    "    print(f'Epoch:{epoch}')\n",
    "    print(f'Loss: {loss_train}')\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "\n",
    "    #update params\n",
    "    Optimizer.update(Layer1)\n",
    "    Optimizer.update(Layer2)\n",
    "    \n",
    "    plt.scatter(epoch,accuracy, c= 'blue')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a47486d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:99\n",
      "Accuracy for test data: 0.0842\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "#forward\n",
    "Layer1.forward(x_test)\n",
    "Act1.forward(Layer1.output)\n",
    "Layer2.forward(Act1.output)\n",
    "Act2.forward(Layer2.output)\n",
    "# Report\n",
    "y_predict = np.argmax(Act2.output,axis = 1)\n",
    "accuracy = np.mean(y_test == y_predict)\n",
    "print(f'Epoch:{epoch}')\n",
    "print(f'Accuracy for test data: {accuracy}')\n",
    "print('--------------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe7ad21",
   "metadata": {},
   "source": [
    "# c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e6a498fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Layer1 = Dense(784,30)\n",
    "Act1=ReLU()\n",
    "Layer2 = Dense(30,10)\n",
    "Act2= Softmax()\n",
    "\n",
    "Layer3 = Dense(10,10)\n",
    "Act3= Softmax()\n",
    "\n",
    "Loss = Categorical_cross_entroy_loss()\n",
    "Optimizer = SGD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "91f51d02",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ansar9811291\\AppData\\Local\\Temp\\ipykernel_5516\\784203532.py:62: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.sum(-np.log(cc)).reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "Epoch:1\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:2\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:3\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:4\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:5\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:6\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:7\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:8\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:9\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:10\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:11\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:12\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:13\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:14\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:15\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:16\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:17\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:18\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:19\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:20\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:21\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:22\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:23\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:24\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:25\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:26\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:27\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:28\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:29\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:30\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:31\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:32\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:33\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:34\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:35\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:36\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:37\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:38\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:39\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:40\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:41\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:42\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:43\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:44\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:45\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:46\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:47\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:48\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:49\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:50\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:51\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:52\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:53\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:54\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:55\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:56\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:57\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:58\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:59\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:60\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:61\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:62\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:63\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:64\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:65\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:66\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:67\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:68\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:69\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:70\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:71\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:72\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:73\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:74\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:75\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:76\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:77\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:78\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:79\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:80\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:81\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:82\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:83\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:84\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:85\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:86\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:87\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:88\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:89\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:90\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:91\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:92\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:93\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:94\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:95\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:96\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:97\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:98\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n",
      "Epoch:99\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880008198347108\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "c=0\n",
    "for epoch in range(100):\n",
    "    #forward\n",
    "    Layer1.forward(x_train)\n",
    "    Act1.forward(Layer1.output)\n",
    "    \n",
    "    Layer2.forward(Act1.output)\n",
    "    Act2.forward(Layer2.output)\n",
    "    \n",
    "    Layer3.forward(Act2.output)\n",
    "    Act3.forward(Layer3.output)\n",
    "    \n",
    "    loss_train = Loss.forward(Act3.output,y_train)\n",
    "    \n",
    "    # Report\n",
    "    y_predict_train = np.argmax(Act2.output,axis = 1)\n",
    "    accuracy_train = np.mean(y_train == y_predict_train)\n",
    "    \n",
    "    #backward\n",
    "    Loss.backward(Act3.output,y_train)\n",
    "    Act3.backward(Loss.b_output)\n",
    "    Layer3.backward(Act3.b_output)\n",
    "    \n",
    "    Act2.backward(Layer3.b_output)\n",
    "    Layer2.backward(Act2.b_output)\n",
    "    \n",
    "    Act1.backward(Layer2.b_output)\n",
    "    Layer1.backward(Act1.b_output)\n",
    "\n",
    "    print(f'Epoch:{epoch}')\n",
    "    print(f'Loss: {loss_train}')\n",
    "    print(f'Accuracy: {accuracy_train}')\n",
    "    \n",
    "    #update params\n",
    "    Optimizer.update(Layer1)\n",
    "    Optimizer.update(Layer2)\n",
    "    Optimizer.update(Layer3)\n",
    "    \n",
    "    plt.scatter(epoch, accuracy, c= 'blue')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6f50b11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:99\n",
      "Accuracy for test data: 0.084104\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "Layer1.forward(x_test)\n",
    "Act1.forward(Layer1.output)\n",
    "\n",
    "Layer2.forward(Act1.output)\n",
    "Act2.forward(Layer2.output)\n",
    "\n",
    "Layer3.forward(Act2.output)\n",
    "Act3.forward(Layer3.output)\n",
    "    \n",
    "# Report\n",
    "y_predict = np.argmax(Act2.output,axis = 1)\n",
    "accuracy = np.mean(y_test == y_predict)\n",
    "\n",
    "print(f'Epoch:{epoch}')\n",
    "print(f'Accuracy for test data: {accuracy}')\n",
    "print('--------------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f936f9",
   "metadata": {},
   "source": [
    "# 3-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5be47f2",
   "metadata": {},
   "source": [
    "# Momentom SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da5231a",
   "metadata": {},
   "source": [
    "# a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "94088748",
   "metadata": {},
   "outputs": [],
   "source": [
    "Layer1 = Dense(784,10)\n",
    "Act1 = Softmax()\n",
    "Loss = Categorical_cross_entroy_loss()\n",
    "Optimizer = SGD(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3446d2ad",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ansar9811291\\AppData\\Local\\Temp\\ipykernel_5516\\784203532.py:62: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.sum(-np.log(cc)).reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09882031801652892\n",
      "--------------------------\n",
      "Epoch:1\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:2\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:3\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:4\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:5\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:6\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:7\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:8\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:9\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:10\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:11\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:12\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:13\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:14\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:15\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:16\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:17\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:18\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:19\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:20\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:21\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:22\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:23\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:24\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:25\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:26\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:27\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:28\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:29\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:30\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:31\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:32\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:33\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:34\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:35\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:36\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:37\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:38\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:39\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:40\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:41\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:42\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:43\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:44\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:45\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:46\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:47\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:48\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:49\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:50\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:51\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:52\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:53\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:54\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:55\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:56\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:57\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:58\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:59\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:60\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:61\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:62\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:63\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:64\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:65\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:66\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:67\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:68\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:69\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:70\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:71\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:72\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:73\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:74\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:75\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:76\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:77\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:78\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:79\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:80\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:81\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:82\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:83\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:84\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:85\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:86\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:87\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:88\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:89\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:90\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:91\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:92\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:93\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:94\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:95\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:96\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:97\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:98\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n",
      "Epoch:99\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880334347107438\n",
      "--------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjUAAAGdCAYAAADqsoKGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAmA0lEQVR4nO3df1CUd2LH8Q8/skBOFxs9Icgve7EhBIUEBeF60mm2omXaUHMNtV7krHeJLXgSZmyVRL028UinYrxDeo43c7k6nsWQBm7PWjpIPC8ZUQJiLvSMpE2meupCPEZW0QDHfvuHk81tJcZFBfn6fs08k/Ds99n9Pt9M3Pc87D6GGGOMAAAAJrjQ8Z4AAADArUDUAAAAKxA1AADACkQNAACwAlEDAACsQNQAAAArEDUAAMAKRA0AALBC+HhPYKz4fD6dPXtWkydPVkhIyHhPBwAA3ABjjC5evKi4uDiFhl7/WsxdEzVnz55VQkLCeE8DAACMwunTpxUfH3/dMXdN1EyePFnS1UVxOp3jPBsAAHAjvF6vEhIS/O/j13PXRM0nv3JyOp1EDQAAE8yNfHSEDwoDAAArEDUAAMAKRA0AALACUQMAAKxA1AAAACsQNQAAwApEDQAAsAJRAwAArEDUAAAAKxA1AADACkQNAACwAlEDAACsQNQAAAArEDUAAMAKRA0AALACUQMAAKxA1AAAACsQNQAAwApEDQAAsAJRAwAArEDUAAAAKxA1AADACqOKmpqaGiUnJysyMlLZ2dlqbW297vi6ujqlpKQoMjJSs2fP1v79+wMev3TpkkpLSxUfH6+oqCilpqZqx44dAWM8Ho+eeuopxcbG6gtf+IIeffRR/du//dtopg8AACwUdNTs3btX5eXl2rRpk44dO6b09HTl5+erp6dnxPGHDx/W0qVLtXLlSnV0dKiwsFCFhYXq7Oz0jykvL1djY6N2796tEydOqKysTKWlpXK73f4xy5cv18mTJ+V2u/Xuu+9qyZIlevLJJ9XR0TGK0wYAALYJMcaYYA7Izs7WvHnztH37dkmSz+dTQkKCVq9erXXr1l0zvqioSP39/dq3b59/3/z585WRkeG/GpOWlqaioiJt2LDBPyYzM1OLFy/Wiy++KEmaNGmSvv/97+upp57yj5k6dar+8R//Ud/4xjc+d95er1fR0dHq6+uT0+kM5pQBAMA4Ceb9O6grNYODg2pvb5fL5fr0CUJD5XK51NLSMuIxLS0tAeMlKT8/P2B8bm6u3G63zpw5I2OMDh48qK6uLi1cuDBgzN69e9Xb2yufz6fa2lp9/PHH+oM/+IMRX3dgYEBerzdgAwAA9goqas6fP6/h4WHFxMQE7I+JiZHH4xnxGI/H87njq6urlZqaqvj4eDkcDi1atEg1NTVasGCBf8yrr76qoaEhTZ06VREREXrmmWdUX1+vBx54YMTXraysVHR0tH9LSEgI5lQBAMAEc0d8+6m6ulpHjhyR2+1We3u7qqqqVFJSogMHDvjHbNiwQRcuXNCBAwfU1tam8vJyPfnkk3r33XdHfM7169err6/Pv50+fXqsTgcAAIyD8GAGT5s2TWFhYeru7g7Y393drdjY2BGPiY2Nve74K1euqKKiQvX19SooKJAkzZkzR8ePH9eWLVvkcrn0P//zP9q+fbs6Ozv18MMPS5LS09P15ptvqqam5ppvSklSRESEIiIigjk9AAAwgQV1pcbhcCgzM1PNzc3+fT6fT83NzcrJyRnxmJycnIDxktTU1OQfPzQ0pKGhIYWGBk4lLCxMPp9PknT58uWrk73OGAAAcHcL6kqNdPXr18XFxZo7d66ysrK0bds29ff3a8WKFZKufvV6xowZqqyslCStWbNGeXl5qqqqUkFBgWpra9XW1qadO3dKkpxOp/Ly8rR27VpFRUUpKSlJhw4d0q5du7R161ZJUkpKih544AE988wz2rJli6ZOnaqGhgY1NTUFfKsKAADcxcwoVFdXm8TERONwOExWVpY5cuSI/7G8vDxTXFwcMP7VV181v/d7v2ccDod5+OGHzb//+78HPH7u3Dnz9a9/3cTFxZnIyEjz4IMPmqqqKuPz+fxjurq6zJIlS8z06dPNvffea+bMmWN27dp1w3Pu6+szkkxfX99oThkAAIyDYN6/g75PzUTFfWoAAJh4btt9agAAAO5URA0AALACUQMAAKxA1AAAACsQNQAAwApEDQAAsAJRAwAArEDUAAAAKxA1AADACkQNAACwAlEDAACsQNQAAAArEDUAAMAKRA0AALACUQMAAKxA1AAAACsQNQAAwApEDQAAsAJRAwAArEDUAAAAKxA1AADACkQNAACwAlEDAACsQNQAAAArEDUAAMAKRA0AALACUQMAAKxA1AAAACsQNQAAwApEDQAAsAJRAwAArEDUAAAAKxA1AADACkQNAACwAlEDAACsQNQAAAArEDUAAMAKRA0AALACUQMAAKxA1AAAACsQNQAAwApEDQAAsAJRAwAArEDUAAAAKxA1AADACkQNAACwAlEDAACsQNQAAAArEDUAAMAKRA0AALACUQMAAKxA1AAAACsQNQAAwApEDQAAsAJRAwAArEDUAAAAKxA1AADACkQNAACwAlEDAACsQNQAAAArEDUAAMAKRA0AALACUQMAAKxA1AAAACsQNQAAwApEDQAAsAJRAwAArEDUAAAAKxA1AADACqOKmpqaGiUnJysyMlLZ2dlqbW297vi6ujqlpKQoMjJSs2fP1v79+wMev3TpkkpLSxUfH6+oqCilpqZqx44d1zxPS0uL/vAP/1Bf+MIX5HQ6tWDBAl25cmU0pwAAACwTdNTs3btX5eXl2rRpk44dO6b09HTl5+erp6dnxPGHDx/W0qVLtXLlSnV0dKiwsFCFhYXq7Oz0jykvL1djY6N2796tEydOqKysTKWlpXK73f4xLS0tWrRokRYuXKjW1la9/fbbKi0tVWgoF5sAAIAUYowxwRyQnZ2tefPmafv27ZIkn8+nhIQErV69WuvWrbtmfFFRkfr7+7Vv3z7/vvnz5ysjI8N/NSYtLU1FRUXasGGDf0xmZqYWL16sF1980X/MH/3RH+mFF14I/iwleb1eRUdHq6+vT06nc1TPAQAAxlYw799BXeYYHBxUe3u7XC7Xp08QGiqXy6WWlpYRj2lpaQkYL0n5+fkB43Nzc+V2u3XmzBkZY3Tw4EF1dXVp4cKFkqSenh4dPXpU06dPV25urmJiYpSXl6e33nrrM+c6MDAgr9cbsAEAAHsFFTXnz5/X8PCwYmJiAvbHxMTI4/GMeIzH4/nc8dXV1UpNTVV8fLwcDocWLVqkmpoaLViwQJL0wQcfSJK+/e1v65vf/KYaGxv16KOP6rHHHtP7778/4utWVlYqOjravyUkJARzqgAAYIK5Iz6QUl1drSNHjsjtdqu9vV1VVVUqKSnRgQMHJF39FZckPfPMM1qxYoUeeeQRvfzyy3rwwQf1wx/+cMTnXL9+vfr6+vzb6dOnx+x8AADA2AsPZvC0adMUFham7u7ugP3d3d2KjY0d8ZjY2Njrjr9y5YoqKipUX1+vgoICSdKcOXN0/PhxbdmyRS6XS/fff78kKTU1NeB5HnroIZ06dWrE142IiFBEREQwpwcAACawoK7UOBwOZWZmqrm52b/P5/OpublZOTk5Ix6Tk5MTMF6Smpqa/OOHhoY0NDR0zbeYwsLC/FdokpOTFRcXp5MnTwaM6erqUlJSUjCnAAAALBXUlRrp6tevi4uLNXfuXGVlZWnbtm3q7+/XihUrJEnLly/XjBkzVFlZKUlas2aN8vLyVFVVpYKCAtXW1qqtrU07d+6UJDmdTuXl5Wnt2rWKiopSUlKSDh06pF27dmnr1q2SpJCQEK1du1abNm1Senq6MjIy9C//8i9677339Nprr92qtQAAABNY0FFTVFSkjz76SBs3bpTH41FGRoYaGxv9HwY+depUwFWX3Nxc7dmzR88//7wqKio0a9YsNTQ0KC0tzT+mtrZW69ev17Jly9Tb26ukpCRt3rxZq1at8o8pKyvTxx9/rGeffVa9vb1KT09XU1OTvvSlL93M+QMAAEsEfZ+aiYr71AAAMPHctvvUAAAA3KmIGgAAYAWiBgAAWIGoAQAAViBqAACAFYgaAABgBaIGAABYgagBAABWIGoAAIAViBoAAGAFogYAAFiBqAEAAFYgagAAgBWIGgAAYAWiBgAAWIGoAQAAViBqAACAFYgaAABgBaIGAABYgagBAABWIGoAAIAViBoAAGAFogYAAFiBqAEAAFYgagAAgBWIGgAAYAWiBgAAWIGoAQAAViBqAACAFYgaAABgBaIGAABYgagBAABWIGoAAIAViBoAAGAFogYAAFiBqAEAAFYgagAAgBWIGgAAYAWiBgAAWIGoAQAAViBqAACAFYgaAABgBaIGAABYgagBAABWIGoAAIAViBoAAGAFogYAAFiBqAEAAFYgagAAgBWIGgAAYAWiBgAAWIGoAQAAViBqAACAFYgaAABgBaIGAABYgagBAABWIGoAAIAViBoAAGAFogYAAFiBqAEAAFYgagAAgBWIGgAAYAWiBgAAWCF8vCcw0Q0PS2++KZ07J91/v5SbKx0+/OnPX/nK1XG/PWakfTdy3FiOGe/XZ47MkTlyHsxx4s7xK1+RwsI05oiam/D669KaNdKvfvXpvrCwq6HzialTr/7z17++/r4bOW4sx4z36zNH5sgcOQ/mOHHnGB8vffe70pIlGlMhxhgzti85Prxer6Kjo9XX1yen03nTz/f669JXvyrdHasHAMCNCwm5+s/XXrv5sAnm/ZvP1IzC8PDVKzQEDQAA1/rk/bGsLPCqzu1G1IzCm28G/soJAAAEMkY6ffrqe+ZYGVXU1NTUKDk5WZGRkcrOzlZra+t1x9fV1SklJUWRkZGaPXu29u/fH/D4pUuXVFpaqvj4eEVFRSk1NVU7duwY8bmMMVq8eLFCQkLU0NAwmunftHPnxuVlAQCYcMbyPTPoqNm7d6/Ky8u1adMmHTt2TOnp6crPz1dPT8+I4w8fPqylS5dq5cqV6ujoUGFhoQoLC9XZ2ekfU15ersbGRu3evVsnTpxQWVmZSktL5Xa7r3m+bdu2KeSTX9aNk/vvH9eXBwBgwhjT90wTpKysLFNSUuL/eXh42MTFxZnKysoRxz/55JOmoKAgYF92drZ55pln/D8//PDD5h/+4R8Cxjz66KPmueeeC9jX0dFhZsyYYc6dO2ckmfr6+hued19fn5Fk+vr6bviYz/Kb3xgTH29MSIgxVy+wsbGxsbGxsf32FhJiTELC1ffMmxHM+3dQV2oGBwfV3t4ul8vl3xcaGiqXy6WWlpYRj2lpaQkYL0n5+fkB43Nzc+V2u3XmzBkZY3Tw4EF1dXVp4cKF/jGXL1/WX/7lX6qmpkaxsbHBTPuWCwu7+lU16dNPeAMAgKs+eW/ctm1s71cTVNScP39ew8PDiomJCdgfExMjj8cz4jEej+dzx1dXVys1NVXx8fFyOBxatGiRampqtGDBAv+YZ599Vrm5uXr88cdvaK4DAwPyer0B2620ZMnVr6rNmBG4////x5s69dPv8F9v340cN5Zjxvv1mSNzvJNe35Y52nIe4/36zPHzx8TH35qvcwfrjrj5XnV1tY4cOSK3262kpCT9/Oc/V0lJieLi4uRyueR2u/XGG2+oo6Pjhp+zsrJSf//3f38bZ331P9bjj99Zd3GcCHeaZI7MkTneuWPG+/WZox1zHK87Cgd1873BwUHde++9eu2111RYWOjfX1xcrAsXLugnP/nJNcckJiaqvLxcZWVl/n2bNm1SQ0OD3nnnHV25ckXR0dGqr69XQUGBf8w3vvEN/epXv1JjY6PKysr0ve99T6Ghn15YGh4eVmhoqL7yla/oZz/72TWvOzAwoIGBAf/PXq9XCQkJt+zmewAA4Pa7bTffczgcyszMVHNzs3+fz+dTc3OzcnJyRjwmJycnYLwkNTU1+ccPDQ1paGgoIFgkKSwsTD6fT5K0bt06/eIXv9Dx48f9myS9/PLLeuWVV0Z83YiICDmdzoANAADYK+hfP5WXl6u4uFhz585VVlaWtm3bpv7+fq1YsUKStHz5cs2YMUOVlZWSpDVr1igvL09VVVUqKChQbW2t2tratHPnTkmS0+lUXl6e1q5dq6ioKCUlJenQoUPatWuXtm7dKkmKjY0d8cPBiYmJmjlz5qhPHgAA2CPoqCkqKtJHH32kjRs3yuPxKCMjQ42Njf4PA586dSrgqktubq727Nmj559/XhUVFZo1a5YaGhqUlpbmH1NbW6v169dr2bJl6u3tVVJSkjZv3qxVq1bdglMEAAB3A/5CSwAAcMfiL7QEAAB3HaIGAABYgagBAABWIGoAAIAViBoAAGAFogYAAFiBqAEAAFYgagAAgBWIGgAAYAWiBgAAWIGoAQAAViBqAACAFYgaAABgBaIGAABYgagBAABWIGoAAIAViBoAAGAFogYAAFiBqAEAAFYgagAAgBWIGgAAYAWiBgAAWIGoAQAAViBqAACAFYgaAABgBaIGAABYgagBAABWIGoAAIAViBoAAGAFogYAAFiBqAEAAFYgagAAgBWIGgAAYAWiBgAAWIGoAQAAViBqAACAFYgaAABgBaIGAABYgagBAABWIGoAAIAViBoAAGAFogYAAFiBqAEAAFYgagAAgBWIGgAAYAWiBgAAWIGoAQAAViBqAACAFYgaAABgBaIGAABYgagBAABWIGoAAIAViBoAAGAFogYAAFiBqAEAAFYgagAAgBWIGgAAYAWiBgAAWIGoAQAAViBqAACAFYgaAABgBaIGAABYgagBAABWIGoAAIAViBoAAGAFogYAAFiBqAEAAFYgagAAgBWIGgAAYIVRRU1NTY2Sk5MVGRmp7Oxstba2Xnd8XV2dUlJSFBkZqdmzZ2v//v0Bj1+6dEmlpaWKj49XVFSUUlNTtWPHDv/jvb29Wr16tR588EFFRUUpMTFR3/rWt9TX1zea6QMAAAsFHTV79+5VeXm5Nm3apGPHjik9PV35+fnq6ekZcfzhw4e1dOlSrVy5Uh0dHSosLFRhYaE6Ozv9Y8rLy9XY2Kjdu3frxIkTKisrU2lpqdxutyTp7NmzOnv2rLZs2aLOzk796Ec/UmNjo1auXDnK0wYAALYJMcaYYA7Izs7WvHnztH37dkmSz+dTQkKCVq9erXXr1l0zvqioSP39/dq3b59/3/z585WRkeG/GpOWlqaioiJt2LDBPyYzM1OLFy/Wiy++OOI86urq9LWvfU39/f0KDw//3Hl7vV5FR0err69PTqczmFMGAADjJJj376Cu1AwODqq9vV0ul+vTJwgNlcvlUktLy4jHtLS0BIyXpPz8/IDxubm5crvdOnPmjIwxOnjwoLq6urRw4cLPnMsnJ3cjQQMAAOwXVBGcP39ew8PDiomJCdgfExOj9957b8RjPB7PiOM9Ho//5+rqaj399NOKj49XeHi4QkND9YMf/EALFiz4zHm88MILevrppz9zrgMDAxoYGPD/7PV6P/f8AADAxHVHfPupurpaR44ckdvtVnt7u6qqqlRSUqIDBw5cM9br9aqgoECpqan69re//ZnPWVlZqejoaP+WkJBwG88AAACMt6Cu1EybNk1hYWHq7u4O2N/d3a3Y2NgRj4mNjb3u+CtXrqiiokL19fUqKCiQJM2ZM0fHjx/Xli1bAn51dfHiRS1atEiTJ09WfX297rnnns+c6/r161VeXu7/2ev1EjYAAFgsqCs1DodDmZmZam5u9u/z+Xxqbm5WTk7OiMfk5OQEjJekpqYm//ihoSENDQ0pNDRwKmFhYfL5fP6fvV6vFi5cKIfDIbfbrcjIyOvONSIiQk6nM2ADAAD2CvpTtuXl5SouLtbcuXOVlZWlbdu2qb+/XytWrJAkLV++XDNmzFBlZaUkac2aNcrLy1NVVZUKCgpUW1urtrY27dy5U5LkdDqVl5entWvXKioqSklJSTp06JB27dqlrVu3Svo0aC5fvqzdu3fL6/X6PyPzxS9+UWFhYbdkMQAAwMQVdNQUFRXpo48+0saNG+XxeJSRkaHGxkb/h4FPnToVcNUlNzdXe/bs0fPPP6+KigrNmjVLDQ0NSktL84+pra3V+vXrtWzZMvX29iopKUmbN2/WqlWrJEnHjh3T0aNHJUkPPPBAwHw+/PBDJScnB33iAADALkHfp2ai4j41AABMPLftPjUAAAB3KqIGAABYgagBAABWIGoAAIAViBoAAGAFogYAAFiBqAEAAFYgagAAgBWIGgAAYAWiBgAAWIGoAQAAViBqAACAFYgaAABgBaIGAABYgagBAABWIGoAAIAViBoAAGAFogYAAFiBqAEAAFYgagAAgBWIGgAAYAWiBgAAWIGoAQAAViBqAACAFYgaAABgBaIGAABYgagBAABWIGoAAIAViBoAAGAFogYAAFiBqAEAAFYgagAAgBWIGgAAYAWiBgAAWIGoAQAAViBqAACAFYgaAABgBaIGAABYgagBAABWIGoAAIAViBoAAGAFogYAAFiBqAEAAFYgagAAgBWIGgAAYAWiBgAAWIGoAQAAViBqAACAFYgaAABgBaIGAABYgagBAABWIGoAAIAViBoAAGAFogYAAFiBqAEAAFYgagAAgBWIGgAAYAWiBgAAWIGoAQAAViBqAACAFYgaAABgBaIGAABYgagBAABWIGoAAIAViBoAAGAFogYAAFiBqAEAAFYgagAAgBWIGgAAYIVRRU1NTY2Sk5MVGRmp7Oxstba2Xnd8XV2dUlJSFBkZqdmzZ2v//v0Bj1+6dEmlpaWKj49XVFSUUlNTtWPHjoAxH3/8sUpKSjR16lRNmjRJTzzxhLq7u0czfQAAYKGgo2bv3r0qLy/Xpk2bdOzYMaWnpys/P189PT0jjj98+LCWLl2qlStXqqOjQ4WFhSosLFRnZ6d/THl5uRobG7V7926dOHFCZWVlKi0tldvt9o959tln9dOf/lR1dXU6dOiQzp49qyVLlozilAEAgI1CjDEmmAOys7M1b948bd++XZLk8/mUkJCg1atXa926ddeMLyoqUn9/v/bt2+ffN3/+fGVkZPivxqSlpamoqEgbNmzwj8nMzNTixYv14osvqq+vT1/84he1Z88effWrX5Ukvffee3rooYfU0tKi+fPnf+68vV6voqOj1dfXJ6fTGcwpAwCAcRLM+3dQV2oGBwfV3t4ul8v16ROEhsrlcqmlpWXEY1paWgLGS1J+fn7A+NzcXLndbp05c0bGGB08eFBdXV1auHChJKm9vV1DQ0MBz5OSkqLExMTPfN2BgQF5vd6ADQAA2CuoqDl//ryGh4cVExMTsD8mJkYej2fEYzwez+eOr66uVmpqquLj4+VwOLRo0SLV1NRowYIF/udwOByaMmXKDb9uZWWloqOj/VtCQkIwpwoAACaYO+LbT9XV1Tpy5Ijcbrfa29tVVVWlkpISHThwYNTPuX79evX19fm306dP38IZAwCAO014MIOnTZumsLCwa7511N3drdjY2BGPiY2Nve74K1euqKKiQvX19SooKJAkzZkzR8ePH9eWLVvkcrkUGxurwcFBXbhwIeBqzfVeNyIiQhEREcGcHgAAmMCCulLjcDiUmZmp5uZm/z6fz6fm5mbl5OSMeExOTk7AeElqamryjx8aGtLQ0JBCQwOnEhYWJp/PJ+nqh4bvueeegOc5efKkTp069ZmvCwAA7i5BXamRrn79uri4WHPnzlVWVpa2bdum/v5+rVixQpK0fPlyzZgxQ5WVlZKkNWvWKC8vT1VVVSooKFBtba3a2tq0c+dOSZLT6VReXp7Wrl2rqKgoJSUl6dChQ9q1a5e2bt0qSYqOjtbKlStVXl6u++67T06nU6tXr1ZOTs4NffMJAADYL+ioKSoq0kcffaSNGzfK4/EoIyNDjY2N/g8Dnzp1KuCqS25urvbs2aPnn39eFRUVmjVrlhoaGpSWluYfU1tbq/Xr12vZsmXq7e1VUlKSNm/erFWrVvnHvPzyywoNDdUTTzyhgYEB5efn65//+Z9v5twBAIBFgr5PzUTFfWoAAJh4btt9agAAAO5URA0AALACUQMAAKxA1AAAACsQNQAAwApEDQAAsAJRAwAArEDUAAAAKxA1AADACkQNAACwAlEDAACsQNQAAAArEDUAAMAK4eM9gbHyyV9G7vV6x3kmAADgRn3yvv3J+/j13DVRc/HiRUlSQkLCOM8EAAAE6+LFi4qOjr7umBBzI+ljAZ/Pp7Nnz2ry5MkKCQm5pc/t9XqVkJCg06dPy+l03tLnRiDWeuyw1mOHtR47rPXYuVVrbYzRxYsXFRcXp9DQ639q5q65UhMaGqr4+Pjb+hpOp5P/ScYIaz12WOuxw1qPHdZ67NyKtf68KzSf4IPCAADACkQNAACwAlFzC0RERGjTpk2KiIgY76lYj7UeO6z12GGtxw5rPXbGY63vmg8KAwAAu3GlBgAAWIGoAQAAViBqAACAFYgaAABgBaLmJtXU1Cg5OVmRkZHKzs5Wa2vreE9pwqusrNS8efM0efJkTZ8+XYWFhTp58mTAmI8//lglJSWaOnWqJk2apCeeeELd3d3jNGN7vPTSSwoJCVFZWZl/H2t965w5c0Zf+9rXNHXqVEVFRWn27Nlqa2vzP26M0caNG3X//fcrKipKLpdL77///jjOeGIaHh7Whg0bNHPmTEVFRelLX/qSXnjhhYC/O4i1Hr2f//zn+pM/+RPFxcUpJCREDQ0NAY/fyNr29vZq2bJlcjqdmjJlilauXKlLly7d/OQMRq22ttY4HA7zwx/+0PzXf/2X+eY3v2mmTJliuru7x3tqE1p+fr555ZVXTGdnpzl+/Lj54z/+Y5OYmGguXbrkH7Nq1SqTkJBgmpubTVtbm5k/f77Jzc0dx1lPfK2trSY5OdnMmTPHrFmzxr+ftb41ent7TVJSkvn6179ujh49aj744APzn//5n+a///u//WNeeuklEx0dbRoaGsw777xj/vRP/9TMnDnTXLlyZRxnPvFs3rzZTJ061ezbt898+OGHpq6uzkyaNMl897vf9Y9hrUdv//795rnnnjOvv/66kWTq6+sDHr+RtV20aJFJT083R44cMW+++aZ54IEHzNKlS296bkTNTcjKyjIlJSX+n4eHh01cXJyprKwcx1nZp6enx0gyhw4dMsYYc+HCBXPPPfeYuro6/5gTJ04YSaalpWW8pjmhXbx40cyaNcs0NTWZvLw8f9Sw1rfO3/3d35nf//3f/8zHfT6fiY2NNf/0T//k33fhwgUTERFh/vVf/3UspmiNgoIC81d/9VcB+5YsWWKWLVtmjGGtb6X/HzU3sra//OUvjSTz9ttv+8f8x3/8hwkJCTFnzpy5qfnw66dRGhwcVHt7u1wul39faGioXC6XWlpaxnFm9unr65Mk3XfffZKk9vZ2DQ0NBax9SkqKEhMTWftRKikpUUFBQcCaSqz1reR2uzV37lz9+Z//uaZPn65HHnlEP/jBD/yPf/jhh/J4PAFrHR0drezsbNY6SLm5uWpublZXV5ck6Z133tFbb72lxYsXS2Ktb6cbWduWlhZNmTJFc+fO9Y9xuVwKDQ3V0aNHb+r175q/0PJWO3/+vIaHhxUTExOwPyYmRu+99944zco+Pp9PZWVl+vKXv6y0tDRJksfjkcPh0JQpUwLGxsTEyOPxjMMsJ7ba2lodO3ZMb7/99jWPsda3zgcffKDvf//7Ki8vV0VFhd5++21961vfksPhUHFxsX89R/ozhbUOzrp16+T1epWSkqKwsDANDw9r8+bNWrZsmSSx1rfRjaytx+PR9OnTAx4PDw/Xfffdd9PrT9TgjlZSUqLOzk699dZb4z0VK50+fVpr1qxRU1OTIiMjx3s6VvP5fJo7d66+853vSJIeeeQRdXZ2aseOHSouLh7n2dnl1Vdf1Y9//GPt2bNHDz/8sI4fP66ysjLFxcWx1pbj10+jNG3aNIWFhV3zLZDu7m7FxsaO06zsUlpaqn379ungwYOKj4/374+NjdXg4KAuXLgQMJ61D157e7t6enr06KOPKjw8XOHh4Tp06JC+973vKTw8XDExMaz1LXL//fcrNTU1YN9DDz2kU6dOSZJ/Pfkz5eatXbtW69at01/8xV9o9uzZeuqpp/Tss8+qsrJSEmt9O93I2sbGxqqnpyfg8d/85jfq7e296fUnakbJ4XAoMzNTzc3N/n0+n0/Nzc3KyckZx5lNfMYYlZaWqr6+Xm+88YZmzpwZ8HhmZqbuueeegLU/efKkTp06xdoH6bHHHtO7776r48eP+7e5c+dq2bJl/n9nrW+NL3/5y9fcmqCrq0tJSUmSpJkzZyo2NjZgrb1er44ePcpaB+ny5csKDQ18ewsLC5PP55PEWt9ON7K2OTk5unDhgtrb2/1j3njjDfl8PmVnZ9/cBG7qY8Z3udraWhMREWF+9KMfmV/+8pfm6aefNlOmTDEej2e8pzah/fVf/7WJjo42P/vZz8y5c+f82+XLl/1jVq1aZRITE80bb7xh2traTE5OjsnJyRnHWdvjt7/9ZAxrfau0traa8PBws3nzZvP++++bH//4x+bee+81u3fv9o956aWXzJQpU8xPfvIT84tf/MI8/vjjfM14FIqLi82MGTP8X+l+/fXXzbRp08zf/u3f+sew1qN38eJF09HRYTo6Oowks3XrVtPR0WH+93//1xhzY2u7aNEi88gjj5ijR4+at956y8yaNYuvdN8JqqurTWJionE4HCYrK8scOXJkvKc04UkacXvllVf8Y65cuWL+5m/+xvzO7/yOuffee82f/dmfmXPnzo3fpC3y/6OGtb51fvrTn5q0tDQTERFhUlJSzM6dOwMe9/l8ZsOGDSYmJsZERESYxx57zJw8eXKcZjtxeb1es2bNGpOYmGgiIyPN7/7u75rnnnvODAwM+Mew1qN38ODBEf+MLi4uNsbc2Nr++te/NkuXLjWTJk0yTqfTrFixwly8ePGm5xZizG/dYhEAAGCC4jM1AADACkQNAACwAlEDAACsQNQAAAArEDUAAMAKRA0AALACUQMAAKxA1AAAACsQNQAAwApEDQAAsAJRAwAArEDUAAAAK/wfyUv4emkLmFkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "c=0\n",
    "for epoch in range(100):\n",
    "    \n",
    "    #forward\n",
    "    Layer1.forward(x_train)\n",
    "    Act1.forward(Layer1.output)\n",
    "    loss_train = Loss.forward(Act1.output,y_train)\n",
    "    \n",
    "    # Report\n",
    "    y_predict_train = np.argmax(Act1.output,axis = 1)\n",
    "    accuracy_train = np.mean(y_train == y_predict_train)\n",
    "    \n",
    "    #backward\n",
    "    Loss.backward(Act1.output,y_train)\n",
    "    Act1.backward(Loss.b_output)\n",
    "    Layer1.backward(Act1.b_output)\n",
    "    \n",
    "    \n",
    "    print(f'Epoch:{epoch}')\n",
    "    print(f'Loss: {loss_train}')\n",
    "    print(f'Accuracy: {accuracy_train}')\n",
    "    print('--------------------------')\n",
    "\n",
    "    #update params\n",
    "    Optimizer.update(Layer1)\n",
    "    \n",
    "    plt.scatter(epoch,accuracy, c= 'blue')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "07bc6fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:99\n",
      "Accuracy: 0.0841\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "Layer1.forward(x_test)\n",
    "Act1.forward(Layer1.output)\n",
    "# Report\n",
    "y_predict_test = np.argmax(Act1.output,axis = 1)\n",
    "accuracy_test = np.mean(y_test == y_predict_test)\n",
    "print(f'Epoch:{epoch}')\n",
    "print(f'Accuracy: {accuracy_test}')\n",
    "print('--------------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc42567",
   "metadata": {},
   "source": [
    "# b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "22662bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "Layer1 = Dense(784,30)\n",
    "Act1=ReLU()\n",
    "\n",
    "Layer2 = Dense(30,10)\n",
    "Act2= Softmax()\n",
    "\n",
    "Loss = Categorical_cross_entroy_loss()\n",
    "Optimizer = SGD(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bd075196",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ansar9811291\\AppData\\Local\\Temp\\ipykernel_5516\\784203532.py:62: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.sum(-np.log(cc)).reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:1\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:2\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:3\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:4\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:5\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:6\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:7\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:8\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:9\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:10\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:11\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:12\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:13\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:14\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:15\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:16\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:17\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:18\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:19\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:20\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:21\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:22\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:23\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:24\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:25\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:26\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:27\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:28\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:29\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:30\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:31\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:32\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:33\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:34\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:35\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:36\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:37\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:38\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:39\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:40\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:41\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:42\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:43\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:44\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:45\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:46\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:47\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:48\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:49\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:50\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:51\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:52\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:53\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:54\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:55\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:56\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:57\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:58\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:59\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:60\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:61\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:62\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:63\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:64\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:65\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:66\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:67\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:68\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:69\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:70\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:71\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:72\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:73\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:74\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:75\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:76\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:77\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:78\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:79\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:80\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:81\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:82\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:83\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:84\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:85\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:86\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:87\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:88\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:89\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:90\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:91\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:92\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:93\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:94\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:95\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:96\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:97\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:98\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n",
      "Epoch:99\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09864538545454546\n",
      "--------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "c=0\n",
    "for epoch in range(100):\n",
    "    #forward\n",
    "    Layer1.forward(x_train)\n",
    "    Act1.forward(Layer1.output)\n",
    "    Layer2.forward(Act1.output)\n",
    "    Act2.forward(Layer2.output)\n",
    "    loss_train = Loss.forward(Act2.output,y_train)\n",
    "    \n",
    "    y_predict_train = np.argmax(Act1.output,axis = 1)\n",
    "    accuracy_train = np.mean(y_train == y_predict_train)\n",
    "    \n",
    "    #backward\n",
    "    Loss.backward(Act2.output,y_train)\n",
    "    Act2.backward(Loss.b_output)\n",
    "    Layer2.backward(Act2.b_output)\n",
    "    Act1.backward(Layer2.b_output)\n",
    "    Layer1.backward(Act1.b_output)\n",
    "    \n",
    "    print(f'Epoch:{epoch}')\n",
    "    print(f'Loss: {loss_train}')\n",
    "    print(f'Accuracy: {accuracy_train}')\n",
    "    print('--------------------------')\n",
    "    \n",
    "    plt.scatter(epoch,accuracy, c= 'blue')\n",
    "    \n",
    "\n",
    "    #update params\n",
    "    Optimizer.update(Layer1)\n",
    "    Optimizer.update(Layer2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c660b855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:99\n",
      "Accuracy for test data: 0.110048\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "#forward\n",
    "Layer1.forward(x_test)\n",
    "Act1.forward(Layer1.output)\n",
    "Layer2.forward(Act1.output)\n",
    "Act2.forward(Layer2.output)\n",
    "\n",
    "# Report\n",
    "y_predict = np.argmax(Act2.output,axis = 1)\n",
    "accuracy = np.mean(y_test == y_predict)\n",
    "print(f'Epoch:{epoch}')\n",
    "print(f'Accuracy for test data: {accuracy}')\n",
    "print('--------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b657f5d",
   "metadata": {},
   "source": [
    "# c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "33b8ee0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Layer1 = Dense(784,30)\n",
    "Act1=ReLU()\n",
    "Layer2 = Dense(30,10)\n",
    "Act2= Softmax()\n",
    "\n",
    "Layer3 = Dense(10,10)\n",
    "Act3= Softmax()\n",
    "\n",
    "Loss = Categorical_cross_entroy_loss()\n",
    "Optimizer = SGD(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b564f7ef",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ansar9811291\\AppData\\Local\\Temp\\ipykernel_5516\\784203532.py:62: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.sum(-np.log(cc)).reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879984429752066\n",
      "--------------------------\n",
      "Epoch:1\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:2\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:3\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:4\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:5\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:6\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:7\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:8\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:9\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:10\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:11\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:12\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:13\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:14\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:15\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:16\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:17\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:18\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:19\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:20\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:21\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:22\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:23\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:24\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:25\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:26\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:27\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:28\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:29\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:30\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:31\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:32\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:33\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:34\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:35\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:36\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:37\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:38\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:39\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:40\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:41\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:42\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:43\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:44\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:45\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:46\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:47\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:48\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:49\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:50\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:51\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:52\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:53\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:54\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:55\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:56\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:57\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:58\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:59\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:60\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:61\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:62\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:63\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:64\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:65\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:66\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:67\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:68\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:69\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:70\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:71\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:72\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:73\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:74\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:75\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:76\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:77\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:78\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:79\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:80\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:81\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:82\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:83\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:84\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:85\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:86\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:87\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:88\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:89\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:90\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:91\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:92\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:93\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:94\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:95\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:96\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:97\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:98\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "Epoch:99\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "c=0\n",
    "for epoch in range(100):\n",
    "    #forward\n",
    "    Layer1.forward(x_train)\n",
    "    Act1.forward(Layer1.output)\n",
    "    Layer2.forward(Act1.output)\n",
    "    Act2.forward(Layer2.output)\n",
    "    \n",
    "    Layer3.forward(Act2.output)\n",
    "    Act3.forward(Layer3.output)\n",
    "    loss_train = Loss.forward(Act3.output,y_train)\n",
    "    \n",
    "    \n",
    "    # Report\n",
    "    y_predict_train = np.argmax(Act2.output,axis = 1)\n",
    "    accuracy_train = np.mean(y_train == y_predict_train)\n",
    "   \n",
    "    \n",
    "    #backward\n",
    "    Loss.backward(Act3.output,y_train)\n",
    "    Act3.backward(Loss.b_output)\n",
    "    Layer3.backward(Act3.b_output)\n",
    "    \n",
    "    Act2.backward(Layer3.b_output)\n",
    "    Layer2.backward(Act2.b_output)\n",
    "    \n",
    "    Act1.backward(Layer2.b_output)\n",
    "    Layer1.backward(Act1.b_output)\n",
    "    \n",
    "    print(f'Epoch:{epoch}')\n",
    "    print(f'Loss: {loss_train}')\n",
    "    print(f'Accuracy: {accuracy_train}')\n",
    "    print('--------------------------')\n",
    "    \n",
    "    plt.scatter(epoch,accuracy, c= 'blue')\n",
    "   \n",
    "    #update params\n",
    "    Optimizer.update(Layer1)\n",
    "    Optimizer.update(Layer2)\n",
    "    Optimizer.update(Layer3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ecbf8763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:99\n",
      "Accuracy: 0.084\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "#forward\n",
    "Layer1.forward(x_test)\n",
    "Act1.forward(Layer1.output)\n",
    "\n",
    "Layer2.forward(Act1.output)\n",
    "Act2.forward(Layer2.output)\n",
    "\n",
    "Layer3.forward(Act2.output)\n",
    "Act3.forward(Layer3.output)\n",
    "    \n",
    "# Report\n",
    "y_predict = np.argmax(Act2.output,axis = 1)\n",
    "accuracy = np.mean(y_test == y_predict)\n",
    "\n",
    "print(f'Epoch:{epoch}')\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('--------------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84db04e1",
   "metadata": {},
   "source": [
    "# 3-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7abb84",
   "metadata": {},
   "source": [
    "# RMSProp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "83e205f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSprop():\n",
    "    def __init__(self, gamma = 0.8,learning_rate = 0.01):\n",
    "        self.v_dw = 0\n",
    "        self.v_db = 0\n",
    "        self.gamma = gamma\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def update(self, layer):\n",
    "        ## dw, db are from current minibatch\n",
    "        ## momentum beta 1\n",
    "        # *** weights *** #\n",
    "        \n",
    "        self.v_dw = self.gamma * self.v_dw + (1 - self.gamma) * layer.g_w ** 2\n",
    "        self.v_db = self.gamma * self.v_db + (1 - self.gamma) * layer.g_b ** 2\n",
    "\n",
    "        layer.w = layer.w -self.learning_rate / ((np.sqrt( self.v_dw+ 1e-08))) * layer.g_w\n",
    "        layer.b = layer.b -self.learning_rate / ((np.sqrt(self.v_db + 1e-08))) * layer.g_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "182269ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0f37b45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Layer1 = Dense(784,10)\n",
    "Act1 = Softmax()\n",
    "Loss = Categorical_cross_entroy_loss()\n",
    "Optimizer = RMSprop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1c91cb87",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ansar9811291\\AppData\\Local\\Temp\\ipykernel_5516\\784203532.py:62: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.sum(-np.log(cc)).reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:1\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:2\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:3\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:4\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:5\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:6\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:7\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:8\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:9\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:10\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:11\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:12\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:13\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:14\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:15\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:16\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:17\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:18\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:19\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:20\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:21\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:22\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:23\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:24\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:25\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:26\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:27\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:28\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:29\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:30\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:31\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:32\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:33\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:34\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:35\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:36\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:37\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:38\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:39\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:40\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:41\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:42\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:43\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:44\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:45\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:46\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:47\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:48\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:49\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:50\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:51\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:52\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:53\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:54\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:55\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:56\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:57\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:58\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:59\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:60\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:61\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:62\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:63\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:64\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:65\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:66\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:67\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:68\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:69\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:70\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:71\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:72\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:73\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:74\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:75\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:76\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:77\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:78\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:79\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:80\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:81\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:82\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:83\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:84\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:85\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:86\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:87\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:88\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:89\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:90\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:91\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:92\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:93\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:94\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:95\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:96\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:97\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:98\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n",
      "Epoch:99\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjUAAAGdCAYAAADqsoKGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAlv0lEQVR4nO3df1DUd37H8Rcs7kJOgUZPCIKYJjYEUUlQEK6RTrMnWKYNNW2o9RLO2iS24GmYsRXij5smlrQV4x1ysXYmSR3PYmwOb8+zdBA5LzlRI8JduBhJL5lq1cVYRlbRKMd++oeTzW0lyiIB+eT5mPnOxO++d/fz/dxc9jnr7ibMGGMEAAAwyoWP9AIAAACGAlEDAACsQNQAAAArEDUAAMAKRA0AALACUQMAAKxA1AAAACsQNQAAwAoRI72A4eL3+3XmzBmNGzdOYWFhI70cAAAwAMYYXbx4UQkJCQoPv/l7MV+aqDlz5oySkpJGehkAAGAQTp06pcTExJvOfGmiZty4cZKub0p0dPQIrwYAAAyEz+dTUlJS4HX8Zr40UfPpXzlFR0cTNQAAjDID+egIHxQGAABWIGoAAIAViBoAAGAFogYAAFiBqAEAAFYgagAAgBWIGgAAYAWiBgAAWIGoAQAAViBqAACAFYgaAABgBaIGAABYgagBAABWIGoAAIAViBoAAGAFogYAAFiBqAEAAFYYVNTU1NRoypQpioyMVFZWlo4cOXLT+V27diklJUWRkZGaPn269u7dG3T7pUuXVFpaqsTEREVFRSk1NVVbtmwJmvF6vXryyScVHx+vr3zlK3r44Yf15ptvDmb5AADAQiFHzc6dO1VWVqZ169bp2LFjmjlzpvLy8nTu3Ll+5w8ePKiFCxdqyZIlam1tVWFhoQoLC9Xe3h6YKSsrU319vbZv367jx49rxYoVKi0tlcfjCcw89dRTOnHihDwej959910tWLBATzzxhFpbWwdx2QAAwDZhxhgTyh2ysrI0e/Zsbd68WZLk9/uVlJSkZcuWadWqVTfMFxUVqaenR3v27AmcmzNnjtLT0wPvxqSlpamoqEhr1qwJzGRkZGj+/Pl68cUXJUljx47VK6+8oieffDIwM378eP3DP/yD/vIv//KW6/b5fIqJiVF3d7eio6NDuWQAADBCQnn9DumdmmvXrqmlpUVut/uzBwgPl9vtVnNzc7/3aW5uDpqXpLy8vKD5nJwceTwenT59WsYYNTU1qaOjQ/PmzQua2blzp7q6uuT3+1VbW6tPPvlEv/d7v9fv8169elU+ny/oAAAA9gopas6fP6++vj7FxcUFnY+Li5PX6+33Pl6v95bz1dXVSk1NVWJiopxOp/Lz81VTU6O5c+cGZt544w319vZq/PjxcrlcevbZZ1VXV6f777+/3+etrKxUTExM4EhKSgrlUgEAwChzR3z7qbq6WocOHZLH41FLS4uqqqpUUlKiffv2BWbWrFmjCxcuaN++fTp69KjKysr0xBNP6N133+33McvLy9Xd3R04Tp06NVyXAwAARkBEKMMTJkyQw+FQZ2dn0PnOzk7Fx8f3e5/4+Pibzl+5ckUVFRWqq6tTQUGBJGnGjBlqa2vThg0b5Ha79atf/UqbN29We3u7pk2bJkmaOXOm3nrrLdXU1NzwTSlJcrlccrlcoVweAAAYxUJ6p8bpdCojI0ONjY2Bc36/X42NjcrOzu73PtnZ2UHzktTQ0BCY7+3tVW9vr8LDg5ficDjk9/slSZcvX76+2JvMAACAL7eQ3qmRrn/9uri4WLNmzVJmZqY2bdqknp4eLV68WNL1r15PmjRJlZWVkqTly5crNzdXVVVVKigoUG1trY4ePaqtW7dKkqKjo5Wbm6uVK1cqKipKycnJOnDggLZt26aNGzdKklJSUnT//ffr2Wef1YYNGzR+/Hjt3r1bDQ0NQd+qAgAAX2JmEKqrq83kyZON0+k0mZmZ5tChQ4HbcnNzTXFxcdD8G2+8YX7nd37HOJ1OM23aNPPjH/846PazZ8+ab37zmyYhIcFERkaaBx54wFRVVRm/3x+Y6ejoMAsWLDATJ040d911l5kxY4bZtm3bgNfc3d1tJJnu7u7BXDIAABgBobx+h/w7NaMVv1MDAMDo84X9Tg0AAMCdiqgBAABWIGoAAIAViBoAAGAFogYAAFiBqAEAAFYgagAAgBWIGgAAYAWiBgAAWIGoAQAAViBqAACAFYgaAABgBaIGAABYgagBAABWIGoAAIAViBoAAGAFogYAAFiBqAEAAFYgagAAgBWIGgAAYAWiBgAAWIGoAQAAViBqAACAFYgaAABgBaIGAABYgagBAABWIGoAAIAViBoAAGAFogYAAFiBqAEAAFYgagAAgBWIGgAAYAWiBgAAWIGoAQAAViBqAACAFYgaAABgBaIGAABYgagBAABWIGoAAIAViBoAAGAFogYAAFiBqAEAAFYgagAAgBWIGgAAYAWiBgAAWIGoAQAAViBqAACAFYgaAABgBaIGAABYgagBAABWIGoAAIAViBoAAGAFogYAAFiBqAEAAFYgagAAgBWIGgAAYAWiBgAAWIGoAQAAViBqAACAFYgaAABgBaIGAABYgagBAABWIGoAAIAViBoAAGAFogYAAFiBqAEAAFYgagAAgBWIGgAAYAWiBgAAWGFQUVNTU6MpU6YoMjJSWVlZOnLkyE3nd+3apZSUFEVGRmr69Onau3dv0O2XLl1SaWmpEhMTFRUVpdTUVG3ZsuWGx2lubtbv//7v6ytf+Yqio6M1d+5cXblyZTCXAAAALBNy1OzcuVNlZWVat26djh07ppkzZyovL0/nzp3rd/7gwYNauHChlixZotbWVhUWFqqwsFDt7e2BmbKyMtXX12v79u06fvy4VqxYodLSUnk8nsBMc3Oz8vPzNW/ePB05ckTvvPOOSktLFR7Om00AAEAKM8aYUO6QlZWl2bNna/PmzZIkv9+vpKQkLVu2TKtWrbphvqioSD09PdqzZ0/g3Jw5c5Senh54NyYtLU1FRUVas2ZNYCYjI0Pz58/Xiy++GLjP17/+db3wwguhX6Ukn8+nmJgYdXd3Kzo6elCPAQAAhlcor98hvc1x7do1tbS0yO12f/YA4eFyu91qbm7u9z7Nzc1B85KUl5cXNJ+TkyOPx6PTp0/LGKOmpiZ1dHRo3rx5kqRz587p8OHDmjhxonJychQXF6fc3Fy9/fbbn7vWq1evyufzBR0AAMBeIUXN+fPn1dfXp7i4uKDzcXFx8nq9/d7H6/Xecr66ulqpqalKTEyU0+lUfn6+ampqNHfuXEnShx9+KEn69re/raefflr19fV6+OGH9eijj+qDDz7o93krKysVExMTOJKSkkK5VAAAMMrcER9Iqa6u1qFDh+TxeNTS0qKqqiqVlJRo3759kq7/FZckPfvss1q8eLEeeughvfzyy3rggQf06quv9vuY5eXl6u7uDhynTp0atusBAADDLyKU4QkTJsjhcKizszPofGdnp+Lj4/u9T3x8/E3nr1y5ooqKCtXV1amgoECSNGPGDLW1tWnDhg1yu9265557JEmpqalBj/Pggw/q5MmT/T6vy+WSy+UK5fIAAMAoFtI7NU6nUxkZGWpsbAyc8/v9amxsVHZ2dr/3yc7ODpqXpIaGhsB8b2+vent7b/gWk8PhCLxDM2XKFCUkJOjEiRNBMx0dHUpOTg7lEgAAgKVCeqdGuv716+LiYs2aNUuZmZnatGmTenp6tHjxYknSU089pUmTJqmyslKStHz5cuXm5qqqqkoFBQWqra3V0aNHtXXrVklSdHS0cnNztXLlSkVFRSk5OVkHDhzQtm3btHHjRklSWFiYVq5cqXXr1mnmzJlKT0/Xv/7rv+r999/Xv//7vw/VXgAAgFEs5KgpKirSxx9/rLVr18rr9So9PV319fWBDwOfPHky6F2XnJwc7dixQ6tXr1ZFRYWmTp2q3bt3Ky0tLTBTW1ur8vJyLVq0SF1dXUpOTtb69eu1dOnSwMyKFSv0ySef6LnnnlNXV5dmzpyphoYG3Xfffbdz/QAAwBIh/07NaMXv1AAAMPp8Yb9TAwAAcKciagAAgBWIGgAAYAWiBgAAWIGoAQAAViBqAACAFYgaAABgBaIGAABYgagBAABWIGoAAIAViBoAAGAFogYAAFiBqAEAAFYgagAAgBWIGgAAYAWiBgAAWIGoAQAAViBqAACAFYgaAABgBaIGAABYgagBAABWIGoAAIAViBoAAGAFogYAAFiBqAEAAFYgagAAgBWIGgAAYAWiBgAAWIGoAQAAViBqAACAFYgaAABgBaIGAABYgagBAABWIGoAAIAViBoAAGAFogYAAFiBqAEAAFYgagAAgBWIGgAAYAWiBgAAWIGoAQAAViBqAACAFYgaAABgBaIGAABYgagBAABWIGoAAIAViBoAAGAFogYAAFiBqAEAAFYgagAAgBWIGgAAYAWiBgAAWIGoAQAAViBqAACAFYgaAABgBaIGAABYgagBAABWIGoAAIAViBoAAGAFogYAAFiBqAEAAFYgagAAgBWIGgAAYAWiBgAAWIGoAQAAViBqAACAFYgaAABgBaIGAABYIWKkFzDa9fVJb70lnT0r3XOPlJMjHTz42Z8feeT63G/O9HduIPcbzpmRfn7WyBpZI9fBGkfvGh95RHI4NPzMIGzevNkkJycbl8tlMjMzzeHDh286/8Ybb5gHHnjAuFwuk5aWZn784x8H3X7x4kVTUlJiJk2aZCIjI82DDz5oXnnllX4fy+/3m/z8fCPJ1NXVDXjN3d3dRpLp7u4e8H1u5c03jUlMNEb67HA4gv88fvz141bnBnK/4ZwZ6ednjazxTnp+W9Zoy3WM9POzxlvPJCZef40cCqG8fivUB6+trTVOp9O8+uqr5pe//KV5+umnTWxsrOns7Ox3/mc/+5lxOBzmH//xH817771nVq9ebcaMGWPefffdwMzTTz9t7rvvPtPU1GQ++ugj88///M/G4XCYH/7whzc83saNG838+fPNSEfNm28aExYW/D8iBwcHBwcHx/XXx7CwoQmbLzRqMjMzTUlJSeDPfX19JiEhwVRWVvY7/8QTT5iCgoKgc1lZWebZZ58N/HnatGnm7/7u74JmHn74YfP8888HnWttbTWTJk0yZ8+eNSMZNb/+9Y3v0HBwcHBwcHB8doSFGZOUdP0183aE8vod0geFr127ppaWFrnd7sC58PBwud1uNTc393uf5ubmoHlJysvLC5rPycmRx+PR6dOnZYxRU1OTOjo6NG/evMDM5cuX9ed//ueqqalRfHz8Ldd69epV+Xy+oGOovPWW9D//M2QPBwCAdYyRTp26/po5XEKKmvPnz6uvr09xcXFB5+Pi4uT1evu9j9frveV8dXW1UlNTlZiYKKfTqfz8fNXU1Gju3LmBmeeee045OTl67LHHBrTWyspKxcTEBI6kpKSBXuYtnT07ZA8FAIDVhvM184749lN1dbUOHTokj8ej5ORk/fSnP1VJSYkSEhLkdrvl8Xi0f/9+tba2Dvgxy8vLVVZWFvizz+cbsrC5554heRgAAKw3nK+ZIUXNhAkT5HA41NnZGXS+s7Pzc/9KKD4+/qbzV65cUUVFherq6lRQUCBJmjFjhtra2rRhwwa53W7t379fv/rVrxQbGxv0OI8//rgeeeQR/eQnP7nheV0ul1wuVyiXN2CPPCIlJkqnT19/ew0AAAQLC7v+WvnpV76HQ0h//eR0OpWRkaHGxsbAOb/fr8bGRmVnZ/d7n+zs7KB5SWpoaAjM9/b2qre3V+HhwUtxOBzy+/2SpFWrVukXv/iF2traAockvfzyy3rttddCuYQh4XBI3/nO9X8OCxv2pwcA4I726Wvjpk3D/Hs1oX4Kuba21rhcLvP666+b9957zzzzzDMmNjbWeL1eY4wxTz75pFm1alVg/mc/+5mJiIgwGzZsMMePHzfr1q274Svdubm5Ztq0aaapqcl8+OGH5rXXXjORkZHme9/73ueuQ+J3akbr7xewxjtrZqSfnzXeWTMj/fys0Y41JiWNzO/UhPyZmqKiIn388cdau3atvF6v0tPTVV9fH/gw8MmTJ4PedcnJydGOHTu0evVqVVRUaOrUqdq9e7fS0tICM7W1tSovL9eiRYvU1dWl5ORkrV+/XkuXLr3dZvtCLVggPfbYnfUrjqPhlyZZI2tkjXfuzEg/P2u0Y40j9YvCYcYYM/xPO/x8Pp9iYmLU3d2t6OjokV4OAAAYgFBev/kPWgIAACsQNQAAwApEDQAAsAJRAwAArEDUAAAAKxA1AADACkQNAACwAlEDAACsQNQAAAArEDUAAMAKRA0AALACUQMAAKxA1AAAACsQNQAAwApEDQAAsAJRAwAArEDUAAAAKxA1AADACkQNAACwAlEDAACsQNQAAAArEDUAAMAKRA0AALACUQMAAKxA1AAAACsQNQAAwApEDQAAsAJRAwAArEDUAAAAKxA1AADACkQNAACwAlEDAACsQNQAAAArEDUAAMAKRA0AALACUQMAAKxA1AAAACsQNQAAwApEDQAAsAJRAwAArEDUAAAAKxA1AADACkQNAACwAlEDAACsQNQAAAArEDUAAMAKRA0AALACUQMAAKxA1AAAACsQNQAAwApEDQAAsAJRAwAArEDUAAAAKxA1AADACkQNAACwAlEDAACsQNQAAAArEDUAAMAKRA0AALACUQMAAKxA1AAAACsQNQAAwApEDQAAsAJRAwAArEDUAAAAKxA1AADACkQNAACwAlEDAACsQNQAAAArDCpqampqNGXKFEVGRiorK0tHjhy56fyuXbuUkpKiyMhITZ8+XXv37g26/dKlSyotLVViYqKioqKUmpqqLVu2BG7v6urSsmXL9MADDygqKkqTJ0/Wt771LXV3dw9m+QAAwEIhR83OnTtVVlamdevW6dixY5o5c6by8vJ07ty5fucPHjyohQsXasmSJWptbVVhYaEKCwvV3t4emCkrK1N9fb22b9+u48ePa8WKFSotLZXH45EknTlzRmfOnNGGDRvU3t6u119/XfX19VqyZMkgLxsAANgmzBhjQrlDVlaWZs+erc2bN0uS/H6/kpKStGzZMq1ateqG+aKiIvX09GjPnj2Bc3PmzFF6enrg3Zi0tDQVFRVpzZo1gZmMjAzNnz9fL774Yr/r2LVrl77xjW+op6dHERERt1y3z+dTTEyMuru7FR0dHcolAwCAERLK63dI79Rcu3ZNLS0tcrvdnz1AeLjcbream5v7vU9zc3PQvCTl5eUFzefk5Mjj8ej06dMyxqipqUkdHR2aN2/e567l04v7vKC5evWqfD5f0AEAAOwVUtScP39efX19iouLCzofFxcnr9fb7328Xu8t56urq5WamqrExEQ5nU7l5+erpqZGc+fO/dx1vPDCC3rmmWc+d62VlZWKiYkJHElJSQO9TAAAMArdEd9+qq6u1qFDh+TxeNTS0qKqqiqVlJRo3759N8z6fD4VFBQoNTVV3/72tz/3McvLy9Xd3R04Tp069QVeAQAAGGm3/jDKb5gwYYIcDoc6OzuDznd2dio+Pr7f+8THx990/sqVK6qoqFBdXZ0KCgokSTNmzFBbW5s2bNgQ9FdXFy9eVH5+vsaNG6e6ujqNGTPmc9fqcrnkcrlCuTwAADCKhfROjdPpVEZGhhobGwPn/H6/GhsblZ2d3e99srOzg+YlqaGhITDf29ur3t5ehYcHL8XhcMjv9wf+7PP5NG/ePDmdTnk8HkVGRoaydAAAYLmQ3qmRrn/9uri4WLNmzVJmZqY2bdqknp4eLV68WJL01FNPadKkSaqsrJQkLV++XLm5uaqqqlJBQYFqa2t19OhRbd26VZIUHR2t3NxcrVy5UlFRUUpOTtaBAwe0bds2bdy4UdJnQXP58mVt37496IO/X/3qV+VwOIZkMwAAwOgVctQUFRXp448/1tq1a+X1epWenq76+vrAh4FPnjwZ9K5LTk6OduzYodWrV6uiokJTp07V7t27lZaWFpipra1VeXm5Fi1apK6uLiUnJ2v9+vVaunSpJOnYsWM6fPiwJOn+++8PWs9HH32kKVOmhHzhAADALiH/Ts1oxe/UAAAw+nxhv1MDAABwpyJqAACAFYgaAABgBaIGAABYgagBAABWIGoAAIAViBoAAGAFogYAAFiBqAEAAFYgagAAgBWIGgAAYAWiBgAAWIGoAQAAViBqAACAFYgaAABgBaIGAABYgagBAABWIGoAAIAViBoAAGAFogYAAFiBqAEAAFYgagAAgBWIGgAAYAWiBgAAWIGoAQAAViBqAACAFYgaAABgBaIGAABYgagBAABWIGoAAIAViBoAAGAFogYAAFiBqAEAAFYgagAAgBWIGgAAYAWiBgAAWIGoAQAAViBqAACAFYgaAABgBaIGAABYgagBAABWIGoAAIAViBoAAGAFogYAAFiBqAEAAFYgagAAgBWIGgAAYAWiBgAAWIGoAQAAViBqAACAFYgaAABgBaIGAABYgagBAABWIGoAAIAViBoAAGAFogYAAFiBqAEAAFYgagAAgBWIGgAAYAWiBgAAWIGoAQAAViBqAACAFYgaAABgBaIGAABYgagBAABWIGoAAIAViBoAAGAFogYAAFiBqAEAAFYYVNTU1NRoypQpioyMVFZWlo4cOXLT+V27diklJUWRkZGaPn269u7dG3T7pUuXVFpaqsTEREVFRSk1NVVbtmwJmvnkk09UUlKi8ePHa+zYsXr88cfV2dk5mOUDAAALhRw1O3fuVFlZmdatW6djx45p5syZysvL07lz5/qdP3jwoBYuXKglS5aotbVVhYWFKiwsVHt7e2CmrKxM9fX12r59u44fP64VK1aotLRUHo8nMPPcc8/pRz/6kXbt2qUDBw7ozJkzWrBgwSAuGQAA2CjMGGNCuUNWVpZmz56tzZs3S5L8fr+SkpK0bNkyrVq16ob5oqIi9fT0aM+ePYFzc+bMUXp6euDdmLS0NBUVFWnNmjWBmYyMDM2fP18vvviiuru79dWvflU7duzQn/zJn0iS3n//fT344INqbm7WnDlzbrlun8+nmJgYdXd3Kzo6OpRLBgAAIySU1++Q3qm5du2aWlpa5Ha7P3uA8HC53W41Nzf3e5/m5uageUnKy8sLms/JyZHH49Hp06dljFFTU5M6Ojo0b948SVJLS4t6e3uDHiclJUWTJ0/+3Oe9evWqfD5f0AEAAOwVUtScP39efX19iouLCzofFxcnr9fb7328Xu8t56urq5WamqrExEQ5nU7l5+erpqZGc+fODTyG0+lUbGzsgJ+3srJSMTExgSMpKSmUSwUAAKPMHfHtp+rqah06dEgej0ctLS2qqqpSSUmJ9u3bN+jHLC8vV3d3d+A4derUEK4YAADcaSJCGZ4wYYIcDscN3zrq7OxUfHx8v/eJj4+/6fyVK1dUUVGhuro6FRQUSJJmzJihtrY2bdiwQW63W/Hx8bp27ZouXLgQ9G7NzZ7X5XLJ5XKFcnkAAGAUC+mdGqfTqYyMDDU2NgbO+f1+NTY2Kjs7u9/7ZGdnB81LUkNDQ2C+t7dXvb29Cg8PXorD4ZDf75d0/UPDY8aMCXqcEydO6OTJk5/7vAAA4MslpHdqpOtfvy4uLtasWbOUmZmpTZs2qaenR4sXL5YkPfXUU5o0aZIqKyslScuXL1dubq6qqqpUUFCg2tpaHT16VFu3bpUkRUdHKzc3VytXrlRUVJSSk5N14MABbdu2TRs3bpQkxcTEaMmSJSorK9Pdd9+t6OhoLVu2TNnZ2QP65hMAALBfyFFTVFSkjz/+WGvXrpXX61V6errq6+sDHwY+efJk0LsuOTk52rFjh1avXq2KigpNnTpVu3fvVlpaWmCmtrZW5eXlWrRokbq6upScnKz169dr6dKlgZmXX35Z4eHhevzxx3X16lXl5eXpe9/73u1cOwAAsEjIv1MzWvE7NQAAjD5f2O/UAAAA3KmIGgAAYAWiBgAAWIGoAQAAViBqAACAFYgaAABgBaIGAABYgagBAABWIGoAAIAViBoAAGAFogYAAFiBqAEAAFYgagAAgBWIGgAAYAWiBgAAWIGoAQAAViBqAACAFSJGegHDxRgjSfL5fCO8EgAAMFCfvm5/+jp+M1+aqLl48aIkKSkpaYRXAgAAQnXx4kXFxMTcdCbMDCR9LOD3+3XmzBmNGzdOYWFhQ/rYPp9PSUlJOnXqlKKjo4f0sRGMvR4+7PXwYa+HD3s9fIZqr40xunjxohISEhQefvNPzXxp3qkJDw9XYmLiF/oc0dHR/J9kmLDXw4e9Hj7s9fBhr4fPUOz1rd6h+RQfFAYAAFYgagAAgBWImiHgcrm0bt06uVyukV6K9djr4cNeDx/2eviw18NnJPb6S/NBYQAAYDfeqQEAAFYgagAAgBWIGgAAYAWiBgAAWIGouU01NTWaMmWKIiMjlZWVpSNHjoz0kka9yspKzZ49W+PGjdPEiRNVWFioEydOBM188sknKikp0fjx4zV27Fg9/vjj6uzsHKEV2+Oll15SWFiYVqxYETjHXg+d06dP6xvf+IbGjx+vqKgoTZ8+XUePHg3cbozR2rVrdc899ygqKkput1sffPDBCK54dOrr69OaNWt07733KioqSvfdd59eeOGFoP92EHs9eD/96U/1h3/4h0pISFBYWJh2794ddPtA9rarq0uLFi1SdHS0YmNjtWTJEl26dOn2F2cwaLW1tcbpdJpXX33V/PKXvzRPP/20iY2NNZ2dnSO9tFEtLy/PvPbaa6a9vd20tbWZP/iDPzCTJ082ly5dCswsXbrUJCUlmcbGRnP06FEzZ84ck5OTM4KrHv2OHDlipkyZYmbMmGGWL18eOM9eD42uri6TnJxsvvnNb5rDhw+bDz/80Pznf/6n+a//+q/AzEsvvWRiYmLM7t27zc9//nPzR3/0R+bee+81V65cGcGVjz7r168348ePN3v27DEfffSR2bVrlxk7dqz5zne+E5hhrwdv79695vnnnzc/+MEPjCRTV1cXdPtA9jY/P9/MnDnTHDp0yLz11lvm/vvvNwsXLrzttRE1tyEzM9OUlJQE/tzX12cSEhJMZWXlCK7KPufOnTOSzIEDB4wxxly4cMGMGTPG7Nq1KzBz/PhxI8k0NzeP1DJHtYsXL5qpU6eahoYGk5ubG4ga9nro/O3f/q353d/93c+93e/3m/j4ePNP//RPgXMXLlwwLpfL/Nu//dtwLNEaBQUF5i/+4i+Czi1YsMAsWrTIGMNeD6X/HzUD2dv33nvPSDLvvPNOYOY//uM/TFhYmDl9+vRtrYe/fhqka9euqaWlRW63O3AuPDxcbrdbzc3NI7gy+3R3d0uS7r77bklSS0uLent7g/Y+JSVFkydPZu8HqaSkRAUFBUF7KrHXQ8nj8WjWrFn60z/9U02cOFEPPfSQ/uVf/iVw+0cffSSv1xu01zExMcrKymKvQ5STk6PGxkZ1dHRIkn7+85/r7bff1vz58yWx11+kgextc3OzYmNjNWvWrMCM2+1WeHi4Dh8+fFvP/6X5D1oOtfPnz6uvr09xcXFB5+Pi4vT++++P0Krs4/f7tWLFCn3ta19TWlqaJMnr9crpdCo2NjZoNi4uTl6vdwRWObrV1tbq2LFjeuedd264jb0eOh9++KFeeeUVlZWVqaKiQu+8846+9a1vyel0qri4OLCf/f07hb0OzapVq+Tz+ZSSkiKHw6G+vj6tX79eixYtkiT2+gs0kL31er2aOHFi0O0RERG6++67b3v/iRrc0UpKStTe3q633357pJdipVOnTmn58uVqaGhQZGTkSC/Han6/X7NmzdLf//3fS5Ieeughtbe3a8uWLSouLh7h1dnljTfe0Pe//33t2LFD06ZNU1tbm1asWKGEhAT22nL89dMgTZgwQQ6H44ZvgXR2dio+Pn6EVmWX0tJS7dmzR01NTUpMTAycj4+P17Vr13ThwoWgefY+dC0tLTp37pwefvhhRUREKCIiQgcOHNB3v/tdRUREKC4ujr0eIvfcc49SU1ODzj344IM6efKkJAX2k3+n3L6VK1dq1apV+rM/+zNNnz5dTz75pJ577jlVVlZKYq+/SAPZ2/j4eJ07dy7o9l//+tfq6uq67f0nagbJ6XQqIyNDjY2NgXN+v1+NjY3Kzs4ewZWNfsYYlZaWqq6uTvv379e9994bdHtGRobGjBkTtPcnTpzQyZMn2fsQPfroo3r33XfV1tYWOGbNmqVFixYF/pm9Hhpf+9rXbvhpgo6ODiUnJ0uS7r33XsXHxwfttc/n0+HDh9nrEF2+fFnh4cEvbw6HQ36/XxJ7/UUayN5mZ2frwoULamlpCczs379ffr9fWVlZt7eA2/qY8ZdcbW2tcblc5vXXXzfvvfeeeeaZZ0xsbKzxer0jvbRR7a/+6q9MTEyM+clPfmLOnj0bOC5fvhyYWbp0qZk8ebLZv3+/OXr0qMnOzjbZ2dkjuGp7/Oa3n4xhr4fKkSNHTEREhFm/fr354IMPzPe//31z1113me3btwdmXnrpJRMbG2t++MMfml/84hfmscce42vGg1BcXGwmTZoU+Er3D37wAzNhwgTzN3/zN4EZ9nrwLl68aFpbW01ra6uRZDZu3GhaW1vNf//3fxtjBra3+fn55qGHHjKHDx82b7/9tpk6dSpf6b4TVFdXm8mTJxun02kyMzPNoUOHRnpJo56kfo/XXnstMHPlyhXz13/91+a3fuu3zF133WX++I//2Jw9e3bkFm2R/x817PXQ+dGPfmTS0tKMy+UyKSkpZuvWrUG3+/1+s2bNGhMXF2dcLpd59NFHzYkTJ0ZotaOXz+czy5cvN5MnTzaRkZHmt3/7t83zzz9vrl69Gphhrwevqamp339HFxcXG2MGtrf/+7//axYuXGjGjh1roqOjzeLFi83Fixdve21hxvzGTywCAACMUnymBgAAWIGoAQAAViBqAACAFYgaAABgBaIGAABYgagBAABWIGoAAIAViBoAAGAFogYAAFiBqAEAAFYgagAAgBWIGgAAYIX/Awbm4065QXFfAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "c=0\n",
    "for epoch in range(100):\n",
    "    \n",
    "    #forward\n",
    "    Layer1.forward(x_train)\n",
    "    Act1.forward(Layer1.output)\n",
    "    loss_train = Loss.forward(Act1.output,y_train)\n",
    "    \n",
    "    \n",
    "    # Report\n",
    "    y_predict_train = np.argmax(Act1.output,axis = 1)\n",
    "    accuracy_train = np.mean(y_train == y_predict_train)\n",
    "    \n",
    "    #backward\n",
    "    Loss.backward(Act1.output,y_train)\n",
    "    Act1.backward(Loss.b_output)\n",
    "    Layer1.backward(Act1.b_output)\n",
    "    \n",
    "    print(f'Epoch:{epoch}')\n",
    "    print(f'Loss: {loss_train}')\n",
    "    print(f'Accuracy: {accuracy_train}')\n",
    "    print('--------------------------')\n",
    "    \n",
    "    plt.scatter(epoch,accuracy, c= 'blue')\n",
    "\n",
    "    #update params\n",
    "    Optimizer.update(Layer1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "11be6ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.084\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "Layer1.forward(x_test)\n",
    "Act1.forward(Layer1.output)\n",
    "# Report\n",
    "y_predict_test = np.argmax(Act1.output,axis = 1)\n",
    "accuracy_test = np.mean(y_test == y_predict_test)\n",
    "print(f'Accuracy: {accuracy_test}')\n",
    "print('--------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c2b250bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "096331dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Layer1 = Dense(784,30)\n",
    "Act1=ReLU()\n",
    "\n",
    "Layer2 = Dense(30,10)\n",
    "Act2= Softmax()\n",
    "\n",
    "Loss = Categorical_cross_entroy_loss()\n",
    "Optimizer = RMSprop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3a36595c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ansar9811291\\AppData\\Local\\Temp\\ipykernel_5516\\784203532.py:62: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.sum(-np.log(cc)).reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0\n",
      "Loss: [inf]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (784,30) (30,10) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [54], line 30\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m#update params\u001b[39;00m\n\u001b[0;32m     29\u001b[0m Optimizer\u001b[38;5;241m.\u001b[39mupdate(Layer1)\n\u001b[1;32m---> 30\u001b[0m Optimizer\u001b[38;5;241m.\u001b[39mupdate(Layer2)\n",
      "Cell \u001b[1;32mIn [43], line 13\u001b[0m, in \u001b[0;36mRMSprop.update\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate\u001b[39m(\u001b[38;5;28mself\u001b[39m, layer):\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m## dw, db are from current minibatch\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m## momentum beta 1\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m# *** weights *** #\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_dw \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgamma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mv_dw\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgamma\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mg_w\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_db \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_db \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma) \u001b[38;5;241m*\u001b[39m layer\u001b[38;5;241m.\u001b[39mg_b \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m     16\u001b[0m     layer\u001b[38;5;241m.\u001b[39mw \u001b[38;5;241m=\u001b[39m layer\u001b[38;5;241m.\u001b[39mw \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearning_rate \u001b[38;5;241m/\u001b[39m ((np\u001b[38;5;241m.\u001b[39msqrt( \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_dw\u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-08\u001b[39m))) \u001b[38;5;241m*\u001b[39m layer\u001b[38;5;241m.\u001b[39mg_w\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (784,30) (30,10) "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "c=0\n",
    "for epoch in range(100):\n",
    "    #forward\n",
    "    Layer1.forward(x_train)\n",
    "    Act1.forward(Layer1.output)\n",
    "    Layer2.forward(Act1.output)\n",
    "    Act2.forward(Layer2.output)\n",
    "    loss_train = Loss.forward(Act2.output,y_train)\n",
    "    \n",
    "    y_predict_train = np.argmax(Act1.output,axis = 1)\n",
    "    accuracy_train = np.mean(y_train == y_predict_train)\n",
    "    \n",
    "    #backward\n",
    "    Loss.backward(Act2.output,y_train)\n",
    "    Act2.backward(Loss.b_output)\n",
    "    Layer2.backward(Act2.b_output)\n",
    "    Act1.backward(Layer2.b_output)\n",
    "    Layer1.backward(Act1.b_output)\n",
    "    \n",
    "    print(f'Epoch:{epoch}')\n",
    "    print(f'Loss: {loss_train}')\n",
    "    print(f'Accuracy: {accuracy_train}')\n",
    "    print('--------------------------')\n",
    "    \n",
    "    plt.scatter(epoch,accuracy, c= 'blue')\n",
    "    \n",
    "\n",
    "    #update params\n",
    "    Optimizer.update(Layer1)\n",
    "    Optimizer.update(Layer2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6ee5a0fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0\n",
      "Accuracy: 0.084\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "#forward\n",
    "Layer1.forward(x_test)\n",
    "Act1.forward(Layer1.output)\n",
    "Layer2.forward(Act1.output)\n",
    "Act2.forward(Layer2.output)\n",
    "# Report\n",
    "y_predict = np.argmax(Act2.output,axis = 1)\n",
    "accuracy = np.mean(y_test == y_predict)\n",
    "print(f'Epoch:{epoch}')\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('--------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0435a23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ccd16476",
   "metadata": {},
   "outputs": [],
   "source": [
    "Layer1 = Dense(784,30)\n",
    "Act1=ReLU()\n",
    "Layer2 = Dense(30,10)\n",
    "Act2= Softmax()\n",
    "\n",
    "Layer3 = Dense(10,10)\n",
    "Act3= Softmax()\n",
    "\n",
    "Loss = Categorical_cross_entroy_loss()\n",
    "Optimizer = RMSprop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f6fad6c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ansar9811291\\AppData\\Local\\Temp\\ipykernel_5516\\784203532.py:62: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.sum(-np.log(cc)).reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09879996991735537\n",
      "--------------------------\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (784,30) (30,10) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [58], line 40\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m#update params\u001b[39;00m\n\u001b[0;32m     39\u001b[0m Optimizer\u001b[38;5;241m.\u001b[39mupdate(Layer1)\n\u001b[1;32m---> 40\u001b[0m Optimizer\u001b[38;5;241m.\u001b[39mupdate(Layer2)\n\u001b[0;32m     41\u001b[0m Optimizer\u001b[38;5;241m.\u001b[39mupdate(Layer3)\n",
      "Cell \u001b[1;32mIn [43], line 13\u001b[0m, in \u001b[0;36mRMSprop.update\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate\u001b[39m(\u001b[38;5;28mself\u001b[39m, layer):\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m## dw, db are from current minibatch\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m## momentum beta 1\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m# *** weights *** #\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_dw \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgamma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mv_dw\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgamma\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mg_w\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_db \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_db \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma) \u001b[38;5;241m*\u001b[39m layer\u001b[38;5;241m.\u001b[39mg_b \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m     16\u001b[0m     layer\u001b[38;5;241m.\u001b[39mw \u001b[38;5;241m=\u001b[39m layer\u001b[38;5;241m.\u001b[39mw \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearning_rate \u001b[38;5;241m/\u001b[39m ((np\u001b[38;5;241m.\u001b[39msqrt( \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_dw\u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-08\u001b[39m))) \u001b[38;5;241m*\u001b[39m layer\u001b[38;5;241m.\u001b[39mg_w\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (784,30) (30,10) "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "c=0\n",
    "for epoch in range(100):\n",
    "    #forward\n",
    "    Layer1.forward(x_train)\n",
    "    Act1.forward(Layer1.output)\n",
    "    Layer2.forward(Act1.output)\n",
    "    Act2.forward(Layer2.output)\n",
    "    \n",
    "    Layer3.forward(Act2.output)\n",
    "    Act3.forward(Layer3.output)\n",
    "    loss_train = Loss.forward(Act3.output,y_train)\n",
    "    \n",
    "    \n",
    "    # Report\n",
    "    y_predict_train = np.argmax(Act2.output,axis = 1)\n",
    "    accuracy_train = np.mean(y_train == y_predict_train)\n",
    "   \n",
    "    \n",
    "    #backward\n",
    "    Loss.backward(Act3.output,y_train)\n",
    "    Act3.backward(Loss.b_output)\n",
    "    Layer3.backward(Act3.b_output)\n",
    "    \n",
    "    Act2.backward(Layer3.b_output)\n",
    "    Layer2.backward(Act2.b_output)\n",
    "    \n",
    "    Act1.backward(Layer2.b_output)\n",
    "    Layer1.backward(Act1.b_output)\n",
    "    \n",
    "    print(f'Epoch:{epoch}')\n",
    "    print(f'Loss: {loss_train}')\n",
    "    print(f'Accuracy: {accuracy_train}')\n",
    "    print('--------------------------')\n",
    "    \n",
    "    plt.scatter(epoch,accuracy, c= 'blue')\n",
    "    \n",
    "    \n",
    "    #update params\n",
    "    Optimizer.update(Layer1)\n",
    "    Optimizer.update(Layer2)\n",
    "    Optimizer.update(Layer3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "74e31ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for test data: 0.084\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "#forward\n",
    "Layer1.forward(x_test)\n",
    "Act1.forward(Layer1.output)\n",
    "\n",
    "Layer2.forward(Act1.output)\n",
    "Act2.forward(Layer2.output)\n",
    "\n",
    "Layer3.forward(Act2.output)\n",
    "Act3.forward(Layer3.output)\n",
    "    \n",
    "# Report\n",
    "y_predict = np.argmax(Act2.output,axis = 1)\n",
    "accuracy = np.mean(y_test == y_predict)\n",
    "\n",
    "print(f'Accuracy for test data: {accuracy}')\n",
    "print('--------------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147eb237",
   "metadata": {},
   "source": [
    "# 3-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8eefca",
   "metadata": {},
   "source": [
    "# Adam_Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8c22cb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdamOptim():\n",
    "    def __init__(self, eta=0.01, beta1=0.9, beta2=0.999, epsilon=1e-8):\n",
    "        self.m_dw, self.v_dw = 0, 0\n",
    "        self.m_db, self.v_db = 0, 0\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.epsilon = epsilon\n",
    "        self.eta = eta\n",
    "\n",
    "    def update(self, t, layer):\n",
    "        ## dw, db are from current minibatch\n",
    "        ## momentum beta 1\n",
    "        # *** weights *** #\n",
    "        \n",
    "        self.m_dw = self.beta1*(self.m_dw) + (1-self.beta1)* layer.g_w\n",
    "        # *** biases *** #\n",
    "        self.m_db = self.beta1*(self.m_db) + (1-self.beta1)* layer.g_b\n",
    "\n",
    "        ## rms beta 2\n",
    "        # *** weights *** #\n",
    "        self.v_dw = self.beta2*(self.v_dw) + (1-self.beta2)*(layer.g_w**2)\n",
    "        # *** biases *** #\n",
    "        self.v_db = self.beta2*(self.v_db) + (1-self.beta2)*(layer.g_b)\n",
    "\n",
    "        ## bias correction\n",
    "        m_dw_corr = self.m_dw/(1-self.beta1**t)\n",
    "        m_db_corr = self.m_db/(1-self.beta1**t)\n",
    "        v_dw_corr = self.v_dw/(1-self.beta2**t)\n",
    "        v_db_corr = self.v_db/(1-self.beta2**t)\n",
    "        \n",
    "        print(m_dw_corr)\n",
    "        \n",
    "        print(v_dw_corr)\n",
    "        print((np.sqrt(v_dw_corr)+self.epsilon))\n",
    "\n",
    "        ## update weights and biases\n",
    "        layer.w = layer.w - self.eta*(m_dw_corr/(np.sqrt(v_dw_corr)+self.epsilon))\n",
    "        layer.b = layer.b - self.eta*(m_db_corr/(np.sqrt(v_db_corr)+self.epsilon))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "616b1ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "72cde09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Layer1 = Dense(784,10)\n",
    "Act1 = Softmax()\n",
    "Loss = Categorical_cross_entroy_loss()\n",
    "Optimizer = AdamOptim(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c0c517f6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ansar9811291\\AppData\\Local\\Temp\\ipykernel_5516\\784203532.py:62: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.sum(-np.log(cc)).reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: \n",
      "Epoch:0\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880057190082644\n",
      "--------------------------\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[1.e-08 1.e-08 1.e-08 ... 1.e-08 1.e-08 1.e-08]\n",
      " [1.e-08 1.e-08 1.e-08 ... 1.e-08 1.e-08 1.e-08]\n",
      " [1.e-08 1.e-08 1.e-08 ... 1.e-08 1.e-08 1.e-08]\n",
      " ...\n",
      " [1.e-08 1.e-08 1.e-08 ... 1.e-08 1.e-08 1.e-08]\n",
      " [1.e-08 1.e-08 1.e-08 ... 1.e-08 1.e-08 1.e-08]\n",
      " [1.e-08 1.e-08 1.e-08 ... 1.e-08 1.e-08 1.e-08]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ansar9811291\\AppData\\Local\\Temp\\ipykernel_5516\\4012035994.py:38: RuntimeWarning: invalid value encountered in sqrt\n",
      "  layer.b = layer.b - self.eta*(m_db_corr/(np.sqrt(v_db_corr)+self.epsilon))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: \n",
      "Epoch:1\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:2\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:3\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:4\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:5\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:6\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:7\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:8\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:9\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:10\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:11\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:12\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:13\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: \n",
      "Epoch:14\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:15\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:16\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:17\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:18\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:19\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:20\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:21\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:22\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:23\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:24\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:25\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:26\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: \n",
      "Epoch:27\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:28\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:29\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:30\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:31\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:32\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:33\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:34\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:35\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:36\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:37\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:38\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:39\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: \n",
      "Epoch:40\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:41\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:42\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:43\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:44\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:45\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:46\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:47\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:48\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:49\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:50\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:51\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:52\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: \n",
      "Epoch:53\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:54\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:55\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:56\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:57\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:58\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:59\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:60\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:61\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:62\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:63\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:64\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:65\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: \n",
      "Epoch:66\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:67\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:68\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:69\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:70\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:71\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:72\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:73\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:74\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:75\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:76\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:77\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:78\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: \n",
      "Epoch:79\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:80\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:81\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:82\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:83\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:84\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:85\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:86\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:87\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:88\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:89\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:90\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:91\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: \n",
      "Epoch:92\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:93\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:94\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:95\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:96\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:97\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:98\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Train data: \n",
      "Epoch:99\n",
      "Loss: [nan]\n",
      "Accuracy: 0.0988\n",
      "--------------------------\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "c=0\n",
    "for epoch in range(100):\n",
    "    \n",
    "    #forward\n",
    "    Layer1.forward(x_train)\n",
    "    Act1.forward(Layer1.output)\n",
    "    loss_train = Loss.forward(Act1.output,y_train)\n",
    "    \n",
    "    \n",
    "    # Report\n",
    "    y_predict_train = np.argmax(Act1.output,axis = 1)\n",
    "    accuracy_train = np.mean(y_train == y_predict_train)\n",
    "    \n",
    "    #backward\n",
    "    Loss.backward(Act1.output,y_train)\n",
    "    Act1.backward(Loss.b_output)\n",
    "    Layer1.backward(Act1.b_output)\n",
    "    \n",
    "    \n",
    "    \n",
    "    print('Train data: ')\n",
    "    print(f'Epoch:{epoch}')\n",
    "    print(f'Loss: {loss_train}')\n",
    "    print(f'Accuracy: {accuracy_train}')\n",
    "    print('--------------------------')\n",
    "    \n",
    "    plt.scatter(epoch,accuracy, c= 'blue')\n",
    "\n",
    "    #update params\n",
    "    Optimizer.update(0.01,Layer1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2cc25ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.084\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "Layer1.forward(x_test)\n",
    "Act1.forward(Layer1.output)\n",
    "# Report\n",
    "y_predict_test = np.argmax(Act1.output,axis = 1)\n",
    "accuracy_test = np.mean(y_test == y_predict_test)\n",
    "print(f'Accuracy: {accuracy_test}')\n",
    "print('--------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "65c194ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "dc0e2021",
   "metadata": {},
   "outputs": [],
   "source": [
    "Layer1 = Dense(784,30)\n",
    "Act1=ReLU()\n",
    "\n",
    "Layer2 = Dense(30,10)\n",
    "Act2= Softmax()\n",
    "\n",
    "Loss = Categorical_cross_entroy_loss()\n",
    "Optimizer = AdamOptim(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6df40683",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ansar9811291\\AppData\\Local\\Temp\\ipykernel_5516\\784203532.py:62: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.sum(-np.log(cc)).reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0\n",
      "Loss: [inf]\n",
      "Accuracy: 0.09880003074380166\n",
      "--------------------------\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[1.e-08 1.e-08 1.e-08 ... 1.e-08 1.e-08 1.e-08]\n",
      " [1.e-08 1.e-08 1.e-08 ... 1.e-08 1.e-08 1.e-08]\n",
      " [1.e-08 1.e-08 1.e-08 ... 1.e-08 1.e-08 1.e-08]\n",
      " ...\n",
      " [1.e-08 1.e-08 1.e-08 ... 1.e-08 1.e-08 1.e-08]\n",
      " [1.e-08 1.e-08 1.e-08 ... 1.e-08 1.e-08 1.e-08]\n",
      " [1.e-08 1.e-08 1.e-08 ... 1.e-08 1.e-08 1.e-08]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ansar9811291\\AppData\\Local\\Temp\\ipykernel_5516\\4012035994.py:38: RuntimeWarning: invalid value encountered in sqrt\n",
      "  layer.b = layer.b - self.eta*(m_db_corr/(np.sqrt(v_db_corr)+self.epsilon))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (784,30) (30,10) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [72], line 29\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m#update params\u001b[39;00m\n\u001b[0;32m     28\u001b[0m Optimizer\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m0.01\u001b[39m,Layer1)\n\u001b[1;32m---> 29\u001b[0m Optimizer\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m0.01\u001b[39m,Layer2)\n",
      "Cell \u001b[1;32mIn [60], line 15\u001b[0m, in \u001b[0;36mAdamOptim.update\u001b[1;34m(self, t, layer)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate\u001b[39m(\u001b[38;5;28mself\u001b[39m, t, layer):\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m## dw, db are from current minibatch\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m## momentum beta 1\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m# *** weights *** #\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm_dw \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mm_dw\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mg_w\u001b[49m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m# *** biases *** #\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm_db \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta1\u001b[38;5;241m*\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm_db) \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta1)\u001b[38;5;241m*\u001b[39m layer\u001b[38;5;241m.\u001b[39mg_b\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (784,30) (30,10) "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "c=0\n",
    "for epoch in range(100):\n",
    "    #forward\n",
    "    Layer1.forward(x_train)\n",
    "    Act1.forward(Layer1.output)\n",
    "    Layer2.forward(Act1.output)\n",
    "    Act2.forward(Layer2.output)\n",
    "    loss_train = Loss.forward(Act2.output,y_train)\n",
    "    \n",
    "    y_predict_train = np.argmax(Act1.output,axis = 1)\n",
    "    accuracy_train = np.mean(y_train == y_predict_train)\n",
    "    \n",
    "    #backward\n",
    "    Loss.backward(Act2.output,y_train)\n",
    "    Act2.backward(Loss.b_output)\n",
    "    Layer2.backward(Act2.b_output)\n",
    "    Act1.backward(Layer2.b_output)\n",
    "    Layer1.backward(Act1.b_output)\n",
    "   \n",
    "    print(f'Epoch:{epoch}')\n",
    "    print(f'Loss: {loss_train}')\n",
    "    print(f'Accuracy: {accuracy_train}')\n",
    "    print('--------------------------')\n",
    "    \n",
    "    plt.scatter(epoch,accuracy, c= 'blue')\n",
    "\n",
    "    #update params\n",
    "    Optimizer.update(0.01,Layer1)\n",
    "    Optimizer.update(0.01,Layer2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e2f99403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0\n",
      "Accuracy: 0.084\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "#forward\n",
    "Layer1.forward(x_test)\n",
    "Act1.forward(Layer1.output)\n",
    "Layer2.forward(Act1.output)\n",
    "Act2.forward(Layer2.output)\n",
    "# Report\n",
    "y_predict = np.argmax(Act2.output,axis = 1)\n",
    "accuracy = np.mean(y_test == y_predict)\n",
    "print(f'Epoch:{epoch}')\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('--------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0432fc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7aecd251",
   "metadata": {},
   "outputs": [],
   "source": [
    "Layer1 = Dense(784,30)\n",
    "Act1=ReLU()\n",
    "Layer2 = Dense(30,10)\n",
    "Act2= Softmax()\n",
    "\n",
    "Layer3 = Dense(10,10)\n",
    "Act3= Softmax()\n",
    "\n",
    "Loss = Categorical_cross_entroy_loss()\n",
    "Optimizer = AdamOptim(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d26b6947",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ansar9811291\\AppData\\Local\\Temp\\ipykernel_5516\\784203532.py:62: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.sum(-np.log(cc)).reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0\n",
      "Loss: [inf]\n",
      "Accuracy: 0.11294486082644628\n",
      "--------------------------\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[1.e-08 1.e-08 1.e-08 ... 1.e-08 1.e-08 1.e-08]\n",
      " [1.e-08 1.e-08 1.e-08 ... 1.e-08 1.e-08 1.e-08]\n",
      " [1.e-08 1.e-08 1.e-08 ... 1.e-08 1.e-08 1.e-08]\n",
      " ...\n",
      " [1.e-08 1.e-08 1.e-08 ... 1.e-08 1.e-08 1.e-08]\n",
      " [1.e-08 1.e-08 1.e-08 ... 1.e-08 1.e-08 1.e-08]\n",
      " [1.e-08 1.e-08 1.e-08 ... 1.e-08 1.e-08 1.e-08]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ansar9811291\\AppData\\Local\\Temp\\ipykernel_5516\\4012035994.py:38: RuntimeWarning: invalid value encountered in sqrt\n",
      "  layer.b = layer.b - self.eta*(m_db_corr/(np.sqrt(v_db_corr)+self.epsilon))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (784,30) (30,10) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [76], line 39\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m#update params\u001b[39;00m\n\u001b[0;32m     38\u001b[0m Optimizer\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m0.01\u001b[39m,Layer1)\n\u001b[1;32m---> 39\u001b[0m Optimizer\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m0.01\u001b[39m,Layer2)\n\u001b[0;32m     40\u001b[0m Optimizer\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m0.01\u001b[39m,Layer3)\n",
      "Cell \u001b[1;32mIn [60], line 15\u001b[0m, in \u001b[0;36mAdamOptim.update\u001b[1;34m(self, t, layer)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate\u001b[39m(\u001b[38;5;28mself\u001b[39m, t, layer):\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m## dw, db are from current minibatch\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m## momentum beta 1\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m# *** weights *** #\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm_dw \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mm_dw\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mg_w\u001b[49m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m# *** biases *** #\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm_db \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta1\u001b[38;5;241m*\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm_db) \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta1)\u001b[38;5;241m*\u001b[39m layer\u001b[38;5;241m.\u001b[39mg_b\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (784,30) (30,10) "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "c=0\n",
    "for epoch in range(100):\n",
    "    #forward\n",
    "    Layer1.forward(x_train)\n",
    "    Act1.forward(Layer1.output)\n",
    "    Layer2.forward(Act1.output)\n",
    "    Act2.forward(Layer2.output)\n",
    "    \n",
    "    Layer3.forward(Act2.output)\n",
    "    Act3.forward(Layer3.output)\n",
    "    loss_train = Loss.forward(Act3.output,y_train)\n",
    "    \n",
    "    \n",
    "    # Report\n",
    "    y_predict_train = np.argmax(Act2.output,axis = 1)\n",
    "    accuracy_train = np.mean(y_train == y_predict_train)\n",
    "   \n",
    "    \n",
    "    #backward\n",
    "    Loss.backward(Act3.output,y_train)\n",
    "    Act3.backward(Loss.b_output)\n",
    "    Layer3.backward(Act3.b_output)\n",
    "    \n",
    "    Act2.backward(Layer3.b_output)\n",
    "    Layer2.backward(Act2.b_output)\n",
    "    \n",
    "    Act1.backward(Layer2.b_output)\n",
    "    Layer1.backward(Act1.b_output)\n",
    "    \n",
    "    print(f'Epoch:{epoch}')\n",
    "    print(f'Loss: {loss_train}')\n",
    "    print(f'Accuracy: {accuracy_train}')\n",
    "    print('--------------------------')\n",
    "    \n",
    "    plt.scatter(epoch,accuracy, c= 'blue')\n",
    "   \n",
    "    #update params\n",
    "    Optimizer.update(0.01,Layer1)\n",
    "    Optimizer.update(0.01,Layer2)\n",
    "    Optimizer.update(0.01,Layer3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b1f02cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for test data: 0.084\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "#forward\n",
    "Layer1.forward(x_test)\n",
    "Act1.forward(Layer1.output)\n",
    "\n",
    "Layer2.forward(Act1.output)\n",
    "Act2.forward(Layer2.output)\n",
    "\n",
    "Layer3.forward(Act2.output)\n",
    "Act3.forward(Layer3.output)\n",
    "    \n",
    "# Report\n",
    "y_predict = np.argmax(Act2.output,axis = 1)\n",
    "accuracy = np.mean(y_test == y_predict)\n",
    "\n",
    "print(f'Accuracy for test data: {accuracy}')\n",
    "print('--------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fda8871",
   "metadata": {},
   "source": [
    "# 3-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f0f080",
   "metadata": {},
   "source": [
    "# a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4c9476d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense:\n",
    "    def __init__(self,n_inputs,n_neurons):\n",
    "        self.w = np.random.uniform(size=(n_inputs,n_neurons))\n",
    "        self.b =  np.random.uniform(size= n_neurons)\n",
    "    \n",
    "    def forward(self,inputs):\n",
    "        self.output = np.dot(inputs,self.w)+self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fdd0ee7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = [[0,0],[0,1],[1,0],[1,1]]\n",
    "y_train = [0, 1 , 1 , 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b331cdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Layer1 = Dense(2,4)\n",
    "Layer2 = Dense(4,2)\n",
    "\n",
    "Act1 = ReLU()\n",
    "Act2 = Softmax()\n",
    "\n",
    "alpha = 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "57476321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.5\n"
     ]
    }
   ],
   "source": [
    "y_predict = []\n",
    "for j in range(len(x_train)) :       \n",
    "        Layer1.forward(x_train[j])\n",
    "        Act1.forward(Layer1.output)\n",
    "        Layer2.forward(Act1.output)\n",
    "        Act2.forward(Layer2.output)\n",
    "        \n",
    "        \n",
    "        \n",
    "        if Act2.output[0] < Act2.output[1] :\n",
    "            y_predict.append(1)\n",
    "        else:\n",
    "            y_predict.append(0)\n",
    "            \n",
    "        \n",
    "        e = y_train[j] - Act2.output\n",
    "        e = np.array(e*alpha)\n",
    "        \n",
    "        k = e*x_train[j]\n",
    "\n",
    "        Layer2.w = Layer2.w + k\n",
    "        Layer2.b = Layer2.b + e\n",
    "\n",
    "\n",
    "y_predict = np.array(y_predict)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "\n",
    "\n",
    "accuracy = np.mean(y_train == y_predict)\n",
    "print(\"accuracy =\", accuracy) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5a41e2",
   "metadata": {},
   "source": [
    "# b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e368d10f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy in epoch 0 = 0.75\n",
      "accuracy in epoch 1 = 0.5\n",
      "accuracy in epoch 2 = 0.5\n",
      "accuracy in epoch 3 = 0.5\n",
      "accuracy in epoch 4 = 0.5\n",
      "accuracy in epoch 5 = 0.5\n",
      "accuracy in epoch 6 = 0.5\n",
      "accuracy in epoch 7 = 0.5\n",
      "accuracy in epoch 8 = 0.5\n",
      "accuracy in epoch 9 = 0.5\n"
     ]
    }
   ],
   "source": [
    "y_predict = []\n",
    "epoch = 10\n",
    "\n",
    "for ind in range(epoch) : \n",
    "    y_predict = []\n",
    "    \n",
    "    for j in range(len(x_train)) :       \n",
    "        Layer1.forward(x_train[j])\n",
    "        Act1.forward(Layer1.output)\n",
    "        Layer2.forward(Act1.output)\n",
    "        Act2.forward(Layer2.output)\n",
    "        \n",
    "        \n",
    "        \n",
    "        if Act2.output[0] < Act2.output[1] :\n",
    "            y_predict.append(1)\n",
    "        else:\n",
    "            y_predict.append(0)\n",
    "            \n",
    "        \n",
    "        e = y_train[j] - Act2.output\n",
    "        e = np.array(e*alpha)\n",
    "        \n",
    "        k = e*x_train[j]\n",
    "\n",
    "        Layer2.w = Layer2.w + k\n",
    "        Layer2.b = Layer2.b + e\n",
    "\n",
    "\n",
    "    y_predict = np.array(y_predict)\n",
    "    y_train = np.array(y_train)\n",
    "\n",
    "\n",
    "\n",
    "    accuracy = np.mean(y_train == y_predict)\n",
    "    print(\"accuracy in epoch\", ind,\"=\", accuracy) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322014b3",
   "metadata": {},
   "source": [
    "The accuracy increased after training for more epochs because each epoch define a new line in our spatial space to classify data \n",
    "and in epoch 3 we reached 100% accuracy. So, after 3 epoches accuracy reached the best."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772e9d63",
   "metadata": {},
   "source": [
    "# 3-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e95017fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0\n",
      "Loss: [0.505]\n",
      "Accuracy: 0.5\n",
      "Epoch:1\n",
      "Loss: [0.505]\n",
      "Accuracy: 0.5\n",
      "Epoch:2\n",
      "Loss: [0.505]\n",
      "Accuracy: 0.5\n",
      "Epoch:3\n",
      "Loss: [0.505]\n",
      "Accuracy: 0.5\n",
      "Epoch:4\n",
      "Loss: [0.505]\n",
      "Accuracy: 0.5\n",
      "Epoch:5\n",
      "Loss: [0.505]\n",
      "Accuracy: 0.5\n",
      "Epoch:6\n",
      "Loss: [0.505]\n",
      "Accuracy: 0.5\n",
      "Epoch:7\n",
      "Loss: [0.505]\n",
      "Accuracy: 0.5\n",
      "Epoch:8\n",
      "Loss: [0.505]\n",
      "Accuracy: 0.5\n",
      "Epoch:9\n",
      "Loss: [0.505]\n",
      "Accuracy: 0.5\n",
      "Epoch:0\n",
      "Loss: [0.49959074]\n",
      "Accuracy: 0.5\n",
      "Epoch:1\n",
      "Loss: [0.49959037]\n",
      "Accuracy: 0.5\n",
      "Epoch:2\n",
      "Loss: [0.49959]\n",
      "Accuracy: 0.5\n",
      "Epoch:3\n",
      "Loss: [0.49958963]\n",
      "Accuracy: 0.5\n",
      "Epoch:4\n",
      "Loss: [0.49958926]\n",
      "Accuracy: 0.5\n",
      "Epoch:5\n",
      "Loss: [0.4995889]\n",
      "Accuracy: 0.5\n",
      "Epoch:6\n",
      "Loss: [0.49958853]\n",
      "Accuracy: 0.5\n",
      "Epoch:7\n",
      "Loss: [0.49958816]\n",
      "Accuracy: 0.5\n",
      "Epoch:8\n",
      "Loss: [0.49958779]\n",
      "Accuracy: 0.5\n",
      "Epoch:9\n",
      "Loss: [0.49958742]\n",
      "Accuracy: 0.5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3-5\n",
    "\n",
    "# a\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def func(y):\n",
    "    if -1<y:\n",
    "        return 1\n",
    "    \n",
    "    elif y == -1:\n",
    "        return np.random.uniform(-4,1)\n",
    "    \n",
    "    elif -2<y:\n",
    "        return -4\n",
    "    \n",
    "    elif y == -2:\n",
    "        return np.random.uniform(-4,4)\n",
    "    \n",
    "    elif -3<y:\n",
    "        return +4\n",
    "    \n",
    "    elif y == -3:\n",
    "        return np.random.uniform(-3,4)\n",
    "    \n",
    "    elif -4<y:\n",
    "        return -3\n",
    "      \n",
    "    elif y == -4:\n",
    "        return np.random.uniform(-3,2)\n",
    "   \n",
    "        \n",
    "    elif y<-4:\n",
    "        return +2\n",
    "    \n",
    "\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for i in range(100):\n",
    "    y = np.random.uniform(-20,20)\n",
    "    x = func(y)\n",
    "    x_bigger = np.random.uniform(func(y),20)\n",
    "    x_lower = np.random.uniform(-20,func(y))\n",
    "    \n",
    "    plt.scatter(x,y,c = 'b')\n",
    "    plt.scatter(x_bigger,y,c = 'r')\n",
    "    plt.scatter(x_lower,y,c = 'g')\n",
    "    \n",
    "    x_train.append(x_lower)\n",
    "    x_train.append(x_bigger)\n",
    "    \n",
    "    y_train.append(0)\n",
    "    y_train.append(1)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "p = np.array(x_train)\n",
    "t = np.array(y_train)\n",
    "\n",
    "p = pd.DataFrame(p,columns =['x_train'])\n",
    "t = pd.DataFrame(t,columns =['y_train'])\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "\n",
    "for i in range(200):\n",
    "    temp=[]\n",
    "    temp.append(p['x_train'][i])\n",
    "    x_train.append(temp)\n",
    "    \n",
    "for i in range(200):\n",
    "    temp=[]\n",
    "    temp.append(t['y_train'][i])\n",
    "    y_train.append(temp)\n",
    "\n",
    "\n",
    "# b\n",
    "\n",
    "class Dense:\n",
    "    def __init__(self,n_inputs,n_neurons):\n",
    "       \n",
    "        self.w=np.random.randint(-2, 2, (n_inputs, n_neurons))\n",
    "        self.b = np.random.randint(-2, 2, (1, n_neurons))    #b\n",
    "        self.weight_history = 0\n",
    "        self.bias_history = 0\n",
    "    \n",
    "    def forward(self,inputs):\n",
    "        self.input = inputs  #p\n",
    "        self.output = np.dot(inputs,self.w)+self.b\n",
    "        #print(self.output)\n",
    "        \n",
    "    def backward(self,b_input):\n",
    "        #print(type(b_input))\n",
    "        #print(b_input)\n",
    "        #print(type(self.w))\n",
    "        #print(self.w)\n",
    "        self.b_output = np.dot(b_input,self.w.T)\n",
    "        self.g_w = np.dot(np.array(self.input).T,b_input)\n",
    "        self.g_b = np.sum(b_input,axis=0,keepdims=True)\n",
    "\n",
    "class UnitStep:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def forward(self,inputs):\n",
    "        self.output=np.heaviside(inputs,0)\n",
    "    \n",
    "    def backward(self,b_input):\n",
    "        self.b_output = 0\n",
    "\n",
    "\n",
    "\n",
    "class ReLU:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def forward(self,inputs):\n",
    "        self.output = np.maximum(0,inputs)\n",
    "        self.input = inputs\n",
    "    \n",
    "    def backward(self,b_input):\n",
    "        self.b_output = b_input\n",
    "        self.b_output[self.input<=0] = 0\n",
    "\n",
    "class SGD:\n",
    "    def __init__(self,learning_rate = 0.001,momentum=0):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.momentum = momentum\n",
    "    def update(self,layer):\n",
    "        if self.momentum:\n",
    "            weight_update = self.momentum*layer.weight_history\\\n",
    "            + (1-self.momentum)*(-self.learning_rate*layer.g_w)\n",
    "            layer.weight_update = weight_update\n",
    "            bias_update = self.momentum*layer.weight_history\\\n",
    "            + (1-self.momentum)*(-self.learning_rate*layer.g_b)\n",
    "            layer.bias_update = bias_update\n",
    "        else:\n",
    "            weight_update = - self.learning_rate*layer.g_w\n",
    "            bias_update = - self.learning_rate*layer.g_b\n",
    "        layer.w = layer.w + weight_update\n",
    "        layer.b = layer.b + bias_update\n",
    "\n",
    "\n",
    "class Mean_Square_Error_loss:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def forward(self,y_predict,y_true):\n",
    "        return np.mean((y_true-y_predict)**2,axis = 0)\n",
    "    \n",
    "    def backward(self,y_predict,y_true):\n",
    "        self.b_output = -2*(y_true-y_predict)\n",
    "\n",
    "\n",
    "class Sigmoid:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def forward(self,inputs):\n",
    "        self.input = inputs\n",
    "        self.output = 1/(1+np.exp(-inputs))\n",
    "    def backward(self,b_input):\n",
    "        self.b_output = b_input*self.output*(1-self.output)\n",
    "\n",
    "\n",
    "class Linear:\n",
    "    def forward(self,inputs):\n",
    "        self.input = inputs\n",
    "        self.output = inputs\n",
    "    def backward(self,b_input):\n",
    "        self.b_output = b_input  \n",
    "\n",
    "\n",
    "\n",
    "class Softmax:\n",
    "\n",
    "    def forward(self,inputs):\n",
    "        neuron_output = np.exp(inputs-np.max(inputs,keepdims=True))\n",
    "        self.output = neuron_output/np.sum(neuron_output,keepdims=True)\n",
    "    \n",
    "    def backward(self,b_input):\n",
    "        self.b_output = b_input\n",
    "        for i , (item1 , item2) in enumerate(zip(self.output,b_input)):\n",
    "            item1 = item1.reshape(-1,1)\n",
    "            #sd means softmax derivative\n",
    "            sd = np.diagflat(item1)-np.dot(item1,item1.T)\n",
    "            #if j=k: S_j-(S_j)^2\n",
    "            #if j!=k: 0-(S_j)*(S_k)\n",
    "            self.b_output[i] = np.dot(sd,item2)\n",
    "\n",
    "\n",
    "#Creating the neural network\n",
    "Layer1=Dense(1,2)\n",
    "Act1 = ReLU()\n",
    "\n",
    "Layer2=Dense(2,1)\n",
    "Act2 = Softmax()\n",
    "\n",
    "Loss = Mean_Square_Error_loss()\n",
    "Optimizer = SGD(learning_rate=0.001, momentum=0.9)\n",
    "\n",
    "epoch = 10\n",
    "for i in range(epoch):\n",
    "    #forwad_propagation\n",
    "    Layer1.forward(x_train)\n",
    "    Act1.forward(Layer1.output)\n",
    "    Layer2.forward(Act1.output)\n",
    "    Act2.forward(Layer2.output)\n",
    "    Loss.forward(Act2.output,y_train)\n",
    "    \n",
    "    \n",
    "    \n",
    "    for k in range(len(Act2.output)):\n",
    "        if np.max(Act2.output) == Act2.output[k]:\n",
    "                Act2.output[k] = 1\n",
    "        else:\n",
    "                Act2.output[k] = 0\n",
    "    \n",
    "\n",
    "    #back_propagation\n",
    "    Loss.backward(Act2.output,y_train)\n",
    "    Act2.backward(Loss.b_output)\n",
    "    Layer2.backward(Act2.b_output)\n",
    "    Act1.backward(Layer2.b_output)\n",
    "    Layer1.backward(Act1.b_output)\n",
    "\n",
    "    #update_params\n",
    "    Optimizer.update(Layer1)\n",
    "    Optimizer.update(Layer2)\n",
    "    \n",
    "    loss = Loss.forward(Act2.output,y_train)\n",
    "    \n",
    "    # Report\n",
    "    y_predict = np.argmax(Act2.output,axis = 1)\n",
    "    accuracy = np.mean(y_train == y_predict)\n",
    "    \n",
    "    print(f'Epoch:{i}')\n",
    "    print(f'Loss: {loss}')\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "\n",
    "#Creating the neural network\n",
    "Layer1=Dense(1,6)\n",
    "Act1 = ReLU()\n",
    "\n",
    "Layer2=Dense(6,1)\n",
    "Act2 = Softmax()\n",
    "\n",
    "Loss = Mean_Square_Error_loss()\n",
    "Optimizer = SGD(learning_rate=0.001, momentum=0.9)\n",
    "\n",
    "epoch = 10\n",
    "for i in range(epoch):\n",
    "    #forwad_propagation\n",
    "    Layer1.forward(x_train)\n",
    "    Act1.forward(Layer1.output)\n",
    "    Layer2.forward(Act1.output)\n",
    "    Act2.forward(Layer2.output)\n",
    "    Loss.forward(Act2.output,y_train)\n",
    "\n",
    "    #back_propagation\n",
    "    Loss.backward(Act2.output,y_train)\n",
    "    Act2.backward(Loss.b_output)\n",
    "    Layer2.backward(Act2.b_output)\n",
    "    Act1.backward(Layer2.b_output)\n",
    "    Layer1.backward(Act1.b_output)\n",
    "\n",
    "    #update_params\n",
    "    Optimizer.update(Layer1)\n",
    "    Optimizer.update(Layer2)\n",
    "    \n",
    "    loss = Loss.forward(Act2.output,y_train)\n",
    "    \n",
    "    # Report\n",
    "    y_predict = np.argmax(Act2.output,axis = 1)\n",
    "    accuracy = np.mean(y_train == y_predict)\n",
    "    \n",
    "    print(f'Epoch:{i}')\n",
    "    print(f'Loss: {loss}')\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44f3c13",
   "metadata": {},
   "source": [
    "#c\n",
    "\n",
    "# There is no difference as our network just classify data with 0 label correctly. So, this change would not affect accuracy accurately.\n",
    "\n",
    "#d\n",
    "\n",
    "What is imbalanced data for classification?\n",
    "Imbalanced classification refers to a classification predictive modeling problem where the number of examples in the training dataset for each class label is not balanced. That is, where the class distribution is not equal or close to equal, and is instead biased or skewed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
